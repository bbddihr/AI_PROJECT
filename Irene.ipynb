{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KOREAVC\\anaconda3\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\KOREAVC\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from pororo import Pororo\n",
    "import pandas as pd\n",
    "from sentence_transformers import util\n",
    "import torch\n",
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import enum\n",
    "import os\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import json\n",
    "# from configs import DEFINES #config파일 사용위해\n",
    "from tqdm import tqdm #진행속도를 알려줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'question' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# 코모란 형태소 분석기 객체 생성\u001b[39;00m\n\u001b[0;32m      4\u001b[0m komoran\u001b[38;5;241m=\u001b[39mKomoran()\n\u001b[1;32m----> 5\u001b[0m text\u001b[38;5;241m=\u001b[39mquestion[\u001b[38;5;241m500\u001b[39m]\n\u001b[0;32m      6\u001b[0m morphs\u001b[38;5;241m=\u001b[39mkomoran\u001b[38;5;241m.\u001b[39mmorphs(text)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(morphs)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'question' is not defined"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Komoran\n",
    "\n",
    "# 코모란 형태소 분석기 객체 생성\n",
    "komoran=Komoran()\n",
    "text=question[500]\n",
    "morphs=komoran.morphs(text)\n",
    "\n",
    "print(morphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('알츠하이머병', 'NNP'), ('의', 'JKG'), ('증상', 'NNP'), ('중', 'NNB'), ('에서', 'JKB'), ('특히', 'MAG'), ('조심', 'NNG'), ('하', 'XSV'), ('아야', 'EC'), ('하', 'VV'), ('ㄹ', 'ETM'), ('것', 'NNB'), ('은', 'JX'), ('무엇', 'NP'), ('이', 'VCP'), ('ㄴ가요', 'EF'), ('?', 'SF')]\n",
      "['알츠하이머병', '증상', '중', '조심', '것']\n"
     ]
    }
   ],
   "source": [
    "#형태소와 품사 태그 추출\n",
    "pos=komoran.pos(text)\n",
    "print(pos)\n",
    "\n",
    "#명사만 추출\n",
    "noun=komoran.nouns(text)\n",
    "print(noun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('알츠하이머병', 'NNP'), ('은', 'JX'), ('치매', 'NNP'), ('를', 'JKO'), ('일으키', 'VV'), ('는', 'ETM'), ('퇴행', 'NNG'), ('성', 'XSN'), ('뇌', 'NNG'), ('질환', 'NNG'), ('이', 'VCP'), ('ㅂ니다', 'EF'), ('.', 'SF'), ('이', 'MM'), ('질병', 'NNP'), ('은', 'JX'), ('서서히', 'MAG'), ('진행', 'NNG'), ('되', 'XSV'), ('며', 'EC'), ('주로', 'MAG'), ('기억력', 'NNG'), ('저하', 'NNP'), ('와', 'JC'), ('성격', 'NNG'), ('변화', 'NNG'), ('등', 'NNB'), ('을', 'JKO'), ('일으키', 'VV'), ('ㅂ니다', 'EF'), ('.', 'SF'), ('알츠하이머병', 'NNP'), ('은', 'JX'), ('아', 'NNP'), ('밀로', 'NNP'), ('이드', 'NNP'), ('와', 'JC'), ('타우', 'NNP'), ('단백질', 'NNP'), ('의', 'JKG'), ('이상', 'NNG'), ('적', 'XSN'), ('이', 'VCP'), ('ㄴ', 'ETM'), ('축적', 'NNG'), ('으로', 'JKB'), ('특징', 'NNG'), ('지', 'VX'), ('어', 'EC'), ('지', 'VX'), ('ㅂ니다', 'EF'), ('.', 'SF'), ('초기', 'NNG'), ('에', 'JKB'), ('는', 'JX'), ('단순', 'XR'), ('하', 'XSA'), ('ㄴ', 'ETM'), ('기억상실', 'NNP'), ('증', 'NNG'), ('으로', 'JKB'), ('시작', 'NNG'), ('하', 'XSV'), ('아', 'EC'), ('혼란', 'NNG'), (',', 'SP'), ('혼란', 'NNG'), (',', 'SP'), ('혼동', 'NNP'), (',', 'SP'), ('혼란', 'NNG'), ('등', 'NNB'), ('의', 'JKG'), ('증상', 'NNG'), ('을', 'JKO'), ('나타내', 'VV'), ('ㅂ니다', 'EF'), ('.', 'SF'), ('병', 'NNG'), ('이', 'JKS'), ('진행', 'NNG'), ('되', 'XSV'), ('면', 'EC'), ('인지', 'NNP'), ('기능', 'NNG'), ('이', 'JKS'), ('저하', 'NNG'), ('되', 'XSV'), ('고', 'EC'), ('기억력', 'NNG'), ('장애', 'NNG'), ('가', 'JKS'), ('생기', 'VV'), ('며', 'EC'), ('성격', 'NNG'), ('변화', 'NNG'), ('도', 'JX'), ('생기', 'VV'), ('ㅂ니다', 'EF'), ('.', 'SF'), ('알츠하이머병', 'NNP'), ('은', 'JX'), ('예방', 'NNP'), ('가능', 'XR'), ('하', 'XSA'), ('ㄴ', 'ETM'), ('퇴행', 'NNG'), ('성', 'XSN'), ('질환', 'NNG'), ('이', 'VCP'), ('며', 'EC'), ('조기', 'NNP'), ('진단', 'NNG'), ('과', 'JC'), ('관리', 'NNG'), ('가', 'JKS'), ('중요', 'XR'), ('하', 'XSA'), ('ㅂ니다', 'EF'), ('.', 'SF'), ('따라서', 'MAJ'), ('치매', 'NNP'), ('가', 'JKS'), ('의심', 'NNG'), ('되', 'XSV'), ('ㄹ', 'ETM'), ('때', 'NNG'), ('는', 'JX'), ('전문가', 'NNG'), ('의', 'JKG'), ('도움', 'NNG'), ('을', 'JKO'), ('받', 'VV'), ('아', 'EC'), ('치매', 'NNP'), ('의', 'JKG'), ('원인', 'NNG'), ('을', 'JKO'), ('확인', 'NNG'), ('하', 'XSV'), ('고', 'EC'), ('적절', 'XR'), ('하', 'XSA'), ('ㄴ', 'ETM'), ('치료', 'NNG'), ('와', 'JC'), ('관리', 'NNG'), ('를', 'JKO'), ('받', 'VV'), ('아야', 'EC'), ('하', 'VX'), ('ㅂ니다', 'EF'), ('.', 'SF')]\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Komoran\n",
    "\n",
    "komoran = Komoran()\n",
    "text = answer[900]\n",
    "pos = komoran.pos(text)\n",
    "\n",
    "print(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('우리', 'NP'), ('챗봇은', 'NA'), ('*', 'SW'), ('*', 'SW'), ('엔', 'NNB'), ('엘', 'NNP'), ('피', 'NNG'), ('*', 'SW'), ('*', 'SW'), ('를', 'JKO'), ('좋아하', 'VV'), ('아', 'EC')]\n"
     ]
    }
   ],
   "source": [
    "komoran = Komoran(userdic = './user_dic.tsv')\n",
    "text = \"우리 챗봇은 **엔엘피**를 좋아해\"\n",
    "pos = komoran.pos(text)\n",
    "\n",
    "print(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def all_data():\n",
    "#     question_path = './training/원천데이터/질문/알츠하이머병'\n",
    "#     answer_path = './training/원천데이터/답변/알츠하이머병'\n",
    "#     q_data=glob.glob(question_path + '/*/*.json')\n",
    "#     a_data=glob.glob(answer_path + '/*/*.json')\n",
    "\n",
    "#     return q_data, a_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_data():\n",
    "    question_path = './training/원천데이터/질문/알츠하이머병'\n",
    "    answer_path = './training/원천데이터/답변/알츠하이머병'\n",
    "\n",
    "    return glob.glob(question_path + '/*/*.json'), glob.glob(answer_path + '/*/*.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'glob'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m q_data,a_data \u001b[38;5;241m=\u001b[39m all_data()\n\u001b[0;32m      2\u001b[0m q_data[\u001b[38;5;241m3\u001b[39m]\n",
      "Cell \u001b[1;32mIn[6], line 5\u001b[0m, in \u001b[0;36mall_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m question_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./training/원천데이터/질문/알츠하이머병\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      3\u001b[0m answer_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./training/원천데이터/답변/알츠하이머병\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m glob\u001b[38;5;241m.\u001b[39mglob(question_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/*/*.json\u001b[39m\u001b[38;5;124m'\u001b[39m), glob\u001b[38;5;241m.\u001b[39mglob(answer_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/*/*.json\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'function' object has no attribute 'glob'"
     ]
    }
   ],
   "source": [
    "q_data,a_data = all_data()\n",
    "q_data[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'q_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(q_data), \u001b[38;5;28mlen\u001b[39m(a_data)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'q_data' is not defined"
     ]
    }
   ],
   "source": [
    "len(q_data), len(a_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fileName': 'HC-Q-0332742', 'participantsInfo': {'participantID': 'QC015', 'gender': '남성', 'age': '50대 이상', 'occupation': '생산/노무직', 'history': False, 'rPlace': '부산/대구/울산/경상'}, 'disease_category': '뇌신경정신질환', 'disease_name': {'kor': '알츠하이머병', 'eng': \"Alzheimer's disease\"}, 'intention': '치료', 'question': '알츠하이머병 치료에는 어떤 방법들이 있는지 자세히 알고 싶어요.', 'entities': [{'id': 0, 'text': '알츠하이머병', 'entity': '질환명', 'position': 0}], 'num_of_words': 8}\n"
     ]
    }
   ],
   "source": [
    "with open(q_data[1000], 'r', encoding='utf-8') as file:\n",
    "    json_data = json.load(file)\n",
    "    print(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['알츠하이머병의 원인으로 매일 소주를 섭취하는 것이 언급되고 있는데, 이에 대한 근거가 있는지 알려주세요.', '알츠하이머병이라는 질병은 유전적 영향을 받는 것인가요?', '알츠하이머병의 발생 원인에 대한 연구나 발견이 진행 중인가요?', '알츠하이머병의 발병과 관련하여 뇌의 노화로 인한 증상과 원인을 알려주세요.', '알츠하이머병의 원인과 관련된 연구 결과가 있을까요? 알려주세요.', '알츠하이머병의 원인은 무엇인가요?', '알츠하이머병이 발생하는 주요 원인은 무엇인가요?', '알츠하이머병 예방을 위해 매일 소주 한 병씩 섭취하는 것이 권장되는 이유가 무엇인가요?', '알츠하이머병과 다른 질병들이 발병하는 원인들에 대해 알려주세요.', '알츠하이머병이 발생하는데 영향을 미치는 주된 요인들은 어떤 것들이 있는지 알려주세요.', '알츠하이머병이 발생하는데에는 어떤 요인들이 영향을 미치나요?', '알츠하이머병과 치매 사이에는 어떠한 연관성이 있을까요?', '알츠하이머병의 원인 중 하나인 뇌의 노화에 대해서 자세히 알려주세요.', '알츠하이머병이 발생하는 주된 원인은 무엇인가요?', '알츠하이머병의 원인에는 가족력, 유전적 요인 이외에 다른 요인들이 있는지 자세히 알려주세요.', '알츠하이머병의 원인에 대해 상세하게 설명해주세요.', '알츠하이머병의 원인과 그에 따른 증상에 대해 알고 싶어요.', '알츠하이머병이 발생하는 주된 원인은 무엇인가요?', '알츠하이머병의 발생과정에서 어떤 요인이 가장 문제가 될 수 있는지 알려주세요.', '알츠하이머병과 관련된 감염균에 대한 정의와 특징을 알 수 있을까요?', '알츠하이머병의 원인이 30대에서 더 쉽게 찾아볼 수 있는 이유가 있나요?', '알츠하이머병의 원인에는 가족력, 유전적 요인 외에 다른 요인들이 있을까요?', '알츠하이머병의 원인과 관련된 다른 원인들을 알려주세요.', '알츠하이머병이 생기는 주된 원인은 무엇인가요?', '알츠하이머병과 다른 노화 현상들 사이에는 어떤 차이점이 있을까요?', '알츠하이머병의 발병 원인과 관련된 주요 요인들은 무엇인가요?', '알츠하이머병이 알츠하이머병의 주요 원인으로 알려져 있나요?', '알츠하이머병이 발생하는데에는 어떤 요인이 영향을 미치나요?', '알츠하이머병이 일어나는 이유와 원인에 대해 알고 싶어요.', '알츠하이머병이 치매와 관련이 있는 원인 중 가장 큰 역할을 하는 것은 무엇인가요?', '매일 소주를 한 병씩 마시는 것이 알츠하이머병의 원인이 될 수 있는지 알고 싶어요.', '알츠하이머병이란 질병이 발생하는 원인에 대해 자세히 설명해주세요.', '알츠하이머병과 노화로 인한 뇌의 노화의 원인과 관련하여 알고 싶습니다.', '알츠하이머병을 확인하기 위해 어떤 의료기관을 방문해야 하나요?', '알츠하이머병의 원인을 설명해주세요.', '알츠하이머병의 원인에 대해 자세한 설명을 듣고 싶어요.', '알츠하이머병의 원인과 관련된 중요한 사항을 알려주세요.', '알츠하이머병의 발병과 관련하여 흔히 언급되는 감염균은 무엇인가요?', '알츠하이머병이라는 질병은 유전적 요인으로 발생하는 질병인가요?', '알츠하이머병 예방을 위한 조치나 예방법은 무엇이 있을까요? 나이로 인한 원인이 알츠하이머병의 원인이 될 수 있을까요?', '알츠하이머병이 젊은 사람에게도 발생하는 원인과 그 원인에 대한 설명을 자세히 해주세요.', '알츠하이머병의 원인에 대해 자세히 알려주세요.', '알츠하이머병의 원인에 대해서 알려주세요.', '알츠하이머병과 매일 소주를 마시는 것 사이에 어떤 연관성이 있는지 알려주세요.', '알츠하이머병의 발생 원인 중에서 노화 이외에 다른 요인도 있는지 알고 싶습니다.', '알츠하이머병과 관련된 원인을 자세히 알려주세요.', '알츠하이머병의 원인이 30대에서 더 많이 나타나는 이유가 있나요?', '알츠하이머병의 원인으로 알려진 노화 이외에 다른 요인이 존재하는지 알려주세요.', '알츠하이머병이 30대에서 더 많이 발생하는 주요 원인은 무엇인가요?', '매일 소주를 한 병씩 마시는 것이 알츠하이머병 발생과 연관이 있는지 알고 싶어요.', '40세 젊은 나이인데, 알츠하이머병이 유전적 요인에 의해 발생할 수 있나요?', '알츠하이머병의 주요 원인은 무엇인가요?', '알츠하이머병이 발생하는 원인과 그에 대한 설명을 해주세요.', '알츠하이머병이 치매를 일으키는 주요 원인은 무엇인가요?', '알츠하이머병의 원인과 관련된 최신 연구결과가 있을까요?', '알츠하이머병이 발생하는데에는 어떤 요인들이 영향을 미치나요?', '알츠하이머병의 원인과 관련하여 어떤 요소들이 가장 중요한 역할을 하는지 알려주세요.', '30대와 40대가 알츠하이머병에 걸리는 원인에 대해 설명해주세요.', '알츠하이머병을 확인하기 위해 어떤 증상이나 신체적인 변화를 주의해야 하나요?', '알츠하이머병의 발병 원인을 알고 싶습니다. 어떤 가설이 있는지 알려주세요.', '알츠하이머병의 원인에 대해 더 자세한 설명을 해주실 수 있나요?', '알츠하이머병의 원인과 관련된 연구나 실험은 있을까요?', '알츠하이머병의 원인에 대해 자세히 알려주세요.', '알츠하이머병의 원인에 대해 설명해주세요.', '알츠하이머병을 진단 받기 위해 어떤 검사 결과를 검토해야 할까요?', '내 머리속에 지우개라는 영화 속에 나오는 알츠하이머병의 원인은 무엇일까요?', '알츠하이머병이 발생하는 주요 원인은 무엇인가요?', '알츠하이머병을 예방하기 위해서는 나이에 따른 원인에 대한 연구가 필요한가요? 나이로 인한 원인이 알츠하이머병의 원인이 될 수 있을까요?', '알츠하이머병의 원인을 예방하거나 관리하기 위해 어떤 조치를 취해야 하나요?', '알츠하이머병은 노화 외에도 다른 원인들이 있을까요?', '알츠하이머병이 발생하는 원인은 무엇인지 자세히 알고 싶어요.', '알츠하이머병의 원인과 이 질병이 발생하는 과정에 대해 알려주세요.', '알츠하이머병이 발병하는 주된 원인은 무엇인가요?', '알츠하이머병과 치매의 관계에 대해 자세히 알려주세요.', '알츠하이머병이 30대에서 더 많이 발생하는 이유가 있을까요?', '알츠하이머병의 원인으로 매일 소주를 섭취하는 것이 언급되고 있는 이유가 있을까요?', '알츠하이머병의 원인과 유전적 요인이 관련이 있는지 알고 싶어요.', '알츠하이머병에 걸릴 수 있는 주된 원인은 무엇인가요?', '알츠하이머병의 원인과 관련된 정보를 자세히 알고 싶어요.', '알츠하이머병의 원인이 무엇인지 알려주세요.', '알츠하이머병과 다른 퇴행성 질병들이 발병하는 원인들이 무엇인지 알려주세요.', '알츠하이머병의 원인과 관련된 연구나 원인에 대한 최근 발견이 있었나요?', '알츠하이머병의 발병 원인과 유전적 요인이 연관되는지 알 수 있을까요?', '알츠하이머병을 진단하기 위해 어떤 검사나 검사 방법을 사용하나요?', '알츠하이머병의 원인과 관련하여, 알츠하이머병의 발병 원인을 자세히 알려주세요.', '알츠하이머병의 원인과 관련하여 추가적인 정보를 알고 싶어요.', '알츠하이머병이 발생하는데 영향을 미치는 요소는 무엇인가요?', '알츠하이머병과 관련된 감염균은 어떤 종류가 있는지 알려주세요.', '알츠하이머병의 원인에 대해 자세히 알려주세요.', '알츠하이머병의 발병과 관련된 감염균에 대해 자세히 설명해주세요.', '알츠하이머병의 원인과 관련된 정보를 알려주세요.', '알츠하이머병의 원인에는 어떤 유전적 요인과 관련이 있을까요?', '알츠하이머병이 치매의 원인으로 알려져 있는 이유를 자세히 알고 싶어요.', '알츠하이머병이 발생하는데 영향을 주는 인자와 그 이유에 대해 설명해주세요.', '알츠하이머병 예방을 위해 매일 소주 한 병씩 섭취하는 것이 어떤 효과가 있을까요?', '알츠하이머병과 기억 장애, 언어 장애의 원인이 서로 다른가요? 어떤 요소가 원인이 되는지 알려주세요.', '알츠하이머병이 발생하는데 영향을 주는 주요한 원인은 무엇인가요?', '알츠하이머병이 유전적인 원인에 의해 발생한다면, 그 원인이 어떤 역할을 하는지 알려주세요.', '알츠하이머병과 치매 사이에는 어떠한 공통점과 차이점이 있는지 알고 싶어요.', '알츠하이머병이라는 질병의 원인은 무엇인가요?', '알츠하이머병의 원인 중에서 노화 외에 다른 요인도 알려주세요.', '알츠하이머병의 원인이 30대에서 더 많이 발생하는 이유가 있나요?', '알츠하이머병이 치매를 일으키는 가장 큰 원인은 무엇인가요?', '알츠하이머병의 원인에 대해 자세한 설명을 해주실 수 있나요?', '알츠하이머병이 발생하는데 영향을 미치는 원인에 대해 알고 싶어요.', '알츠하이머병의 정확한 진단을 받기 위해 어떤 정보를 의료진에게 제공해야 할까요?', '알츠하이머병이 발생하는 주요 원인은 무엇인가요?', '알츠하이머병의 원인과 관련하여 가장 흔히 발생하는 원인은 무엇인가요?', '알츠하이머병을 일으키는 주된 퇴행성 뇌질환은 무엇인가요?', '알츠하이머병이 발생하는데 영향을 미치는 주요 원인은 무엇인가요?', '알츠하이머병이 치매를 일으키는 주요 원인에 대해 설명해주세요.', '알츠하이머병이 발생하는데에는 어떤 원인이 관련되어 있을까요?', '알츠하이머병의 원인과 관련된 연구나 주장이 있는지 알고 싶습니다.', '알츠하이머병이 치매와 다른 점은 무엇인가요?', '알츠하이머병의 원인과 이 질병이 발생하는데 어떤 요인들이 관련되는지 알고 싶어요.', '알츠하이머병의 발생에는 어떤 요인들이 관여되나요?', '알츠하이머병과 치매는 어떤 점에서 유사한가요?', '알츠하이머병과 치매의 원인과 관련된 다른 요인들이 있을까요?', '알츠하이머병의 원인에 대해 더 자세히 설명해주실 수 있을까요?', '알츠하이머병이 나이가 들면서 발생하는 이유가 무엇인가요?', '알츠하이머병의 원인과 관련된 정보를 알려주세요.', '알츠하이머병의 원인에는 어떤 요소들이 관여하는 건가요?', '내 머리속에 지우개라는 영화 속에 나오는 알츠하이머병이 어떤 원인으로 발생하는지 알려주세요.', '알츠하이머병이 노인에게서 주로 발생하는 이유에 대해 자세히 설명해주세요.', '알츠하이머병의 정확한 정의와 원인을 알려주세요.', '알츠하이머병이 발생하는데 영향을 미치는 원인은 무엇인가요?', '알츠하이머병과 기억 장애, 언어 장애의 발생 원인에 대해 알고 싶어요. 어떤 것들이 서로 다른 원인으로 작용하는 건가요?', '알츠하이머병과 노화로 인한 뇌의 노화의 원인을 자세히 알고 싶어요.', '알츠하이머병의 원인과 관련된 원인을 알려주세요.', '알츠하이머병의 원인은 무엇인가요?', '알츠하이머병이 발병하는데 영향을 미치는 주요 원인은 무엇인가요?', '알츠하이머병이 가족력이 있는 사람들에게 더 자주 발생하는 이유가 있을까요?', '40세 젊은 나이에 알츠하이머병을 진단받았는데, 이는 유전적인 요인이 있을까요?', '알츠하이머병이 어떻게 발생하는지 알려주세요.', '알츠하이머병이 발생하는 주요한 원인은 무엇인가요?', '알츠하이머병이 발생하는 원인에 대해 설명해주세요.', '알츠하이머병 예방을 위해 매일 소주 한 병씩 섭취하는 것이 예방 효과가 있을까요?', '알츠하이머병이 주로 젊은 사람에게도 발생하는 원인은 무엇인가요? 그 원인을 알고 싶어요.', '알츠하이머병의 원인에 대해 자세히 알고 싶어요.', '알츠하이머병의 발병 원인에는 가족력, 유전적 요인 외에 어떤 다른 요인들이 있는지 궁금합니다.', '기억 장애와 언어 장애는 알츠하이머병과 관련이 있을까요? 이 질병의 원인은 무엇인가요?', '알츠하이머병이 40세 젊은 나이에 발병하는 원인은 무엇인가요? 유전적인 영향이 있을까요?', '알츠하이머병의 원인에 대해 더 알고 싶어요. 어떤 연구나 발견이 있었나요?', '알츠하이머병의 원인과 관련하여 최신 연구나 동향이 있을까요?', '알츠하이머병이 발생하는 이유를 설명해주세요.', '알츠하이머병의 원인과 유전적 요인 사이에는 어떤 연관성이 있을까요?', '알츠하이머병을 예방하기 위해 매일 소주 한 병씩 섭취하는 것이 좋을까요?', '알츠하이머병과 노화로 인한 뇌의 노화의 원인을 비교해서 알려주세요.', '알츠하이머병을 예방하기 위해 어떤 예방 수단이 효과적일까요? 나이로 인한 원인이 알츠하이머병의 원인이 될 수 있을까요?', '알츠하이머병과 관련하여 최근의 주요 원인은 무엇인가요?', '알츠하이머병과 기억 장애, 언어 장애의 원인과 증상이 서로 다른가요? 어떤 요소가 원인이 되는지 자세히 알려주세요.', '알츠하이머병이 발생하는데 연령과의 관계가 있을까요?', '알츠하이머병의 원인은 노화 이외에도 어떤 것들이 있는지 알려주세요.', '알츠하이머병이라는 질병의 발생 원인은 무엇인가요?', '알츠하이머병의 원인과 관련된 연구 결과는 어떤 것들이 있을까요?', '알츠하이머병이 30대에서 더 쉽게 볼 수 있는 이유에 대해서 설명해주세요.', '알츠하이머병의 원인을 이해하는데 도움이 될만한 정보를 알려주세요.', '알츠하이머병과 관련된 감염균의 종류와 특징을 알고 싶어요.', '매일 소주를 한 병씩 마시는 것이 알츠하이머병의 원인으로 어떤 영향을 미칠 수 있는지 알고 싶어요.', '알츠하이머병은 왜 발생하는 건가요?', '알츠하이머병은 어떤 요인에 의해 발병하게 되는 질병인가요?', '알츠하이머병의 원인에는 어떤 요인들이 작용하나요?', '알츠하이머병이 발생하는 주요 원인은 무엇인가요?', '알츠하이머병의 발병 원인과 관련된 최근 연구 결과를 알고 싶습니다.', '알츠하이머병 예방을 위해 매일 소주 한 병씩 섭취하는 것이 어떻게 도움이 될까요?', '알츠하이머병에 걸릴 만한 특별한 원인이 있는지 알려주세요.', '알츠하이머병의 원인으로 매일 소주를 섭취하는 것이 언급되고 있는데, 그 이유에 대해 설명해주세요.', '알츠하이머병의 원인에 대해 알고 싶습니다.', '알츠하이머병이 발생하는 이유와 관련하여 최근 연구나 발견된 사실이 있나요?', '알츠하이머병의 원인과 관련된 중요한 요소는 무엇인가요?', '알츠하이머병의 원인과 관련된 연구나 이론이 있나요?', '알츠하이머병의 원인과 관련하여 유전적 요인에 대해 설명해주실 수 있나요?', '알츠하이머병과 노화로 인한 뇌의 노화의 원인에 대해 더 자세한 설명을 듣고 싶습니다.', '알츠하이머병이 치매의 주요 원인 중 하나로 알려져 있는지 알려주세요.', '알츠하이머병의 발생 원인과 관련된 정보를 알려주세요.', '알츠하이머병과 기억 장애, 언어 장애의 발생 원인이 다른가요? 어떤 이유로 인해 발생하는 건가요?', '알츠하이머병이 발생하는 원인에 대한 최근 연구나 발견의 가능성은 있나요?', '알츠하이머병 예방을 위해서는 나이로 인한 요인에 대한 연구나 조사가 필요한가요? 나이로 인한 원인이 알츠하이머병의 원인이 될 수 있을까요?', '알츠하이머병과 관련된 주요 원인과 관련된 사항을 알려주세요.', '알츠하이머병이 발생하는 주요한 원인은 무엇인가요?', '알츠하이머병이 발생하는 주요 원인은 무엇인가요?', '알츠하이머병의 원인에 대해 자세한 설명을 듣고 싶어요.', '알츠하이머병과 기억 장애, 언어 장애의 원인과 증상이 서로 다른가요? 어떤 요소가 원인이 되어 발생하는지 자세히 알려주세요.', '알츠하이머병이 치매를 일으키는데에 가장 큰 원인은 무엇인가요?', '알츠하이머병의 원인과 관련된 요인이 무엇인지 궁금합니다.', '알츠하이머병이 어떤 원인으로 인해 발생하는지 알려주세요.', '알츠하이머병이 발생하는데에 어떤 요소들이 영향을 미치는지 알려주세요.', '알츠하이머병의 원인과 관련된 정보를 알려주세요.', '알츠하이머병의 발병 원인은 어떤 것들인지 알려주세요.', '알츠하이머병과 관련된 감염균은 어떤 원리로 발병하는 건가요?', '알츠하이머병이 30대와 40대에서 많이 발생하는 이유가 무엇인가요?', '알츠하이머병의 원인으로 매일 소주를 섭취하는 것이 언급되고 있는데, 이에 대한 조사가 필요한가요?', '알츠하이머병이 생기는 원인을 알려주세요.', '알츠하이머병의 원인과 관련된 중요한 사항을 알려주세요.', '알츠하이머병의 발생과정에서 가장 큰 영향을 주는 원인은 무엇인가요?', '알츠하이머병과 관련된 감염균은 어떤 것들이 있는지 알려주세요.', '알츠하이머병을 유발하는 감염균으로 알려진 감염균은 무엇인가요?', '알츠하이머병 발생의 주요 원인은 무엇인가요?', '알츠하이머병의 발생 원인 중에서 노화로 인한 뇌의 노화와 관련된 것은 무엇인가요?', '알츠하이머병에 대한 원인에 대해서 자세히 알려주세요.', '알츠하이머병 예방을 위해 매일 소주 한 병씩 섭취하는 것이 권장되는 이유가 있나요?', '알콜을 섭취하면 알츠하이머병이 발생할 수 있는 원인이 될 수 있을까요?', '알츠하이머병이 치매를 일으키는 주요 원인을 알려주세요.', '알츠하이머병에 대한 원인과 관련된 연구나 이론이 있는지 알려주세요.', '알콜을 매일 한 병씩 섭취할 경우, 알츠하이머병이 발생할 수 있는 원인이 될 수 있는지 알려주세요.', '가족력이 알츠하이머병의 발병에 영향을 미칠 수 있는 원인으로 알려져 있나요?', '알츠하이머병이 주로 발생하는 원인은 어떤 것이 있고, 이에 대한 원인은 어떤 것이 있는지 궁금합니다.', '알츠하이머병을 확인하기 위한 검사 방법이 있을까요?', '알츠하이머병이 발생하는 주요 원인은 무엇인가요?', '알츠하이머병의 원인과 관련된 정보를 알고 싶어요.', '알츠하이머병의 원인과 관련된 최신 연구 결과는 있나요?', '기억 장애와 언어 장애의 발생 원인이 서로 다를 수 있을까요? 그렇다면 어떤 원인이 다른 원인과 비교하여 더 큰 차이가 있는 건가요?', '알츠하이머병이 발생하는데에는 어떤 원인들이 주요 역할을 하는 건가요?', '알츠하이머병이 발생하는데 영향을 주는 주요한 요소는 무엇인가요?', '알츠하이머병의 원인은 알려져 있나요?', '알츠하이머병의 원인이 무엇인지 상세히 알려주세요.', '알츠하이머병의 발생과정에서 어떤 요인이 문제가 되는지 알려주세요.', '40세 젊은 나이에 알츠하이머병 진단을 받았는데, 그 원인이 유전적 요인인가요?', '나이로 인해 알츠하이머병이 발생하는 원인이 있을까요?', '알츠하이머병이 발생하는 주요한 원인은 무엇인가요?', '알츠하이머병이 발생하는데에는 어떤 환경적인 요인들이 관련되나요?', '알츠하이머병이 주로 노인에게 발생하는 이유는 무엇인가요? 그 원인에 대해 알려주세요.', '알츠하이머병의 원인과 그 영향에 대해 알려주세요.', '알츠하이머병이 생기는 원인과 관련된 자세한 설명을 해주실 수 있을까요?', '알츠하이머병이 발생하는 가장 일반적인 원인은 무엇인가요?', '알츠하이머병의 원인과 관련된 정보를 알고 싶습니다.', '알츠하이머병의 발생 원인에 대한 연구나 발견을 통해 어떻게 해석할 수 있을까요?', '알츠하이머병의 발병 원인에는 가족력, 유전적 요인 외에 다른 요소들이 있는지 알려주세요.', '알츠하이머병이 발생하는 원인에 대해 자세한 내용을 알려주세요.', '알츠하이머병의 원인과 관련된 중요한 연구나 이론이 있는지 알고 싶습니다.', '알츠하이머병이 알츠하이머병의 원인으로 알려진 이유가 무엇인가요?', '알츠하이머병의 원인을 자세히 알려주세요.', '알츠하이머병이 주로 발생하는 원인은 무엇이며, 이에 대한 원인은 어떤 것이 있는지 알려주세요.', '알츠하이머병이 왜 발생하는지 원인을 알 수 있을까요?', '알츠하이머병이 치매를 일으키는 이유와 원인에 대해 알고 싶어요.', '알츠하이머병의 원인을 정확히 알 수 있을까요? 어떤 요인이 알츠하이머병의 원인이 될까요?', '알츠하이머병이 30대에서 더 많이 발생하는 원인에 대해서 알려주세요.', '알츠하이머병의 원인에는 가족력, 유전적 요인 이외에 다른 요인들이 있는지 알 수 있을까요?', '알츠하이머병의 주요 원인은 무엇인가요?', '알츠하이머병을 유발하는 특정 감염균에는 어떤 것들이 있나요?', '알츠하이머병을 일으키는 감염균이 있는지 알고 싶어요.', '알츠하이머병이라는 질병의 발생 원인에 대해 알려주세요.', '알츠하이머병의 원인으로 치매가 알려져 있는데, 이에 대해 자세히 알고 싶어요.', '알츠하이머병이라는 질병이 가족력이 있는 사람에게 더 자주 발생하는 건가요?', '알츠하이머병이 발생하는 주요한 원인은 무엇인가요?', '알츠하이머병의 원인과 관련하여 자세한 설명을 해주세요.', '알츠하이머병이 발생하는 주요 원인은 무엇인가요?', '기억 장애와 언어 장애의 원인과 증상은 서로 다를 수 있는 건가요? 알츠하이머병과 관련하여 어떤 차이가 있는지 알려주세요.', '알츠하이머병은 어떤 원인으로 발생하는지 알고 싶어요.', '알츠하이머병이 발생하는 원인은 무엇인가요?', '알츠하이머병이 가족력이 있는 사람에게 더 자주 발생하는 이유는 무엇인가요?', '알츠하이머병이 발생하는데 영향을 미치는 요인이 무엇인가요?', '알츠하이머병의 원인과 관련된 최신 연구나 이론이 있나요?', '알츠하이머병의 원인과 관련된 중요한 요인은 무엇인가요?', '알츠하이머병이 발생하는 원인과 관련된 정보를 알고 싶습니다.', '알츠하이머병의 발생 원인을 알고 싶어요.', '알츠하이머병의 정확한 원인은 무엇인가요?', '알츠하이머병이 알츠하이머병의 원인으로 알려져 있는데, 그 이유에 대해 자세히 알고 싶어요.', '알츠하이머병이 발생하는데에 소주 섭취가 연관되어 있을 수 있는지 알려주세요.', '알츠하이머병 예방을 위해 매일 소주 한 병씩 섭취하는 것이 바람직한 이유가 무엇인가요?', '알츠하이머병의 원인에는 어떤 가족력, 유전적 요인 이외에 다른 요소들이 있는지 알고 싶어요.', '알츠하이머병의 원인이 알려지지 않았을 때, 어떤 이론이 주로 제기되나요?', '알츠하이머병이 발생하는데에는 어떤 요소들이 관여하나요?', '알츠하이머병을 진단 받기 위해 어떤 종류의 병원이나 의사를 찾아야 하나요?', '알츠하이머병이 발생하는 다양한 원인들에 대해서 설명해주세요.', '알츠하이머병과 관련하여 매일 소주 한 병씩 섭취하는 것이 원인이 될 수 있는지 알려주세요.', '알츠하이머병을 예방할 수 있는 방법은 있을까요? 나이로 인한 원인이 알츠하이머병의 원인이 될 수 있을까요?', '30대와 40대가 알츠하이머병에 걸리는 이유가 무엇인가요?', '알츠하이머병이 발생하는 주요 원인과 관련된 정보를 알고 싶어요.', '알츠하이머병이 발생하는데에는 어떤 환경적인 요인이 연관되나요?', '알츠하이머병의 원인에 대해 자세히 알려주세요.', '알츠하이머병이 치매를 일으키는 주된 원인으로 알려진 이유는 무엇인가요?', '알츠하이머병이 발생하는 주요 원인에 대해 자세히 알려주세요.', '알츠하이머병이 발생하는데에는 어떤 요소들이 영향을 미치나요?', '알츠하이머병의 원인을 자세히 알려주세요.', '알츠하이머병의 원인으로 알려진 요인들이 어떤 것이 있는지 알고 싶어요.', '알츠하이머병이 30대와 40대에서 많이 발생하는 이유가 무엇인가요?', '알츠하이머병이 젊은 사람에게도 자주 발생하는 이유는 무엇인가요? 그 원인에 대해 알려주세요.', '알츠하이머병이 일어나는 정확한 원인은 무엇인가요?', '알츠하이머병의 원인과 관련된 정보를 자세히 알고 싶어요.', '알츠하이머병이 젊은 사람에게도 발생하는 주요한 원인이 무엇인가요? 그 원인을 알려주세요.', '알츠하이머병이 발생하는데 영향을 미치는 원인은 어떤 것들이 있을까요?', '알츠하이머병의 정확한 원인은 무엇인가요?', '알츠하이머병의 원인에는 가족력, 유전적 요인 외에 다른 요인이 있을까요?', '알츠하이머병의 발병 원인과 관련된 다른 원인들에 대해 알려주세요.', '알츠하이머병의 원인과 관련된 연구나 이론이 있을까요?', '알츠하이머병의 발생과정에 어떤 요소들이 기여하는지 알려주세요.', '알츠하이머병 발병과 관련하여 뇌의 노화에 대한 상세한 정보를 알고 싶어요.', '알츠하이머병의 원인이 무엇인지 알 수 있을까요?', '알츠하이머병이 발생하는데에는 어떤 유전적인 요인들이 관여하나요?', '알츠하이머병의 원인은 어떻게 작용하는지 알고 싶어요.', '알츠하이머병이 치매와 관련하여 가장 큰 원인 중 하나로 알려져 있나요?', '알츠하이머병에 걸린 사람이 어떻게 진단을 받게 되나요?', '알츠하이머병의 원인은 무엇인가요?', '40세 젊은 나이인데, 알츠하이머병에 대해 유전적 요인이 있는지 확인할 수 있는 방법이 있을까요?', '알츠하이머병의 원인이 무엇인지 알고 싶습니다.', '알츠하이머병에 대해서 알려주세요.', '알츠하이머병에 관한 기본적인 정보를 알려주세요.', '알츠하이머병과 치매의 차이를 설명해주세요.', '알츠하이머병의 정확한 정의와 특징을 알려주세요.', '알츠하이머병의 정의와 특징을 자세히 알려주세요.', '알츠하이머병에 대해 정확한 정의를 알고 싶어요.', '알츠하이머병이란 무엇을 의미하는 질병인가요?', '알츠하이머병이란 무엇을 의미하는 용어인가요?', '알츠하이머병에 대해서 알고 싶습니다. 어떤 질병인가요?', '알츠하이머병이 노화로 인해 생기는 질병인가요?', '알츠하이머병의 핵심적인 정의와 특징을 알려주세요.', '알츠하이머병의 정의와 증상을 알고 싶어요.', '알츠하이머병의 핵심적인 특징과 정의는 무엇인가요?', '알츠하이머병에 대해 자세한 설명을 들을 수 있을까요?', '알츠하이머병과 관련된 상세한 정의를 알고 싶어요.', '파킨슨병과 알츠하이머병이라는 용어는 어떤 차이점을 가지고 있나요?', '알츠하이머병이라는 질병은 어떤 것을 의미하는 건가요?', '알츠하이머병이란 무엇을 의미하는 질병인가요?', '알츠하이머병이라는 병이 무엇을 의미하는지 자세히 설명해주실 수 있나요?', '알츠하이머병에 대해 자세한 정의와 특성을 알려주세요.', '파킨슨병과 알츠하이머병의 정확한 차이를 설명해주세요.', '알츠하이머병이란 질환은 어떤 사람들이 자주 걸리는 질환인가요? 우리가 흔히 아는 치매와는 다른가요?', '알츠하이머병이란 정확한 정의를 알 수 있을까요?', '알츠하이머병이 어떤 증상을 가지고 있는지 알려주세요.', '알츠하이머병이란 어떤 원인으로 발생하는 질병인가요?', '알츠하이머병이란 질병의 정의와 특징은 무엇인가요?', '알츠하이머병의 정의와 특징을 자세히 알려주세요.', '알츠하이머병과 치매의 차이점을 알려주세요.', '알츠하이머병은 어떤 병인가요? 그리고 알츠하이머병이라는 질병은 어떻게 정의되나요?', '알츠하이머병에 대해 상세한 설명을 듣고 싶습니다.', '알츠하이머병이란 정확히 무엇을 의미하는 건가요?', '노화성 질환인 알츠하이머병과 노화가 서로 관련이 있는 것인가요?', '알츠하이머병이란 무엇인지 자세하게 설명해주실 수 있나요?', '알츠하이머병에 대해 상세한 설명을 듣고 싶어요.', '알츠하이머병이라는 용어의 의미와 그 정의를 알려주세요.', '알츠하이머병의 정확한 정의와 특성을 알려주세요.', '알츠하이머병이란 정확히 어떤 질병을 의미하는 건가요?', '알츠하이머병에 대한 정의를 알려주세요.', '알츠하이머병의 핵심적인 정의와 특성을 알고 싶습니다.', '알츠하이머병이란 질환은 어떤 기준으로 정의되는지 궁금합니다. 알츠하이머병에 대한 정확한 정의를 알려주세요.', '알츠하이머병이 치매와 같은 의미를 갖는 질병인가요?', '알츠하이머병이라는 질병은 치매와는 어떻게 다른가요?', '알츠하이머병이란 어떤 종류의 뇌신경 질환인가요? 치매와 비교해 설명해주세요.', '알츠하이머병이란 어떤 질병을 의미하는 건가요?', '알츠하이머병의 정의와 증상은 어떻게 되는지 알려주세요.', '알츠하이머병이라는 질환은 무엇인가요? 우리가 흔히 아는 치매와 같은 건가요?', '파킨슨병과 알츠하이머병의 차이점과 주요 특성을 알려주세요.', '알츠하이머병과 치매의 차이점을 알고 싶어요.', '알츠하이머병이란 어떤 원인으로 인해 발생하는 질병인가요?', '나이가 들면 발생하는 치매와 알츠하이머병을 정확히 구분할 수 있을까요?', '알츠하이머병이라는 질환에 대한 정확한 정의를 알려주세요.', '알츠하이머병이라는 용어가 치매와 같은 의미를 가지고 있는 건가요?', '알츠하이머병의 정의와 특성에 대해서 자세한 설명을 듣고 싶어요.', '알츠하이머병과 치매는 어떤 점에서 유사한가요?', '알츠하이머병이란 무엇인지 자세히 설명해주실 수 있나요?', '알츠하이머병은 치매와 어떻게 다른지 알려주세요.', '알츠하이머병이라는 질병은 어떤 원인으로 발생하는 건가요?', '나이가 들면 알츠하이머병이 발생하는 병인가요?', '알츠하이머병이란 정확한 명칭은 무엇인가요? 이 질환은 어떤 증상을 가지고 있는 건가요?', '알츠하이머병에 대해 자세한 설명을 들을 수 있을까요?', '알츠하이머병에 대해 자세한 설명을 해주실 수 있을까요?', '파킨슨병과 알츠하이머병의 정의와 치료 방법에 대해서 알고 싶어요.', '알츠하이머병에 대한 핵심적인 정의와 특징을 알려주세요.', '알츠하이머병의 핵심적인 정의와 특성을 알려주세요.', '알츠하이머병에 대한 핵심적인 정의와 예방 방법은 무엇인가요?', '파킨슨병과 알츠하이머병의 정의와 원인에 대해 자세히 알고 싶어요.', '알츠하이머병에 대해 자세히 알려주세요.', '알츠하이머병이란 무엇을 의미하는 질병인가요?', '알츠하이머병은 어떤 원인으로 발생하는 질환인가요? 알츠하이머병의 정의와 특성을 알고 싶어요.', '알츠하이머병은 어떤 원인으로 인해 발생하는 질병인가요? 자세한 설명을 듣고 싶어요.', '알츠하이머병은 어떤 특징을 가지는 질병인가요?', '알츠하이머병이란 정확히 무엇을 의미하는 건가요?', '알츠하이머병에 대해 자세히 알고 싶습니다.', '파킨슨병과 알츠하이머병은 서로 다른 증상을 보이는 데 어떤 점에서 차이가 있나요?', '알츠하이머병의 정확한 정의와 주요 증상을 알려주세요.', '알츠하이머병에 대한 기본적인 정보를 알려주세요.', '알츠하이머병의 핵심적인 정의와 특성은 무엇인가요?', '알츠하이머병은 치매와 어떻게 구별될까요?', '알츠하이머병이란 어떤 증상을 보이는 질병인가요?', '알츠하이머병은 어떤 원인으로 인해 발생하는 질병인가요?', '알츠하이머병이란 어떤 원인으로 발생하는 질병인가요?', '알츠하이머병이라는 질병에 대한 상세한 정보를 알려주세요.', '파킨슨병과 알츠하이머병은 서로 어떤 점에서 다른 질병인가요?', '알츠하이머병과 노망은 다른 병인인가요?', '알츠하이머병은 어떤 경우에 발생하는 질병인가요?', '알츠하이머병의 핵심적인 정의와 진단 방법은 무엇인가요?', '알츠하이머병이란 어떤 종류의 질병을 말하는 건가요?', '알츠하이머병이란 질병의 정의와 특징을 알려주세요.', '알츠하이머병이란 무엇인지 자세히 알려주세요.', '알츠하이머병의 정의와 특성은 어떻게 되는지 알려주세요.', '알츠하이머병이 치매와 어떤 차이가 있는 질병인가요?', '알츠하이머병은 어떤 질병을 의미하는 건가요?', '파킨슨병과 알츠하이머병이라는 용어의 차이점을 자세히 알고 싶어요.', '파킨슨병과 알츠하이머병의 의미와 특징은 무엇인가요?', '알츠하이머병에 대한 자세한 설명을 듣고 싶어요.', '알츠하이머병이란 무엇을 의미하는 질병인가요?', '알츠하이머병이 치매와 어떤 관련이 있는 질병인가요?', '알츠하이머병의 정확한 정의를 알려주세요.', '알츠하이머병이라는 질병은 어떤 원인으로 발생하는 건가요?', '알츠하이머병에 대해 더 자세히 알고 싶어요.', '알츠하이머병과 치매의 차이점과 공통점을 알려주세요.', '파킨슨병과 알츠하이머병의 차이점과 주요 증상에 대해 알려주세요.', '알츠하이머병은 치매와 관련이 있는 것인가요? 어떤 증상이 나타날 수 있는지 알려주세요.', '알츠하이머병에 대한 기본적인 설명과 특성을 알려주세요.', '알츠하이머병이 노망과 비슷한 노화성 질환이라고 할 수 있나요?', '알츠하이머병은 어떤 식으로 증상이 나타나는 질병인가요?', '알츠하이머병에 대한 상세한 설명을 해주세요.', '알츠하이머병에 대해 더 자세한 정보를 알고 싶어요.', '알츠하이머병이란 정확하게 어떤 질병을 의미하는 건가요?', '알츠하이머병과 노망이 정확히 같은 증상인가요?', '알츠하이머병이라는 질병은 노화로 인해 생기는 것인가요?', '알츠하이머병은 어떤 종류의 치매인가요? 그리고 알츠하이머병이 발생하는 원인은 무엇인가요?', '알츠하이머병이라는 용어의 의미와 정의를 알려주세요.', '알츠하이머병에 대한 정의와 증상을 알고 싶습니다.', '알츠하이머병이란 어떤 질병을 의미하는 건가요?', '알츠하이머병의 정의와 증상에 대해 자세히 알고 싶어요.', '알츠하이머병에 대한 핵심적인 정의와 증상을 알려주세요.', '알츠하이머병의 정확한 정의와 증상을 알고 싶어요.', '알츠하이머병에 대해 자세한 설명을 해주실 수 있나요?', '알츠하이머병과 노망이 정확하게 동일한 질병인가요?', '알츠하이머병은 어떤 특징을 가지고 있나요? 우리가 흔히 알고 있는 치매와는 다른가요?', '파킨슨병과 알츠하이머병의 정의와 증상은 어떻게 다른가요?', '알츠하이머병이라는 용어가 정확히 무엇을 의미하는지 알려주세요.', '알츠하이머병이란 질환은 어떤 것을 의미하는 건가요?', '알츠하이머병의 정의와 증상에 대해서 알고 싶어요.', '알츠하이머병의 정확한 정의와 진단 기준은 무엇인가요?', '알츠하이머병이라는 병은 어떤 것을 의미하는 건가요?', '알츠하이머병이 주로 어떤 연령대에서 발생하는지 알려주세요.', '알츠하이머병의 정확한 의미와 특성을 알려주세요.', '알츠하이머병에 대해 자세한 설명을 해주실 수 있나요?', '알츠하이머병에 대해 정확히 정의해주실 수 있을까요?', '알츠하이머병과 치매는 어떤 면에서 다른가요?', '알츠하이머병의 정확한 정의와 그 정의가 나타나는 원인을 알려주세요.', '알츠하이머병이란 무엇을 의미하는 질병인가요?', '파킨슨병과 알츠하이머병의 정의와 원인에 대해 알고 싶어요.', '나이가 들면서 생기는 노망과 알츠하이머병은 같은 증상인가요?', '파킨슨병과 알츠하이머병의 주요 차이점을 알려주세요.', '알츠하이머병이라는 질병은 정확히 무엇인가요?', '알츠하이머병에 대한 기본적인 정보를 알려주세요.', '알츠하이머병의 정의와 특징을 알려주세요.', '알츠하이머병의 정의와 증상에 대해 자세히 알려주세요.', '파킨슨병과 알츠하이머병의 차이에 대해 자세한 설명을 듣고 싶어요.', '알츠하이머병에 대해 자세히 설명해주세요.', '알츠하이머병의 정의와 특징을 알려주세요.', '알츠하이머병이라는 질병은 어떤 것을 의미하나요?', '알츠하이머병은 어떤 방식으로 진행되는 질병인가요?', '파킨슨병과 알츠하이머병의 정확한 정의와 원인에 대해 알려주세요.', '알츠하이머병과 관련된 정의와 증상에 대해 알려주세요.', '파킨슨병과 알츠하이머병은 어떤 연관성이 있는지 자세히 알려주세요.', '알츠하이머병이 치매와 어떻게 같은 의미로 사용되는지 알고 싶어요.', '알츠하이머병이란 어떤 원인으로 발생하는 질병인가요?', '알츠하이머병이란 무엇인지 정확하게 알려주세요.', '알츠하이머병에 대해 자세히 설명해주실 수 있나요?', '알츠하이머병에 관한 정의와 특성을 자세히 알려주세요.', '알츠하이머병이 노망과 같은 증세를 가지고 있는 것이 맞나요?', '알츠하이머병에 대한 정의와 특성을 알고 싶어요.', '알츠하이머병의 정확한 정의와 진단에 대해 알려주세요.', '파킨슨병과 알츠하이머병은 어떤 원인으로 발생하는지 알려주세요.', '알츠하이머병은 어떤 증상들을 유발하는 질병인가요?', '알츠하이머병이라는 용어의 정확한 의미를 알 수 있을까요?', '알츠하이머병이 나이가 들면 발생하는 병인가요?', '알츠하이머병이라는 질병은 어떤 형태로 발생하는 것인가요? 알츠하이머병의 정의와 진단 방법에 대해 알려주세요.', '알츠하이머병에 대한 기본적인 설명을 해주실 수 있을까요?', '파킨슨병과 알츠하이머병의 정확한 정의와 차이에 대해 설명해주세요.', '알츠하이머병에 대해 더 자세한 내용을 알고 싶어요.', '알츠하이머병이란 질병의 핵심적인 정의와 특성은 무엇인가요?', '알츠하이머병에 대한 상세한 설명을 들을 수 있을까요?', '알츠하이머병이란 무엇을 의미하는 질병인가요?', '알츠하이머병이라는 질병의 정확한 정의를 알려주세요.', '알츠하이머병이란 무엇인지 자세히 설명해주세요.', '알츠하이머병의 정확한 의미와 증상을 알고 싶어요.', '알츠하이머병의 핵심적인 특징과 정의를 알고 싶어요.', '알츠하이머병의 정확한 정의를 알려주세요.', '알츠하이머병과 관련하여 기억력 감퇴와 단어가 잘 떠오르지 않는 증상이 일상 생활에서 어떤 영향을 미치나요?', '알츠하이머병의 주요 증상에 대해 자세히 알고 싶어요.', '알츠하이머병의 주요 증상에 대해 자세히 알려주세요.', '알츠하이머병 환자가 증상을 인지하는 방법이 있나요?', '알츠하이머병의 정확한 정의가 무엇인가요?', '알츠하이머병의 증상 중에서 특히 주의해야 할 것은 무엇인가요?', '알츠하이머병의 주요 증상 중에서 가장 흔히 나타나는 것은 무엇인가요?', '알츠하이머병의 주요 증상과 특징에 대해 자세히 설명해주실 수 있나요?', '알츠하이머병의 증상과 진단 방법에 대해 자세하게 알려주세요.', '알츠하이머병으로 인해 나타나는 대표적인 증상은 어떤 것들이 있나요?', '알츠하이머병의 증상이 심각하다면 어떤 종류의 의료 검사가 필요한가요?', '알츠하이머병의 증상과 특징에 대해 알려주세요.', '알츠하이머병의 주요 증상과 관련된 정보를 알려주세요.', '알츠하이머병과 치매는 어떻게 다른 병인지 자세히 알려주세요.', '알츠하이머병 초기 단계에서 보이는 대표적인 초기 증상은 무엇인가요?', '알츠하이머병의 주요 증상은 무엇인가요?', '기억상실증 외에 다른 증상들이 있는지 궁금합니다.', '알츠하이머병의 증상들은 어떤 특징을 가지고 있나요?', '알츠하이머병과 치매는 서로 다른 증상을 보이는 질병인가요?', '알츠하이머병의 초기 증상 중에서 기억력 문제가 아니라 다른 증상이 있는지 알려주세요.', '알츠하이머병에 걸렸을 때 일반인이 보이는 증상 중에서 가장 흔한 것은 무엇인가요?', '알츠하이머병 진단을 받는데 얼마나 시간이 걸리는지 알려주세요.', '알츠하이머병의 대표적인 증상들은 무엇인가요?', '알츠하이머병의 주요 증상은 무엇인가요?', '알츠하이머병의 증상 중 가까운 기억들의 기억력이 저하되는 것이 일반적인가요?', '알츠하이머병으로 진단 받을 수 있는지 알려주세요.', '알츠하이머병의 증상을 정의해주시고, 그 특징적인 증상들을 알려주세요.', '알츠하이머병의 증상 중에서 가장 흔한 것은 무엇인가요?', '알츠하이머병이란 정확하게 무엇을 의미하는 질병인가요?', '알츠하이머병과 관련하여 기억력 감퇴와 단어가 잘 떠오르지 않는 증상이 치매에 대한 정보와 관련이 있는지 알려주세요.', '할머니의 기억력 감퇴와 기억력 저하는 어떤 증상을 동반하는 건가요?', '알츠하이머병의 증상 중에서 특히 조심해야 할 것은 무엇인가요?', '알츠하이머병과 치매는 어떻게 구분되는 질병인가요?', '알츠하이머병과 치매는 어떤 병들인지 자세히 알려주세요.', '알츠하이머병의 초기 증상 중에서 기억력 문제 이외에 다른 증상이 있는지 알려주세요.', '알츠하이머병의 특징적인 증상은 어떤 것들이 있는지 알고 싶어요.', '알츠하이머병의 초기 증상이 무엇인지 자세히 알고 싶어요.', '알츠하이머병에 걸렸을 때 일반인이 알 수 있는 주요 증상은 무엇인가요?', '알츠하이머병과 가까운 기억 상실이 연관이 있는지 알고 싶어요.', '알츠하이머병과 치매는 서로 다른 병이라고 할 수 있나요?', '알츠하이머병의 주요 증상 중에는 어떤 것들이 있는지 알려주세요.', '알츠하이머병의 주요 증상 중 가까운 기억들을 잊어버리는 것이 포함되는 건가요?', '알츠하이머병으로 인한 증상 중에서 일반인이 가장 먼저 느끼는 것은 무엇인가요?', '알츠하이머병의 주요 증상 중 가까운 기억들을 잘 생각하지 못하는 것은 치매의 증상일까요?', '알츠하이머병의 초기 증상 중에 가까운 기억을 잃는 것이 포함되는지 궁금해요.', '알츠하이머병의 증상 중에서 주의해야 할 것은 어떤 것인가요?', '알츠하이머병이 발생하면 어떤 증상이 나타날까요?', '알츠하이머병에 걸렸을 때 일반인이 흔히 나타내는 증상은 어떤 것이 있을까요?', '알츠하이머병의 주요 증상에는 어떤 것이 있는지 알고 싶어요.', '알츠하이머병의 초기 증상 중에서 기억력 저하 외에 다른 증상이 있을 수 있는지 알고 싶어요.', '알츠하이머병의 주요 증상들을 정의해주실 수 있나요?', '알츠하이머병으로 진단 받을 수 있는 의료 시설이나 의료진은 어디에 있을까요?', '알츠하이머병의 초기 증상 중에서 기억에 문제가 발생하는 것 외에 다른 증상이 있는지 알고 싶어요.', '알츠하이머병의 증상에 대해 상세히 설명해주세요.', '치매와 알츠하이머병은 각각 어떤 증상을 가지고 있나요?', '알츠하이머병의 초기 증상 중에서 기억력 문제 이외에 다른 증상을 알려주세요.', '알츠하이머병과 치매의 정확한 정의를 알려주세요.', '알츠하이머병의 증상에는 어떤 것들이 있는지 자세히 설명해주세요.', '알츠하이머병의 증상과 진단은 어떻게 진행되나요?', '알츠하이머병과 가까운 기억 상실이 연관이 있는지 알려주세요.', '알츠하이머병의 진단을 받기 위해 어떤 절차를 거쳐야 하나요?', '알츠하이머병으로 진단 받기 위해서는 어떤 증상이 있어야 하나요?', '알츠하이머병 환자가 느낄 수 있는 가장 흔한 증상은 무엇인가요?', '알츠하이머병으로 인한 증상에 대해 자세히 설명해주세요.', '알츠하이머병의 증상 중 가까운 기억들의 기억력이 저하되는 것이 있는지 알고 싶어요.', '알츠하이머병의 진단을 받으려면 어떤 검사를 받아야 하나요?', '알츠하이머병의 증상 중 기억력 감퇴 외에 어떤 증상들이 있을까요?', '알츠하이머병의 초기 증상 중 다른 증상들과 구별되는 특징은 무엇인가요?', '알츠하이머병에 의한 증상 중에서 일반인이 특히 주의해야 할 것은 무엇인가요?', '알츠하이머병의 정의와 함께 증상에 대해 더 자세히 알고 싶어요.', '알츠하이머병의 증상 중 가까운 기억들에 대한 기억력 감퇴가 흔한 것인가요?', '알츠하이머병의 주요 증상과 그에 대한 예후는 어떻게 되는지 알고 싶어요.', '알츠하이머병의 진단을 받을 수 있는 병원이나 의사를 찾는 방법은 어떤 것이 있나요?', '알츠하이머병의 주요 증상 중 기억력 감퇴와 단어가 잘 떠오르지 않는 증상이 포함되나요?', '알츠하이머병의 초기 단계에서는 어떤 증상들이 나타날 수 있을까요?', '알츠하이머병과 치매는 어떤 병들로 구분되는지 알 수 있을까요?', '알츠하이머병과 관련하여 기억력 감퇴와 단어가 잘 떠오르지 않는 증상이 나타나는지 알려주세요.', '알츠하이머병의 진단은 주로 어떤 과정으로 이루어지나요?', '알츠하이머병의 대표적인 증상 중 기억력 감퇴 외에 어떤 증상들이 흔히 나타날까요?', '알츠하이머병의 증상 중 기억력 감퇴 외에 어떤 것들이 있는지 자세히 알려주세요.', '알츠하이머병의 증상 중 가까운 기억들의 기억력이 저하되는 것이 흔한 증상인가요?', '알츠하이머병과 치매는 서로 다른 질병인가요?', '알츠하이머병이라는 질병의 초기 증상에는 어떤 것들이 있나요?', '알츠하이머병의 주요 증상은 어떤 것들이 있는지 알고 싶어요.', '할머니의 증상 중 기억상실증이 어떻게 나타나는지 알 수 있을까요?', '알츠하이머병의 주요 초기 증상은 무엇인가요? 알츠하이머병의 특징적인 증상들을 알려주세요.', '알츠하이머병이라는 질병의 특징과 증상에 대해 알려주세요.', '알츠하이머병과 치매의 정의와 차이에 대해 설명해주세요.', '알츠하이머병의 일반적인 특징적인 증상에는 어떤 것들이 있나요?', '알츠하이머병과 관련하여 기억력 감퇴와 단어가 잘 떠오르지 않는 증상이 어떻게 진행되는지 자세히 알고 싶어요.', '알츠하이머병의 정의와 주요 증상은 무엇인가요?', '알츠하이머병으로 인한 증상 중에서 특히 주의해야 할 증상은 무엇인가요?', '알츠하이머병으로 인한 기억력의 약화는 어떤 기준으로 판단되는 건가요?', '알츠하이머병의 대표적인 증상 중 기억력 감퇴 외에 어떤 것이 있는지 알려주세요.', '알츠하이머병의 증상 중에서 일반인이 알 수 있는 것이 있을까요?', '알츠하이머병의 증상 중에 기억상실증 외에 어떤 특이한 증상이 나타날 수 있을까요?', '알츠하이머병의 증상에는 어떤 특징이 있나요?', '알츠하이머병이 치매와 어떤 점에서 다른 질병인가요?', '알츠하이머병에는 기억력 감퇴 외에 어떤 증상들이 나타날 수 있는지 자세히 설명해주세요.', '알츠하이머병은 어떤 질병인가요? 알츠하이머병의 주요 증상은 무엇인가요?', '알츠하이머병 초기 단계에서 어떤 주요한 증상들이 나타날 수 있을까요?', '알츠하이머병과 치매는 어떻게 다른 질병인가요? 자세한 설명을 부탁드립니다.', '알츠하이머병과 관련하여 기억력 감퇴와 단어가 잘 떠오르지 않는 증상이 나타나는지 알고 싶습니다.', '알츠하이머병의 증상은 어떻게 나타나는지 자세히 설명해주세요.', '알츠하이머병의 주요 증상에는 어떤 것들이 포함되나요?', '알츠하이머병은 치매와 어떻게 구분되는지 알려주세요.', '알츠하이머병의 특징적인 증상들에 대해 자세히 알려주세요.', '알츠하이머병의 주요 증상들에는 어떤 것들이 포함되나요?', '알츠하이머병과 치매는 어떻게 다른 질병인가요?', '알츠하이머병으로 인해 나타나는 증상 중에서 가장 흔한 것은 무엇인가요?', '알츠하이머병 초기 단계에서 어떤 증상들이 주로 나타나는지 알려주세요.', '알츠하이머병의 주요 증상 중 어떤 것들이 있는지 알려주세요.', '알츠하이머병에 걸렸을 때 일반인이 주로 어떤 증상을 경험하게 되나요?', '알츠하이머병과 치매의 차이점은 무엇인가요? 자세히 설명해주세요.', '알츠하이머병의 주요 증상과 그 특징을 상세히 알려주세요.', '알츠하이머병의 주요 증상에 대해 알고 싶어요.', '알츠하이머병과 치매의 정의와 특성을 자세히 알고 싶어요.', '알츠하이머병의 증상들이 어떤 식으로 나타나는지 설명해주세요.', '알츠하이머병의 의미와 특징을 알려주세요.', '알츠하이머병의 초기 증상 중 가까운 기억을 잃는 것이 포함되나요?', '알츠하이머병이 발병하면 기억력 감퇴 외에도 어떤 신체적인 증상들이 나타날 수 있는지 자세한 설명을 해주세요.', '알츠하이머병과 관련하여 기억력 감퇴와 단어가 잘 떠오르지 않는 증상의 정의와 특징은 무엇인가요?', '알츠하이머병으로 인한 증상 중에서 일반인이 이해하기 쉬운 것은 무엇인가요?', '알츠하이머병의 증상 중 기억력 감퇴와 단어가 잘 떠오르지 않는 증상이 어떤 의미를 갖는지 알려주세요.', '알츠하이머병으로 인해 발생하는 주요 증상은 무엇인가요?', '알츠하이머병 진단을 위해 어떤 검사가 시행되나요?', '알츠하이머병이 발생할 경우 주로 나타나는 증상 중 기억력 감퇴 외에도 어떤 증상들이 나타날까요?', '알츠하이머병을 진단 받을 수 있는 의료 전문가는 누구인가요?', '알츠하이머병 환자의 증상이 어떻게 진행되는지 알고 싶어요.', '알츠하이머병의 초기 증상 중에서 기억력 저하 외에 다른 증상이 있을까요?', '알츠하이머병과 관련하여 기억력 감퇴와 단어가 잘 떠오르지 않는 증상에 대해 설명해주세요.', '알츠하이머병의 주요 증상을 자세히 설명해주세요.', '알츠하이머병의 증상이 기억력 감퇴와 어떤 관련이 있는지 알려주세요.', '알츠하이머병의 증상은 어떤 것들이 있는지 알려주세요.', '알츠하이머병에 걸렸을 때 일반인이 보통 어떤 증상을 경험하게 되나요?', '알츠하이머병의 증상 중에서 가장 흔한 것은 무엇인가요?', '알츠하이머병의 주요 증상과 그 특징적인 증상들에 대해 자세한 설명을 해주세요.', '알츠하이머병 환자가 느낄 수 있는 일반적인 증상이 어떤 것들이 있나요?', '알츠하이머병 초기 단계의 초기 증상 중 기억력이 저하되는 것 외에 다른 증상이 있을까요?', '알츠하이머병에는 기억력 감퇴 이외에도 어떤 신체적인 이상 증상이 나타날 수 있는지 알려주세요.', '알츠하이머병의 주요 증상 중 가까운 기억들을 잘 떠올리지 못하는 것이 포함되는 건가요?', '알츠하이머병의 증상 중 가까운 기억들을 잘 떠올리지 못하는 것이 흔한 증상일까요?', '알츠하이머병이라는 질병에 대해 자세히 설명해주세요.', '알츠하이머병의 정의와 증상에 대해 알고 싶습니다.', '알츠하이머병과 치매는 무엇이 다른 질병인가요?', '알츠하이머병의 증상에는 어떤 것이 포함되는지 알고 싶어요.', '알츠하이머병 환자가 증상을 경험할 때 어떤 변화가 나타날 수 있을까요?', '알츠하이머병 진단을 받기 위해서는 어떤 증상이 있어야 하나요?', '알츠하이머병 환자가 증상을 느끼는 방법에는 어떤 것들이 있을까요?', '알츠하이머병의 초기 증상 중에서 기억력 문제 외에 다른 증상이 있는지 알려주세요.', '알츠하이머병 진단을 받을 때 주로 어떤 정보를 의사에게 제공해야 하나요?', '알츠하이머병의 주요 증상 중 기억상실증 이외에 다른 어떤 증상이 있는지 알 수 있을까요?', '알츠하이머병의 주요 증상에 대해서 자세히 알려주세요.', '알츠하이머병의 증상 중에서 기억상실증 외에 어떤 증상이 나타날 수 있는지 알고 싶어요.', '알츠하이머병의 대표적인 증상에 대해 자세한 정보를 알려주세요.', '알츠하이머병이 발생할 경우 기억력 감퇴 외에 어떤 증상들이 주로 나타날 수 있는지 알려주세요.', '알츠하이머병의 초기 증상 중에 가까운 기억을 잃는 것이 포함되는지 알고 싶어요.', '알츠하이머병의 증상이 나타나면 어떤 조치를 취해야 할까요?', '알츠하이머병의 증상 중에서 가장 흔한 것이 무엇인지 자세히 알려주세요.', '알츠하이머병 환자에게 나타날 수 있는 주요한 증상은 무엇인가요?', '알츠하이머병의 주요 증상 중에서 가장 흔한 것을 알고 싶어요.', '알츠하이머병의 초기 증상 중 기억력이 저하되는 것 외에 어떤 증상들이 있을까요?', '알츠하이머병의 주요 증상이 나타날 경우에는 어떤 증상들이 주로 나타날까요?', '알츠하이머병이란 무엇인가요? 알츠하이머병의 주요 증상에 대해 알려주세요.', '알츠하이머병과 치매의 정의와 특성을 알고 싶어요.', '알츠하이머병 진단을 위해 어떤 혈액 검사가 사용되나요?', '알츠하이머병을 진단하는 과정에서 어떤 검사가 일반적으로 시행되나요? 중증도 기준을 정하는 기준은 어떻게 되는지 알려주세요.', '알츠하이머병 진단을 위해 어떤 혈액 검사가 필요한가요?', '알츠하이머 질병의 진단에 있어  Apo E 유전자는 어떤 역할을 하는 건가요?', '알츠하이머병을 진단하기 위해 어떤 검사가 필요한가요?', '알츠하이머병으로 인한 기억력 저하, 일상생활 어려움과 관련된 주요한 요인은 무엇인가요?', '알츠하이머병 진단을 받기 위해 어떤 과정을 거쳐야 하나요?', '알츠하이머병을 진단하기 위해 어떤 검사나 조사가 필요한가요?', '알츠하이머병 진단을 위해 어떤 의학적 절차가 필요한가요?', '알츠하이머병의 진단을 받을 수 있는 의사를 알려주세요.', '알츠하이머병의 중증도를 어떻게 확인하는지 알려주세요.', '알츠하이머병의 진단을 받을 수 있는 전문의의 종류와 특징은 어떤 것이 있나요?', '길을 잃고, 집을 못 찾을 때 알츠하이머병인지 확인하려면 어떤 의료기관을 찾아가야 할까요?', '알츠하이머 질병의 주요 진단 방법 중  Apo E 유전자의 기능은 어떤 것이 있는지 알려주세요.', '알츠하이머병을 진단하는데 사용되는 주요한 검사 중에 Apo E 유전자 검사가 있는 것 맞나요?', '알츠하이머병 진단을 받기 위해서는 어떤 의료 기관을 방문해야 하나요?', '알츠하이머병 진단을 받을 수 있는 의사의 이름과 연락처를 알고 싶어요.', '알츠하이머병을 진단하는데 사용되는 주요 검사 방법은 무엇인가요?', '알츠하이머병 진단을 받을 수 있는 곳을 찾기 위해 어떤 검색어를 사용해야 할까요?', '알츠하이머병을 확인하는데 있어서 어떤 진단 방법이 가장 효과적인가요?', '알츠하이머병 진단을 받을 수 있는 의사의 종류는 어떻게 되나요?', '알츠하이머병 진단을 받기 위해 어떤 의사를 찾아가야 할까요?', '알츠하이머병을 진단하기 위해 어떤 의료 기관을 방문해야 할까요?', '알츠하이머병 진단을 위해 문진과 뇌 CT 외에 다른 진단 방법을 사용할 수 있을까요?', '알츠하이머병 진단을 위해 어떤 의료 전문가를 찾아야 할까요?', '알츠하이머병의 진단을 위해서는 어떤 검사가 필요한가요?', '알츠하이머병을 진단해 줄 수 있는 전문의가 어디에 있나요?', '치매 진단을 받기 위해 어떤 의료진과 상담해야 할까요?', '알츠하이머병과 관련하여 기억력 저하, 일상생활 어려움이 생기는 원리를 알려주세요.', '알츠하이머병 진단을 받으려면 어떤 검사가 필요한가요?', '알츠하이머병 진단은 얼마나 정확하게 이루어지나요?', '알츠하이머병을 진단하는데 가장 흔히 사용되는 검사 방법은 무엇인가요?', '길을 잃고, 집을 못 찾을 때 알츠하이머병인지 의심하고 진단을 받기 위해 어떤 전문의를 찾아야 하나요?', '알츠하이머병의 진단을 받기 위해 어떤 검사를 받아야 하는지 알려주세요.', '아버지가 길을 잃어버리고 집을 찾지 못하는데, 어떤 의사를 찾아가면 적절한 진단을 받을 수 있을까요?', '알츠하이머병을 진단하기 위해 어떤 단계들이 포함되나요?', '알츠하이머병의 진단을 받기 위해 어떤 종류의 전문의를 찾아야 하나요?', '알츠하이머병을 진단하는 주요 기준은 무엇인가요?', '알츠하이머병을 진단하기 위해 어떤 종류의 혈액 검사를 시행하는지 알려주세요.', '알츠하이머병을 정확하게 진단하기 위해 어떤 의학적 절차가 필요한가요?', '알츠하이머병을 진단하는데 일반적으로 어떤 절차가 필요한가요?', '알츠하이머병 진단을 위해 뇌CT를 찍는 것은 문진으로만 가능한가요?', '알츠하이머병이란 어떤 증상을 가지는 질병인가요? 알려주세요.', '알츠하이머병이 의심되는데, 어떤 전문의를 방문해야 할까요?', '알츠하이머병 진단을 받으려면 어떤 검사가 필요한지 알고 싶어요.', '알츠하이머병은 어떤 증상들을 가지는 질병인가요?', '알츠하이머병 진단을 받으려면 어떤 과정을 거쳐야 하나요?', '알츠하이머병을 확인하기 위해 어떤 종류의 검사가 주로 필요한지 알려주세요.', '알츠하이머병 진단을 위해 어떤 종류의 의료 검사가 이루어지나요?', '알츠하이머병을 어떻게 평가하고 진단하는 건가요?', '알츠하이머병을 진단하는 방법은 무엇인가요?', '알츠하이머병을 의심할만한 증상이 있다면 어떤 의사를 방문해야 할까요?', '알츠하이머병 진단을 위해 의사에게 어떤 정보를 제공해야 할까요?', '치매가 의심되는 증상이 있을 때 어떤 전문의를 찾아가야 할까요?', '알츠하이머병 진단을 위해 어떤 검사들이 필요한가요?', '알츠하이머병 진단을 받을 수 있는 전문의의 역할은 무엇인가요?', '알츠하이머병 진단을 받을 수 있는 전문의는 누구인가요?', '알츠하이머병 진단을 위해 뇌 영상 검사의 필요성과 목적에 대해 알려주세요.', 'Apo E 유전자 검사를 통해 알츠하이머병을 확인하는데 어떤 점이 가장 중요한가요?', '알츠하이머병 진단을 받기 위해서는 어떤 검사가 필요한가요?', '알츠하이머병 진단을 받을 수 있는 병원이 어디인지 알려주세요.', '알츠하이머병 진단을 받기 위해서는 어떤 의료기관의 의사를 찾아야 하나요?', '알츠하이머병 진단을 받기 위해서는 어떤 전문의를 찾아가야 하나요?', '알츠하이머병 진단을 받을 수 있는 보건소는 어디에 있나요?', '알츠하이머병 진단을 받기 위해서는 어떤 전문가를 찾아야 할까요?', '알츠하이머병 진단을 받을 수 있는 전문의의 소개를 받으려면 어떻게 해야 할까요?', '알츠하이머병을 진단하는데 가장 흔히 사용되는 방법은 무엇인가요?', '알츠하이머병 진단을 위해 어떤 과정을 거쳐야 하나요?', '알츠하이머병 진단을 받기 위해 어떤 종류의 전문가를 찾아야 하나요?', '알츠하이머병 진단을 위해 어떤 종류의 검사가 필요한가요?', '알츠하이머병 진단을 받을 때, 어떤 혈액 검사가 필요한가요?', '뇌 사진을 찍는 것 외에 다른 진단 방법이 있을까요?', '알츠하이머병 진단을 위해 뇌 CT가 필수적으로 사용되는 것인가요?', '알츠하이머병 초기 진단을 받으려면 가까운 보건소에서도 가능한가요?', '알츠하이머병 진단을 받기 위해서는 어떤 전문의를 찾아야 할까요?', '알츠하이머병을 진단하기 위해 어떤 검사 절차를 거쳐야 하나요?', '알츠하이머병의 진단을 받기 위해 어떤 종류의 검사가 필요한가요?', '알츠하이머병을 진단하기 위해 어떤 의료 영상 검사가 사용되나요?', '알츠하이머병 진단을 받을 때, 어떤 검사 결과가 주로 확인되나요?', '알츠하이머병을 의심해볼 만한 증상이 나타나면 어떤 진료과를 방문해야 할까요?', '알츠하이머병 진단을 받을 수 있는 전문 분야가 어디인가요?', '알츠하이머병을 진단받기 위해 어느 진료과를 방문해야 할까요?', '알츠하이머 질병을 진단하는데 있어 Apo E 유전자의 기능을 어떻게 평가하나요?', '알츠하이머병 진단에 있어서 뇌 영상 검사의 중요성을 알려주세요.', '알츠하이머병 진단을 무료로 받으려면 어떤 단계를 거쳐야 할까요?', '알츠하이머병 진단을 위해 어떤 종류의 검사를 받아야 하는지 자세히 알려주세요.', '알츠하이머병 진단을 위해 어떤 방법이 주로 사용되나요?', '알츠하이머병을 정확하게 진단할 수 있는 검사나 검사 방법이 있을까요?', '알츠하이머병의 진단을 받기 위해 어떤 과에 내원해야 할까요?', '알츠하이머병을 진단하는데 필요한 검사는 무엇이 있을까요?', '알츠하이머병 진단을 위해 어떤 혈액 검사가 일반적으로 사용되나요?', '알츠하이머병을 의심할 때 어떤 의료기관을 방문해야 할까요?', '알츠하이머병 진단을 위해 문진과 뇌 CT를 통해 확인할 수 있을까요?', '알츠하이머병을 진단하기 위해 뇌CT를 찍어야 하는지, 아니면 뇌CT가 사용되지 않을까요?', '알츠하이머병을 진단하기 위해 어떤 종류의 검사가 사용되나요?', '알츠하이머병을 진단하는데 있어서 어떤 종류의 신체 검사가 이루어지나요?', '알츠하이머병을 진단하기 위해 어떤 자기 공명 영상 검사가 사용되나요?', '알츠하이머병을 진단하기 위해 어떤 종류의 의료 검사가 필요한가요?', '알츠하이머병 진단을 위해 뇌 CT를 찍는 것이 필수적인가요?', '알츠하이머병 진단을 받으려면 어떤 의사를 찾아야 하나요?', '알츠하이머병 초기 진단은 가까운 보건소에서도 가능한지 알고 싶어요.', '알츠하이머병 진단을 위한 검사의 종류와 그 순서에 대해 알고 싶어요.', '알츠하이머병 진단은 어떻게 이루어지는지 알려주세요.', '알츠하이머병 진단을 받기 위해 어떤 절차를 따라야 하나요?', '알츠하이머병 진단을 받으려면 어떤 진료과를 찾아야 할까요?', '알츠하이머병 진단을 위해 어떤 종류의 검사가 일반적으로 사용되나요?', '알츠하이머병 진단 비용은 어느 정도인가요?', '알츠하이머병을 진단하는데 가장 일반적인 방법은 무엇인가요?', '알츠하이머병 진단을 위해 어떤 의료 기록이 필요한가요?', '알츠하이머병 진단을 위해 어떤 영상 검사가 활용될 수 있나요?', '알츠하이머병을 확인하기 위해 어떤 종류의 의료 영상 검사가 필요한가요?', '알츠하이머병을 진단받기 위해 어떤 의료기관을 방문해야 하나요?', '알츠하이머병 진단은 어떤 방식으로 진행되나요?', '알츠하이머병 진단을 받으려면 가까운 보건소를 찾아가야 하나요?', '알츠하이머병 진단을 받으려면 어떤 검사를 받아야 할까요?', '알츠하이머병 진단을 받는데 얼마나 시간이 걸릴까요?', '알츠하이머병을 진단하기 위해서는 어떤 절차를 거쳐야 하나요?', '알츠하이머병 진단을 받기 위해 어떤 의료 전문가의 도움이 필요한가요?', '알츠하이머병을 진단하기 위해 어떤 검사를 받아야 할까요?', '길을 잃어버리고 집을 찾지 못하는 아버지의 증상이 나타났을 때, 어떤 의료진과 상담해야 할까요?', '알츠하이머병 진단을 무료로 받을 수 있는지 궁금합니다.', '알츠하이머병 진단을 위해 일반적으로 어떤 종류의 검사가 필요한지 알고 싶어요.', '알츠하이머병 진단을 위해 일반적으로 어떤 검사가 필요한지 알 수 있을까요?', '알츠하이머병 진단을 위해 어떤 검사나 검사가 필요한가요?', '알츠하이머병은 어떤 질병인가요?', '뇌 사진을 찍을 때 어떤 조건이 필요한가요?', '알츠하이머병을 진단하기 위해 어떤 절차를 거쳐야 하는지 알려주세요.', '알츠하이머병을 진단받기 위해 어떤 의료진과 상담해야 할까요?', '알츠하이머병을 진단하는 과정에서 어떤 정보들이 수집되나요?', '알츠하이머병 진단을 위해 방문해야 할 병원의 종류가 있을까요?', '알츠하이머병 진단을 받을 수 있는 병원이 있을까요?', '알츠하이머병을 진단하는 데에 필요한 주요 절차와 검사는 어떤 것들이 있는지 알려주세요.', '알츠하이머병과 관련하여 기억력 저하, 일상생활 어려움이 나타나는 이유에 대해 설명해주세요.', '알츠하이머병 진단을 위해 어떤 의료 영상 검사가 사용되나요?', '알츠하이머병의 진단을 받기 위해 어떤 의사와 상담해야 할까요?', '알츠하이머병 진단을 받기 위해 어떤 절차를 거쳐야 하나요?', '알츠하이머병을 확인하기 위해 주로 어떤 검사가 필요한지 알고 싶어요.', '알츠하이머병 진단을 위해 어떤 검사들이 이루어지는지 알려주세요.', '알츠하이머병을 진단하기 위해 어떤 검사가 일반적으로 사용되나요?', '알츠하이머병을 정확하게 진단받을 수 있는 의료기관은 어디에 있나요?', '알츠하이머병의 진단은 어떤 방법으로 이루어지나요?', '뇌 사진을 찍으면 알츠하이머병을 진단할 수 있는 건가요?', '알츠하이머병을 진단하기 위해 어떤 종류의 검사가 필요한지 알려주세요.', '알츠하이머병 진단을 위해 어떤 영상 검사들이 활용되나요?', '알츠하이머병 진단을 위해 필요한 검사에는 어떤 것들이 있는지 알려주세요.', '알츠하이머병 진단을 받을 수 있는 병원이 어디인지 알려주세요.', '알츠하이머병 진단을 위해 어떤 의료 영상 검사가 일반적으로 사용되나요?', '알츠하이머병의 진단을 받기 위해 어떤 의료기관을 찾아야 할까요?', '아버지가 길을 잃어버리고 집을 못 찾는 경우, 어떤 의료진의 도움을 받아야 할까요?', '알츠하이머병을 진단받으려면 어떤 진료과를 찾아가야 할까요?', '알츠하이머병 진단을 위해 뇌CT를 찍어보는 것 외에도 어떤 방법이 있을까요?', '알츠하이머병 진단을 받기 위해 어떤 전문의를 방문해야 할까요?', '알츠하이머병으로 인한 기억력 저하, 일상생활 어려움이 발생하는 메커니즘에 대해 자세히 알려주세요.', '알츠하이머병 진단을 받기 위해 어떤 종류의 검사를 받아야 할까요?', '알츠하이머병 진단을 받기 위해서는 어떤 의사를 찾아야 할까요?', '알츠하이머병을 확인하기 위해 어떤 종류의 검사가 필요한지 알려주세요.', '알츠하이머병 진단을 받기 위해 어떤 의사를 방문해야 하나요?', '알츠하이머병 진단을 받을 때 어떤 검사가 이루어지나요?', '뇌 영상 검사를 통해 알츠하이머병을 진단할 수 있을까요?', '알츠하이머병 초기 진단은 가까운 보건소에서도 가능한가요?', '알츠하이머 질병의 진단 과정에서 Apo E 유전자의 기능을 어떻게 확인하나요?', '알츠하이머병을 확인하기 위해 어떤 종류의 검사가 필요한지 자세히 알려주세요.', '알츠하이머병 진단을 받을 수 있는 곳을 알고 싶어요.', '알츠하이머병을 진단하기 위해 어떤 종류의 검사가 필요한가요?', '알츠하이머병 진단을 위해 어떤 과정을 거쳐야 하나요?', '알츠하이머병 진단을 위해 어떤 검사들이 필요한가요?', '알츠하이머병의 진단을 위해 어떤 의료진을 찾아야 할까요?', '알츠하이머병 진단을 위해 어떤 종류의 의료 전문가를 찾아가야 하나요?', '알츠하이머병 진단을 위해 어떤 절차를 거쳐야 하나요?', '알츠하이머병 진단을 위해서는 뇌 CT 이외에 어떤 검사가 필요한가요?', '알츠하이머병을 진단하기 위해 어떤 검사들이 주로 사용되나요?', '알츠하이머병을 정확히 진단받을 수 있는 의료기관은 어디인가요?', '알츠하이머병을 정확하게 진단해주는 의료기관이 어디인가요?', '알츠하이머병을 정확하게 진단할 수 있는 전문의의 진료 시간대와 예약방법은 무엇인가요?', '알츠하이머병 진단을 받을 수 있는 의사의 전문 분야가 무엇인가요?', '알츠하이머병을 진단하기 위해 문진 이외에 어떤 검사가 주로 필요한가요?', '알츠하이머병을 진단하기 위해서는 뇌 영상 검사가 꼭 필요한가요?', '뇌CT를 통해 알츠하이머병을 정확히 진단할 수 있는 방법은 무엇인가요?', '알츠하이머병을 진단하기 위해 어떤 종류의 영상 검사가 사용되나요?', '알츠하이머병을 판단하기 위해 어떤 종류의 검사가 필요한가요?', '알츠하이머병에 대한 정확한 진단을 위해 어떤 검사가 필요한지 알려주세요.', '알츠하이머병 초기 진단을 받으려면 가까운 보건소에서 어떤 검사를 받아야 할까요?', '알츠하이머병 진단을 위해 어떤 검사가 일반적으로 사용되는지 알려주세요.', '알츠하이머병은 어떤 질병인가요? 정의와 주요 증상을 알려주세요.', '알츠하이머병을 진단하기 위해 어떤 종류의 검사가 사용되나요? 중증도 기준을 정하는 기준은 어떻게 되나요?', '알츠하이머 질병의 진단 과정에서 Apo E 유전자의 기능을 어떻게 확인하나요?', '할머니의 알츠하이머병 진단을 받을 수 있는 병원이 어디에 있나요?', '알츠하이머 질병을 진단하는 데에  Apo E 유전자가 어떤 역할을 하는지 알 수 있을까요?', '알츠하이머병 진단을 받기 위해 어떤 의사를 찾아가야 하나요?', '알츠하이머병 진단을 위해 어떤 과에서 어떤 검사를 받아야 하나요?', '길을 잃어버리고 집을 찾지 못하는 아버지의 증상이 발생할 경우, 어떤 의사를 찾아야 할까요?', '알츠하이머병 진단을 받기 위해 방문할 전문의를 알려주세요.', 'Apo E 유전자 검사는 알츠하이머병의 진단에 어떤 역할을 하는 건가요?', '뇌CT와 같은 검사를 통해 알츠하이머병을 진단하는 것이 정확한 결과를 얻을 수 있을까요?', '알츠하이머병을 진단하기 위해 어떤 종류의 검사가 주로 사용되는지 알려주세요.', '알츠하이머병을 진단받을 수 있는 병원이 어디에 위치하고 있나요?', '알츠하이머병을 진단하기 위해 어떤 증상을 확인해야 하나요?', '알츠하이머병 진단을 위한 검사나 조사를 받을 때 어떤 정보나 결과를 주로 얻게 되나요?', '알츠하이머병 진단을 받을 수 있는 병원이 어디에 있는지 알려주세요.', '알츠하이머병을 의심할 만한 아버지의 행동이나 상태를 확인할 수 있는 진단 방법이 있을까요?', '알츠하이머병 진단을 위해 필요한 검사 방법은 어떤 것들이 있나요?', '알츠하이머병을 의심하고 진단받기 위해 어떤 의료기관을 찾아가야 할까요?', '길을 자주 잃어버리고, 집을 못 찾을 때 알츠하이머병을 의심하고 진단을 받으려면 어떤 전문의의 도움을 받아야 하나요?', '알츠하이머병 진단을 받기 위해 어떤 단계를 거쳐야 하나요?', '알츠하이머병과 관련하여 기억력 저하, 일상생활 어려움을 경험하는 것이 맞을까요?', '뇌 사진이 알츠하이머병을 진단하는 정확도와 신뢰도가 높은가요?', '알츠하이머병을 진단하기 위해 일반적으로 어떤 종류의 검사가 필요한지 알려주세요.', '알츠하이머병의 기억력 저하, 일상생활 어려움이 관련되는 원인에 대해 알려주세요.', '알츠하이머병을 진단하기 위해 뇌 사진이 중요한 이유가 무엇인가요?', '치매 진단을 받을 수 있는 병원이나 클리닉을 알고 계신가요?', '치매 진단을 위해 어떤 전문가를 찾아야 할까요?', '알츠하이머병을 진단하기 위해 필요한 주요 요소는 어떤 것들이 있나요?', '알츠하이머병을 진단하는데 가장 중요한 기능 중에 Apo E 유전자 기능이 어떤 역할을 하나요?', '알츠하이머병을 진단하는 과정에 대해 자세히 알려주세요.', '알츠하이머병을 진단할 때, Apo E 유전자 검사 외에도 다른 검사가 사용되는 이유가 있을까요?', '알츠하이머병 진단을 위해 어떤 초음파 검사가 필요한가요?', '나이가 들면서 기억력이 감소하고 일상생활에 어려움을 겪는데, 알츠하이머병이 의심되는 이유가 무엇인가요?', '알츠하이머병 진단을 받기 위해 어떤 정보나 자료가 필요한가요?', '알츠하이머병 진단은 가까운 곳에서 받을 수 있나요?', '알츠하이머병 진단을 위해 어떤 검사들이 일반적으로 사용되나요?', '아는 친구의 알츠하이머병 진단을 위한 주요 검사 항목은 무엇인가요?', '알츠하이머병 진단을 받을 수 있는 보건소는 어디에 있나요?', '알츠하이머병을 진단하기 위해 사용되는 특정 기준이나 절차가 있을까요?', '알츠하이머병 진단을 위해 뇌 영상 검사는 어떤 단계를 거치나요?', '알츠하이머병 진단을 받으려면 어떤 과에 내원해야 할까요?', '알츠하이머병 진단을 무료로 받을 수 있는 방법이 있을까요?', '알츠하이머병 초기 진단을 받으려면 가까운 보건소에서 어떤 절차를 따라야 하나요?', '알츠하이머병을 진단하기 위해 어떤 검사 절차가 이루어지나요?', '뇌 영상 검사를 통해 알츠하이머병의 진단 결과를 확인할 수 있을까요?', '알츠하이머병 진단을 위해 어떤 검사를 받아야 할까요?', '알츠하이머병 진단을 받을 수 있는 병원의 위치를 알려주세요.', '아버지가 길을 자주 잃어버리고, 집을 못 찾을 때 알츠하이머병인지 확인하기 위해 어떤 검사를 받아야 할까요?', '알츠하이머병 진단을 위해 어떤 의료 영상 검사가 필요한가요?', '알츠하이머병을 진단할 수 있는 의학적 전문 기관은 어디에서 찾을 수 있을까요?', '알츠하이머병의 진단 결과를 확인하기 위해 어떤 종류의 검사가 필요한가요? 중증도 기준을 정하는 기준은 어떻게 되는지 알려주세요.', '알츠하이머병 진단을 위해 어떤 의료 기기나 장비를 사용하나요?', '알츠하이머병을 진단할 수 있는 전문의료기관을 추천해주세요.', '알츠하이머병 진단을 받기 위해서는 어떤 진료과를 찾아가야 할까요?', '알츠하이머병 진단을 받기 위해 어떤 종류의 신체 검사가 필요한가요?', '알츠하이머병의 진단을 받을 수 있는 의료기관을 찾고 있습니다. 어디를 추천해주실 수 있나요?', '알츠하이머병 진단을 받을 수 있는 병원이 어디인지 알려주세요.', '알츠하이머병의 정확한 진단을 위해 필요한 검사나 진료 과정은 어떻게 되나요?', '알츠하이머병을 정확하게 진단하는 의사는 누구인가요?', '알츠하이머병을 진단받으려면 어떤 의료진을 찾아가야 하나요?', '알츠하이머병 진단을 위해 주로 어떤 종류의 검사가 시행되나요?', '알츠하이머병 진단의 정확도는 어느 정도인가요?', '알츠하이머병의 정의와 특징을 자세히 알려주세요.', '알츠하이머병 진단에 대해 자세히 알려주세요.', '알츠하이머병을 진단하기 위해 어떤 종류의 검사를 받아야 하나요?', '알츠하이머병을 진단하기 위해 어떤 종류의 의학적 절차가 필요한지 알 수 있을까요?', '알츠하이머병 진단을 위해 어떤 절차를 따라야 하는지 알려주세요.', '알츠하이머병 진단을 위한 뇌 영상 검사의 필요성에 대해 알려주세요.', '알츠하이머병을 진단하는데 가장 중요한 기준이나 절차는 무엇인가요?', '알츠하이머병 진단을 받기 위해 어떤 과정을 거쳐야 할까요?', '알츠하이머병을 진단하는데 뇌 사진이 가장 정확한 방법인가요?', '알츠하이머병 초기 진단을 받으려면 가까운 보건소에서 어떤 절차를 거쳐야 하나요?', '알츠하이머병의 진단을 받으려면 가까운 보건소에서도 가능한지요?', '알츠하이머병을 정확하게 진단해주는 전문의의 종류와 연락처를 알려주세요.', '알츠하이머병 초기 진단을 받을 수 있는 가까운 보건소는 어디인가요?', '알츠하이머병 진단을 받을 수 있는 가까운 곳은 어디인가요?', '알츠하이머병 진단을 받을 수 있는 전문의가 있는 곳은 어디인가요?', '알츠하이머병 진단의 정확도는 어느 정도일까요?', '알츠하이머병 진단을 위해 어떤 종류의 검사가 일반적으로 사용되나요?', '알츠하이머병을 진단해줄 수 있는 의사나 전문가가 있는 곳은 어디인가요?', '알츠하이머병 진단을 위해 어떤 의료 기관을 방문해야 하는지 알고 싶어요.', '알츠하이머병 진단을 위해 병원에서 어떤 검사를 받아야 하나요?', '알츠하이머병 진단을 받기 위해서는 어떤 검사나 절차를 거쳐야 할까요?', '알츠하이머병의 정확한 진단을 받기 위해서는 어떤 과에서 어떤 진단 검사를 받아야 하나요?', '알츠하이머병이란 어떤 질병인가요? 어떤 증상이 나타나나요?', '알츠하이머병 진단을 받기 위해서 어떤 과정이 필요한가요?', '알츠하이머병을 진단하기 위해 어떤 종류의 검사를 시행하나요? 중증도 기준을 정하는 기준은 어떻게 되는지 알려주세요.', '알츠하이머병의 진단은 어떻게 이루어지나요? 어떤 방법들을 사용하나요? 중증도 기준은 어떻게 결정되나요?', '알츠하이머병 진단을 받기 위해 어떤 과에 내원해야 할까요?', '알츠하이머병을 정확히 진단하기 위해 어떤 절차를 거쳐야 하나요?', '알츠하이머병을 진단하기 위해 어떤 검사가 필요한가요?', '알츠하이머병을 진단하기 위해 어떤 검사가 필요한지 알려주세요.', '알츠하이머병 진단을 받기 위해 어떤 영상 검사가 사용되나요?', '알츠하이머병을 확인하기 위해 어떤 검사 방법들이 사용되나요?', '알츠하이머병 진단을 위해 뇌 영상 검사가 어떤 역할을 하는지 자세히 알려주세요.', '알츠하이머병 진단을 받기 위해 어떤 의료 기기를 사용하는 것이 좋을까요?', '알츠하이머병 진단을 위해 어떤 진료과나 병원을 찾아야 하나요?', '아는 친구의 진단을 위해 어떤 진단 방법이 주로 사용되나요?', '보건소에서도 알츠하이머병을 진단할 수 있는지 알고 싶습니다.', '알츠하이머병 진단 비용은 얼마인가요?', '알츠하이머병의 정확한 진단을 받기 위해 어떤 종류의 의사를 찾아야 하나요?', '알츠하이머병 진단을 받을 수 있는 병원이나 클리닉을 알려주세요.', '알츠하이머병 진단을 위해 병원에서 어떤 종류의 진단 검사를 진행하는지 알려주세요.', '알츠하이머병 진단을 위해 필요한 검사들은 어떤 것들이 있나요?', '알츠하이머병 초기 진단을 받으려면 가까운 보건소에서 어떤 검사를 시행하나요?', '알츠하이머병 진단을 위해 어떤 검사가 이루어지나요?', '알츠하이머병 진단을 받기 위해 어떤 테스트가 필요한가요?', '알츠하이머병의 진단을 받을 수 있는 병원을 알고 싶습니다.', '알츠하이머병을 진단하는 과정에는 어떤 절차가 포함되나요?', '알츠하이머병을 진단받기 위해 어떤 의료기관을 찾아가야 할까요?', '알츠하이머병의 진단에 있어서 어떤 지표를 기준으로 판단하나요?', '알츠하이머병 진단은 보건소에서도 받을 수 있는지 궁금합니다.', '알츠하이머병을 진단받을 수 있는 검사는 어떤 것들이 있을까요?', '알츠하이머병을 진단하기 위해 주로 사용되는 검사 방법은 어떤 것이 있나요?', '알츠하이머병 진단을 위해 어떤 뇌 영상 검사가 주로 사용되나요?', '알츠하이머병 진단을 받으려면 어떤 종류의 의사를 찾아야 하나요?', 'Apo E 유전자 검사는 어떤 방법으로 알츠하이머병을 진단하는 건가요?', '알츠하이머병 진단을 위해 어떤 진단 검사를 받아야 하는지 알려주세요.', '알츠하이머병 진단을 받기 위해 어떤 단계를 거쳐야 하나요?', '알츠하이머병 진단을 위해 어떤 뇌 구조나 기능에 대한 정보를 얻을 수 있나요?', '알츠하이머병을 진단받을 수 있는 의료기관은 어디인가요?', '알츠하이머병을 진단하기 위해 어떤 전문가를 찾아야 하나요?', '알츠하이머병 진단을 위해 병원에서 어떤 종류의 검사를 시행하나요?', '알츠하이머병 진단을 받으려면 어떤 의사와 상담해야 할까요?', '알츠하이머병을 진단하는 주요 기준은 무엇인가요?', '알츠하이머병을 진단받을 수 있는 의료기관은 어디에 있을까요?', '알츠하이머병을 진단하기 위해 병원에서 어떤 검사를 시행하는지 상세히 설명해주세요.', '알츠하이머병 진단을 받기 위해 어떤 의사와 상담해야 할까요?', '알츠하이머병 진단을 받기 위해 병원을 방문해야 할까요?', '알츠하이머병을 확인하기 위해 어떤 의료진료를 받아야 할까요?', '알츠하이머병의 진단에 대한 주요 지표는 어떤 것들이 있을까요?', '알츠하이머병을 진단하기 위해 어떤 종류의 혈액 검사가 필요한가요?', '알츠하이머병 진단을 받을 때 어떤 정보나 진단 결과를 제공받나요?', '알츠하이머병을 진단하기 위해 어떤 의료 전문가를 찾아야 하나요?', '알츠하이머병 진단을 위한 정확한 방법은 무엇인가요?', '알츠하이머병 진단을 받으려면 어떤 단계를 거쳐야 할까요?', '알츠하이머병 진단을 위해 어떤 검사들이 필요한지 상세히 알려주세요.', '알츠하이머병 진단을 위해 병원에서 어떤 검사를 시행하는지 자세히 알고 싶어요.', '알츠하이머병의 진단을 받기 위해서는 어느 과로 가야 하나요?', '알츠하이머병의 진단을 위해 의사는 어떤 진단 방법을 사용하나요?', '알츠하이머병을 진단할 수 있는 전문의를 찾을 수 있는 방법이 있을까요?', '알츠하이머병 진단을 받기 위해서는 어떤 과정을 거쳐야 하나요?', '알츠하이머병을 의심할 만한 증상이 있다면 어떤 진단 절차를 거치나요?', '알츠하이머병 진단을 위해 어떤 영상 검사를 받아야 할까요?', '알츠하이머병 진단을 위한 병원에서 어떤 검사가 주로 이루어지나요?', '알츠하이머병 진단에는 어떤 검사들이 주로 사용되나요?', '알츠하이머병 초기 진단을 받으려면 가까운 보건소에서 검사를 받아야 하나요?', '알츠하이머병을 진단하는데 어떤 검사나 조사가 필요한가요?', '알츠하이머병 진단을 받기 위해 예약하는 방법이 있을까요?', '알츠하이머병 진단을 위해 어떤 전문의를 방문해야 할까요?', '알츠하이머병을 진단하기 위해 어떤 절차를 거쳐야 하나요?', '알츠하이머병을 확인하기 위해 어떤 유형의 검사가 필요한가요?', '뇌CT를 통해 알츠하이머병을 진단하는 것이 정확도에 영향을 미치나요?', '알츠하이머병의 진단 과정에서 Apo E 유전자 검사가 어떤 방식으로 이루어지나요?', '알츠하이머병 진단을 위해 어떤 종류의 생체 검사가 필요한가요?', '알츠하이머병 진단을 받기 위해서는 문진 외에 다른 검사가 필요한가요?', '알츠하이머병을 진단해주는 전문의가 있는 곳을 알려주세요.', '알츠하이머병과 관련하여 기억력 저하, 일상생활 어려움이 어떤 메커니즘으로 발생하는지 알려주세요.', '알츠하이머병을 진단하기 위해 어떤 방법들이 사용되나요? 중증도 기준을 정하는 기준은 무엇인가요?', '알츠하이머병 진단을 무료로 받을 수 있는 병원이나 의료기관은 어디인가요?', '알츠하이머병 진단을 받으려면 어떤 의료 기관을 방문해야 할까요?', '알츠하이머병을 확인하기 위해 어떤 검사를 받아야 할까요?', '알츠하이머병을 진단하는 데에는 어떤 종류의 검사가 주로 사용되는지 알려주세요.', '알츠하이머병 진단을 받으려면 어떻게 해야 하나요?', '알츠하이머병 치료에 있어서 약물 이외의 치료법이 있을까요?', '알츠하이머병 환자를 위한 집에서의 치료 방법 중 어떤 것이 가장 효과가 있을까요?', '알츠하이머병을 치료하는 데에 가장 효과적인 방법은 무엇인가요?', '알츠하이머병 치료에 있어서 개인의 노력이 필요한가요?', '알츠하이머병을 치료하기 위한 근본적인 치료방법은 아직까지 없는 건가요?', '알츠하이머병의 치료 방법 중 가장 효과적인 방법은 무엇인가요?', '알츠하이머병 치료의 목표는 무엇이며, 어떤 치료 방법이 가장 보편적으로 사용되는지 궁금합니다.', '알츠하이머병 치료를 위해 수술이나 시술이 필요한가요?', '알츠하이머병을 완치하는 데에 어떤 종류의 치료가 필요한가요?', '알츠하이머병을 치료하기 위한 다른 치료 방법들이 있는지 궁금합니다.', '알츠하이머병을 치료하는 데에 있어서 어떤 종류의 의료 전문가를 찾아야 할까요?', '알츠하이머병을 치료하기 위해 현재 사용되는 치료법에 대해 설명해주세요.', '알츠하이머병의 증상을 줄이기 위한 치료 방법 중 어떤 것이 가장 효과적인지 알려주세요.', '알츠하이머병을 초기에 치료하면 어떤 점이 좋을까요?', '알츠하이머병을 치료하기 위한 다른 치료법은 없을까요?', '알츠하이머병 치료에 있어서 가장 효과적인 방법은 무엇인가요?', '알츠하이머병을 치료하는데 있어서 어떤 종류의 약물이 사용되는지 자세히 알려주세요.', '알츠하이머병을 치료하기 위해 주로 사용되는 치료법은 무엇인가요?']\n"
     ]
    }
   ],
   "source": [
    "q_list = []\n",
    "for i in range(1000):\n",
    "    with open(q_data[i], 'r', encoding='utf-8') as file:\n",
    "        json_data = json.load(file)\n",
    "        q_list.append(json_data['question'])\n",
    "print(q_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'치료'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_data['intention']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "a_list = []\n",
    "for i in range(1000):\n",
    "    with open(a_data[i], 'r', encoding='utf-8') as file:\n",
    "        json_data = json.load(file)\n",
    "        sentence = \"\"\n",
    "        for key in json_data['answer']:\n",
    "            sentence += json_data['answer'][key]\n",
    "        a_list.append(sentence)\n",
    "print(len(a_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_list=[]\n",
    "for i in range(1000):\n",
    "    with open(q_data[i],'r',encoding='utf-8') as file:\n",
    "        json_data=json.load(file)\n",
    "        sentence = \"\"\n",
    "        sentence += json_data['intention']\n",
    "        i_list.append(sentence)\n",
    "len(i_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '원인', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '정의', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '증상', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '진단', '치료', '치료', '치료', '치료', '치료', '치료', '치료', '치료', '치료', '치료', '치료', '치료', '치료', '치료', '치료', '치료', '치료', '치료']\n"
     ]
    }
   ],
   "source": [
    "print(i_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_df = pd.DataFrame(q_list)\n",
    "a_df = pd.DataFrame(a_list)\n",
    "df = pd.concat((q_df, a_df), axis=1)\n",
    "df.columns=['question', 'answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>알츠하이머병의 정의와 특징을 자세히 알려주세요.</td>\n",
       "      <td>알츠하이머병은 치매의 한 형태로, 인지 기능의 저하를 일으키는 질병입니다. 이 질병...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>알츠하이머병 진단에 대해 자세히 알려주세요.</td>\n",
       "      <td>알츠하이머병은 주로 치매의 주요 원인으로 알려져 있는 노인성 치매로서, 노인들 사이...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>알츠하이머병을 진단하기 위해 어떤 종류의 검사를 받아야 하나요?</td>\n",
       "      <td>알츠하이머병은 신경 세포가 파괴되어 뇌가 약화되고 비정상적인 신경 세포가 만들어지는...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>알츠하이머병을 진단하기 위해 어떤 종류의 의학적 절차가 필요한지 알 수 있을까요?</td>\n",
       "      <td>알츠하이머병은 치매와 함께 가장 흔한 퇴행성 뇌질환이며, 주로 노년층에서 발생하는 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>알츠하이머병 진단을 위해 어떤 절차를 따라야 하는지 알려주세요.</td>\n",
       "      <td>알츠하이머병은 뇌 신경세포의 소실로 인해 생기는 치매를 말합니다. 이 질환은 점진적...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          question  \\\n",
       "880                     알츠하이머병의 정의와 특징을 자세히 알려주세요.   \n",
       "881                       알츠하이머병 진단에 대해 자세히 알려주세요.   \n",
       "882            알츠하이머병을 진단하기 위해 어떤 종류의 검사를 받아야 하나요?   \n",
       "883  알츠하이머병을 진단하기 위해 어떤 종류의 의학적 절차가 필요한지 알 수 있을까요?   \n",
       "884            알츠하이머병 진단을 위해 어떤 절차를 따라야 하는지 알려주세요.   \n",
       "\n",
       "                                                answer  \n",
       "880  알츠하이머병은 치매의 한 형태로, 인지 기능의 저하를 일으키는 질병입니다. 이 질병...  \n",
       "881  알츠하이머병은 주로 치매의 주요 원인으로 알려져 있는 노인성 치매로서, 노인들 사이...  \n",
       "882  알츠하이머병은 신경 세포가 파괴되어 뇌가 약화되고 비정상적인 신경 세포가 만들어지는...  \n",
       "883  알츠하이머병은 치매와 함께 가장 흔한 퇴행성 뇌질환이며, 주로 노년층에서 발생하는 ...  \n",
       "884  알츠하이머병은 뇌 신경세포의 소실로 인해 생기는 치매를 말합니다. 이 질환은 점진적...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[880:885]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q_df = pd.DataFrame(q_list)\n",
    "# a_df = pd.DataFrame(a_list)\n",
    "# i_df = pd.DataFrame(i_list)\n",
    "# df = pd.concat((q_df, a_df,i_df), axis=1)\n",
    "# df.columns=['question', 'answer','intention']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert(loc=2, column='intention', value=i_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>intention</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>알츠하이머병의 주요 증상을 자세히 설명해주세요.</td>\n",
       "      <td>알츠하이머병은 치매를 일으키는 퇴행성 뇌질환으로, 주로 노인들에게서 발생합니다.알츠...</td>\n",
       "      <td>증상</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>알츠하이머병의 증상이 기억력 감퇴와 어떤 관련이 있는지 알려주세요.</td>\n",
       "      <td>알츠하이머병은 치매의 대표적인 원인으로 알려져 있는 신경퇴행성 질환입니다.알츠하이머...</td>\n",
       "      <td>증상</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>알츠하이머병의 증상은 어떤 것들이 있는지 알려주세요.</td>\n",
       "      <td>치매는 뇌세포의 파괴로 인해 뇌 기능의 장애가 발생하는 퇴행성 질환이며, 정상적인 ...</td>\n",
       "      <td>증상</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>알츠하이머병에 걸렸을 때 일반인이 보통 어떤 증상을 경험하게 되나요?</td>\n",
       "      <td>알츠하이머병은 치매의 원인으로 알려져 있지만, 사실은 아밀로이드의 축적과 관련이 있...</td>\n",
       "      <td>증상</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>알츠하이머병의 증상 중에서 가장 흔한 것은 무엇인가요?</td>\n",
       "      <td>알츠하이머병은 노인들 사이에서 가장 흔한 치매의 원인으로 알려져 있습니다.알츠하이머...</td>\n",
       "      <td>증상</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>알츠하이머병의 주요 증상과 그 특징적인 증상들에 대해 자세한 설명을 해주세요.</td>\n",
       "      <td>알츠하이머병은 신경학적인 장애를 일으키는 알츠하이머병의 심각한 퇴행성 뇌 질환입니다...</td>\n",
       "      <td>증상</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>알츠하이머병 환자가 느낄 수 있는 일반적인 증상이 어떤 것들이 있나요?</td>\n",
       "      <td>알츠하이머병은 퇴행성 뇌질환으로, 노인들의 인지 기능이 점차적으로 악화되어 가는 질...</td>\n",
       "      <td>증상</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>알츠하이머병 초기 단계의 초기 증상 중 기억력이 저하되는 것 외에 다른 증상이 있을까요?</td>\n",
       "      <td>알츠하이머병은 치매와 유사한 치매의 가장 흔한 유형이며, 노화와 다양한 원인에 의해...</td>\n",
       "      <td>증상</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>알츠하이머병에는 기억력 감퇴 이외에도 어떤 신체적인 이상 증상이 나타날 수 있는지 ...</td>\n",
       "      <td>알츠하이머병은 치매를 일으키는 가장 흔한 퇴행성 뇌질환으로, 서서히 진행되어 기억력...</td>\n",
       "      <td>증상</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>알츠하이머병의 주요 증상 중 가까운 기억들을 잘 떠올리지 못하는 것이 포함되는 건가요?</td>\n",
       "      <td>알츠하이머병은 뇌의 퇴행성 질환으로, 아밀로이드 단백질과 타우 단백질의 이상으로 인...</td>\n",
       "      <td>증상</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question  \\\n",
       "600                         알츠하이머병의 주요 증상을 자세히 설명해주세요.   \n",
       "601              알츠하이머병의 증상이 기억력 감퇴와 어떤 관련이 있는지 알려주세요.   \n",
       "602                      알츠하이머병의 증상은 어떤 것들이 있는지 알려주세요.   \n",
       "603             알츠하이머병에 걸렸을 때 일반인이 보통 어떤 증상을 경험하게 되나요?   \n",
       "604                     알츠하이머병의 증상 중에서 가장 흔한 것은 무엇인가요?   \n",
       "605        알츠하이머병의 주요 증상과 그 특징적인 증상들에 대해 자세한 설명을 해주세요.   \n",
       "606            알츠하이머병 환자가 느낄 수 있는 일반적인 증상이 어떤 것들이 있나요?   \n",
       "607  알츠하이머병 초기 단계의 초기 증상 중 기억력이 저하되는 것 외에 다른 증상이 있을까요?   \n",
       "608  알츠하이머병에는 기억력 감퇴 이외에도 어떤 신체적인 이상 증상이 나타날 수 있는지 ...   \n",
       "609   알츠하이머병의 주요 증상 중 가까운 기억들을 잘 떠올리지 못하는 것이 포함되는 건가요?   \n",
       "\n",
       "                                                answer intention  \n",
       "600  알츠하이머병은 치매를 일으키는 퇴행성 뇌질환으로, 주로 노인들에게서 발생합니다.알츠...        증상  \n",
       "601  알츠하이머병은 치매의 대표적인 원인으로 알려져 있는 신경퇴행성 질환입니다.알츠하이머...        증상  \n",
       "602  치매는 뇌세포의 파괴로 인해 뇌 기능의 장애가 발생하는 퇴행성 질환이며, 정상적인 ...        증상  \n",
       "603  알츠하이머병은 치매의 원인으로 알려져 있지만, 사실은 아밀로이드의 축적과 관련이 있...        증상  \n",
       "604  알츠하이머병은 노인들 사이에서 가장 흔한 치매의 원인으로 알려져 있습니다.알츠하이머...        증상  \n",
       "605  알츠하이머병은 신경학적인 장애를 일으키는 알츠하이머병의 심각한 퇴행성 뇌 질환입니다...        증상  \n",
       "606  알츠하이머병은 퇴행성 뇌질환으로, 노인들의 인지 기능이 점차적으로 악화되어 가는 질...        증상  \n",
       "607  알츠하이머병은 치매와 유사한 치매의 가장 흔한 유형이며, 노화와 다양한 원인에 의해...        증상  \n",
       "608  알츠하이머병은 치매를 일으키는 가장 흔한 퇴행성 뇌질환으로, 서서히 진행되어 기억력...        증상  \n",
       "609  알츠하이머병은 뇌의 퇴행성 질환으로, 아밀로이드 단백질과 타우 단백질의 이상으로 인...        증상  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[600:610]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "question                              알츠하이머병과 치매는 서로 다른 질병인가요?\n",
       "answer       알츠하이머병은 신경퇴행성 질환으로, 기억력 저하와 인지 기능 손상을 초래합니다.알츠...\n",
       "intention                                                   증상\n",
       "Name: 550, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[550]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fileName': 'HC-A-02138665', 'disease_category': '뇌신경정신질환', 'disease_name': {'kor': '알츠하이머병', 'eng': \"Alzheimer's disease\"}, 'department': ['정신건강의학과', '신경과', '신경외과'], 'intention': '정의', 'answer': {'intro': '알츠하이머병은 신경퇴행성질환의 일종으로, 뇌의 신경세포 소실로 인해 기억력이 손상되는 질환입니다. 이 질병은 서서히 진행되며, 환자는 자신의 기억력을 잃게 됩니다.', 'body': '알츠하이머병은 노인들 사이에서 가장 흔하게 발병하는 치매로, 기억상실과 같은 인지능력 저하가 특징입니다. 일부 환자는 새로운 기억이나 문제 해결 능력이 감소하는 특징을 보이며, 다른 환자들은 기억력을 잃은 후에도 언어기능이나 판단력에는 영향이 없을 수 있습니다.', 'conclusion': '알츠하이머병을 관리하기 위해 기억력과 인지능력을 보존하기 위해 다양한 치료 방법이 있습니다. 이러한 치료 전략은 환자의 인지기능 손실을 지연시키고 일상생활을 유지하는데 도움을 줄 수 있습니다.'}, 'num_of_words': 76}\n"
     ]
    }
   ],
   "source": [
    "with open(a_data[1000], 'r', encoding='utf-8') as file:\n",
    "    json_data = json.load(file)\n",
    "    print(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "알츠하이머병 치료에는 어떤 방법들이 있는지 자세히 알고 싶어요.\n"
     ]
    }
   ],
   "source": [
    "with open(q_data[1000], 'r', encoding='utf-8') as file:\n",
    "    json_data = json.load(file)\n",
    "    print(json_data['question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>intention</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>알츠하이머병을 초기에 치료하면 어떤 점이 좋을까요?</td>\n",
       "      <td>알츠하이머병은 주로 노인들에서 발견되는 치매의 가장 흔한 형태입니다. 이 질병은 최...</td>\n",
       "      <td>치료</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>알츠하이머병을 치료하기 위한 다른 치료법은 없을까요?</td>\n",
       "      <td>알츠하이머병은 뇌 조직의 이상으로 인한 퇴행성 신경 질환으로, 주로 노년층에서 발생...</td>\n",
       "      <td>치료</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>알츠하이머병 치료에 있어서 가장 효과적인 방법은 무엇인가요?</td>\n",
       "      <td>알츠하이머병은 노인들에게서 흔히 발생하는 치매의 한 형태입니다. 아밀로이드 단백질과...</td>\n",
       "      <td>치료</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>알츠하이머병을 치료하는데 있어서 어떤 종류의 약물이 사용되는지 자세히 알려주세요.</td>\n",
       "      <td>알츠하이머병은 노인들이 흔히 겪는 치매를 일으키는 퇴행성 신경질환입니다. 뇌세포에 ...</td>\n",
       "      <td>치료</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>알츠하이머병을 치료하기 위해 주로 사용되는 치료법은 무엇인가요?</td>\n",
       "      <td>알츠하이머병은 현재까지의 많은 연구를 통해 예방과 조기 진단을 통해 진행을 억제할 ...</td>\n",
       "      <td>치료</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          question  \\\n",
       "995                   알츠하이머병을 초기에 치료하면 어떤 점이 좋을까요?   \n",
       "996                  알츠하이머병을 치료하기 위한 다른 치료법은 없을까요?   \n",
       "997              알츠하이머병 치료에 있어서 가장 효과적인 방법은 무엇인가요?   \n",
       "998  알츠하이머병을 치료하는데 있어서 어떤 종류의 약물이 사용되는지 자세히 알려주세요.   \n",
       "999            알츠하이머병을 치료하기 위해 주로 사용되는 치료법은 무엇인가요?   \n",
       "\n",
       "                                                answer intention  \n",
       "995  알츠하이머병은 주로 노인들에서 발견되는 치매의 가장 흔한 형태입니다. 이 질병은 최...        치료  \n",
       "996  알츠하이머병은 뇌 조직의 이상으로 인한 퇴행성 신경 질환으로, 주로 노년층에서 발생...        치료  \n",
       "997  알츠하이머병은 노인들에게서 흔히 발생하는 치매의 한 형태입니다. 아밀로이드 단백질과...        치료  \n",
       "998  알츠하이머병은 노인들이 흔히 겪는 치매를 일으키는 퇴행성 신경질환입니다. 뇌세포에 ...        치료  \n",
       "999  알츠하이머병은 현재까지의 많은 연구를 통해 예방과 조기 진단을 통해 진행을 억제할 ...        치료  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_csv(\"Alz.csv\", sep=',')\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      알츠하이머병의 원인으로 매일 소주를 섭취하는 것이 언급되고 있는데, 이에 대한 근거...\n",
       "1                         알츠하이머병이라는 질병은 유전적 영향을 받는 것인가요?\n",
       "2                     알츠하이머병의 발생 원인에 대한 연구나 발견이 진행 중인가요?\n",
       "3              알츠하이머병의 발병과 관련하여 뇌의 노화로 인한 증상과 원인을 알려주세요.\n",
       "4                    알츠하이머병의 원인과 관련된 연구 결과가 있을까요? 알려주세요.\n",
       "                             ...                        \n",
       "995                         알츠하이머병을 초기에 치료하면 어떤 점이 좋을까요?\n",
       "996                        알츠하이머병을 치료하기 위한 다른 치료법은 없을까요?\n",
       "997                    알츠하이머병 치료에 있어서 가장 효과적인 방법은 무엇인가요?\n",
       "998        알츠하이머병을 치료하는데 있어서 어떤 종류의 약물이 사용되는지 자세히 알려주세요.\n",
       "999                  알츠하이머병을 치료하기 위해 주로 사용되는 치료법은 무엇인가요?\n",
       "Name: question, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = df['question']\n",
    "answer = df['answer']\n",
    "df['question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import konlpy.tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "from mecab import MeCab\n",
    "\n",
    "# 형태소 분석기\n",
    "mecab = MeCab()\n",
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mecab import MeCab\n",
    "mecab = MeCab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('알츠하이머병', 'NNG'), ('은', 'JX'), ('기억력', 'NNG'), ('과', 'JC'), ('판단력', 'NNG'), ('을', 'JKO'), ('담당', 'NNG'), ('하', 'XSV'), ('는', 'ETM'), ('뇌', 'NNG'), ('의', 'JKG'), ('인지', 'NNG'), ('기능', 'NNG'), ('에', 'JKB'), ('손상', 'NNG'), ('을', 'JKO'), ('초래', 'NNG'), ('하', 'XSV'), ('는', 'ETM'), ('퇴행', 'NNG'), ('성', 'XSN'), ('신경', 'NNG'), ('질환', 'NNG'), ('입니다', 'VCP+EF'), ('.', 'SF'), ('알츠하이머병', 'NNG'), ('은', 'JX'), ('주로', 'MAG'), ('기억력', 'NNG'), ('저하', 'NNG'), ('가', 'JKS'), ('특징', 'NNG'), ('적', 'XSN'), ('인', 'VCP+ETM'), ('증상', 'NNG'), ('입니다', 'VCP+EF'), ('.', 'SF'), ('처음', 'NNG'), ('에', 'JKB'), ('는', 'JX'), ('최근', 'NNG'), ('에', 'JKB'), ('발생', 'NNG'), ('한', 'XSV+ETM'), ('일', 'NNG'), ('을', 'JKO'), ('기억', 'NNG'), ('하', 'XSV'), ('는', 'ETM'), ('능력', 'NNG'), ('이', 'JKS'), ('점점', 'MAG'), ('약해', 'VA+EC'), ('지', 'VX'), ('다가', 'EC'), (',', 'SC'), ('이후', 'NNG'), ('에', 'JKB'), ('는', 'JX'), ('완전히', 'MAG'), ('상실', 'NNG'), ('됩니다', 'XSV+EF'), ('.', 'SF'), ('이러', 'XR'), ('한', 'XSA+ETM'), ('증상', 'NNG'), ('들', 'XSN'), ('은', 'JX'), ('환자', 'NNG'), ('의', 'JKG'), ('일상', 'NNG'), ('생활', 'NNG'), ('과', 'JC'), ('사회', 'NNG'), ('활동', 'NNG'), ('에', 'JKB'), ('큰', 'VA+ETM'), ('영향', 'NNG'), ('을', 'JKO'), ('주', 'VV'), ('며', 'EC'), (',', 'SC'), ('가족', 'NNG'), ('과', 'JC'), ('사회', 'NNG'), ('에', 'JKB'), ('부정', 'NNG'), ('적', 'XSN'), ('인', 'VCP+ETM'), ('영향', 'NNG'), ('을', 'JKO'), ('미칠', 'VV+ETM'), ('수', 'NNB'), ('있', 'VV'), ('습니다', 'EF'), ('.', 'SF'), ('알츠하이머병', 'NNG'), ('은', 'JX'), ('초기', 'NNG'), ('에', 'JKB'), ('는', 'JX'), ('환자', 'NNG'), ('들', 'XSN'), ('에게', 'JKB'), ('많', 'VA'), ('은', 'ETM'), ('고통', 'NNG'), ('을', 'JKO'), ('안겨', 'VV+EC'), ('주', 'VX'), ('며', 'EC'), (',', 'SC'), ('가족', 'NNG'), ('들', 'XSN'), ('에게', 'JKB'), ('는', 'JX'), ('죄책감', 'NNG'), ('을', 'JKO'), ('유발', 'NNG'), ('할', 'XSV+ETM'), ('수', 'NNB'), ('있', 'VV'), ('는', 'ETM'), ('질병', 'NNG'), ('입니다', 'VCP+EF'), ('.', 'SF'), ('조기', 'NNG'), ('발견', 'NNG'), ('과', 'JC'), ('진단', 'NNG'), ('은', 'JX'), ('병', 'NNG'), ('의', 'JKG'), ('진행', 'NNG'), ('을', 'JKO'), ('예방', 'NNG'), ('하', 'XSV'), ('고', 'EC'), ('환자', 'NNG'), ('와', 'JC'), ('가족', 'NNG'), ('에게', 'JKB'), ('큰', 'VA+ETM'), ('도움', 'NNG'), ('이', 'JKS'), ('됩니다', 'VV+EF'), ('.', 'SF')]\n"
     ]
    }
   ],
   "source": [
    "# text = question[100]\n",
    "text= answer[800]\n",
    "pos = mecab.pos(text)\n",
    "print(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "re.compile(r'[^ ?,.!A-Za-z0-9가-힣+]', re.UNICODE)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# 한글, 영어, 숫자, 공백, ?!.,을 제외한 나머지 문자 제거\n",
    "korean_pattern = r'[^ ?,.!A-Za-z0-9가-힣+]'\n",
    "\n",
    "# 패턴 컴파일\n",
    "normalizer = re.compile(korean_pattern)\n",
    "normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "수정 전: 알츠하이머병의 원인이 30대에서 더 쉽게 찾아볼 수 있는 이유가 있나요?\n",
      "수정 후: 알츠하이머병의 원인이 30대에서 더 쉽게 찾아볼 수 있는 이유가 있나요?\n",
      "수정 전: 알츠하이머병은 노화된 단백질이 뇌세포를 파괴하는 퇴행성 신경 질환입니다. 이 질환은 노화에 따른 뇌신경세포의 죽음으로 인해 발생하며, 정확한 원인은 알려져 있지 않습니다. 초기 증상은 경미한 기억 장애부터 언어 장애, 행동 변화 등으로 나타납니다.알츠하이머병은 점진적인 기억력 감퇴와 언어 장애, 실행증(실어증), 시공간능력 장애, 행동 및 정신행동 증상 등을 보입니다. 진행되면서 불안, 우울, 난폭성 등과 같은 정신증상도 나타날 수 있습니다.알츠하이머병은 치료가 불가능한 질환이지만, 조기에 진단을 받고 적절한 치료와 관리를 시작하는 것이 중요합니다. 이를 통해 삶의 질을 향상시키고 증상을 완화시킬 수 있습니다.\n",
      "수정 후: 알츠하이머병은 노화된 단백질이 뇌세포를 파괴하는 퇴행성 신경 질환입니다. 이 질환은 노화에 따른 뇌신경세포의 죽음으로 인해 발생하며, 정확한 원인은 알려져 있지 않습니다. 초기 증상은 경미한 기억 장애부터 언어 장애, 행동 변화 등으로 나타납니다.알츠하이머병은 점진적인 기억력 감퇴와 언어 장애, 실행증실어증, 시공간능력 장애, 행동 및 정신행동 증상 등을 보입니다. 진행되면서 불안, 우울, 난폭성 등과 같은 정신증상도 나타날 수 있습니다.알츠하이머병은 치료가 불가능한 질환이지만, 조기에 진단을 받고 적절한 치료와 관리를 시작하는 것이 중요합니다. 이를 통해 삶의 질을 향상시키고 증상을 완화시킬 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "print(f'수정 전: {question[20]}')\n",
    "print(f'수정 후: {normalizer.sub(\"\", question[20])}')\n",
    "print(f'수정 전: {answer[20]}')\n",
    "print(f'수정 후: {normalizer.sub(\"\", answer[20])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'알츠하이머병 예방을 위해 매일 소주 한 병씩 섭취하는 것이 권장되는 이유가 있나요?'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normalize(sentence):\n",
    "    return normalizer.sub(\"\", sentence)\n",
    "\n",
    "normalize(question[200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['알츠하이머병',\n",
       " '의',\n",
       " '원인',\n",
       " '중',\n",
       " '에서',\n",
       " '노화',\n",
       " '외',\n",
       " '에',\n",
       " '다른',\n",
       " '요인',\n",
       " '도',\n",
       " '알려',\n",
       " '주',\n",
       " '세요',\n",
       " '.']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mecab.morphs(normalize(question[100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한글 전처리를 함수화\n",
    "def clean_text(sentence, tagger):\n",
    "    sentence = normalize(sentence)\n",
    "    sentence = tagger.morphs(sentence)\n",
    "    sentence = ' '.join(sentence)\n",
    "    sentence = sentence.lower()\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'알츠하이머병 은 노화 된 단백질 이 뇌 세포 를 파괴 하는 퇴 행성 신경 질환 입니다 . 이 질환 은 노화 에 따른 뇌신경 세포 의 죽음 으로 인해 발생 하며 , 정확한 원인 은 알려져 있지 않습니다 . 초기 증상 은 경미한 기억 장애 부터 언어 장애 , 행동 변화 등 으로 나타납니다 . 알츠하이머병 은 점진 적 인 기억 력 감퇴 와 언어 장애 , 실행증 실어증 , 시공간 능력 장애 , 행동 및 정신 행동 증상 등 을 보입니다 . 진행 되면서 불안 , 우울 , 난폭 성 등 과 같은 정신증 상도 나타날 수 있습니다 . 알츠하이머병 은 치료 가 불가능한 질환 이지만 , 조기 에 진단 을 받고 적절한 치료 와 관리 를 시작 하는 것 이 중요합니다 . 이를 통해 삶 의 질 을 향상 시키고 증상 을 완화 시킬 수 있습니다 .'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 한글\n",
    "clean_text(question[20], okt)\n",
    "clean_text(answer[20], okt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1000)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(question), len(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [clean_text(sent, okt) for sent in question.values[:1000]]\n",
    "answers = [clean_text(sent, okt) for sent in answer.values[:1000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['알츠하이머병 의 원인 으로 매일 소주 를 섭취 하는 것 이 언급 되고 있는데 , 이 에 대한 근거 가 있는지 알려주세요 .',\n",
       " '알츠하이머병 이라는 질병 은 유전 적 영향 을 받는 것 인가요 ?',\n",
       " '알츠하이머병 의 발생 원인 에 대한 연구 나 발견 이 진행 중 인가요 ?',\n",
       " '알츠하이머병 의 발병 과 관련 하여 뇌 의 노화 로 인한 증상 과 원인 을 알려주세요 .',\n",
       " '알츠하이머병 의 원인 과 관련 된 연구 결과 가 있을까요 ? 알려주세요 .']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['알츠하이머병 의 정확한 원인 은 아직 밝혀지지 않았지만 , 연구 들 이 알츠하이머병 의 발병 기전 에 대해 논의 하고 있습니다 . 일부 연구 에 따르면 , 유전 적 인 요소 와 뇌 의 기능 손상 이 관련 되어 있다고 알려져 있습니다 . 알츠하이머병 은 아밀로이드 베타 단백질 과 타우 단백질 의 과도 한 생 성 , 뇌 세포 의 비정상 적 인 활동 , 뇌 조직 의 변화 로 인해 발생 하는 것 으로 생각 되고 있습니다 . 이러한 변화 가 알츠하이머병 의 발병 위험 을 증가 시키고 , 병 의 진행 을 가속 화 시킨다는 것 입니다 . 알츠하이머병 의 발병 과 관련 된 위험 요소 에 대해 서는 더 많은 연구 와 조사 가 필요합니다 . 더 많은 연구 와 자료 수집 을 통해 알츠하이머병 에 대한 더 많은 이해 와 예방 방법 이 개발 될 것 으로 기대 됩니다 .',\n",
       " '알츠하이머병 은 현재 까지 완전한 원인 이 밝혀지지 않았습니다 . 알츠하이머병 은 아직 완전히 이해 되지 않았지만 , 연구 결과 에 따르면 유전 적 인 요소 와 다양한 환경 적 인 요인 이 이 질환 을 일으키는 역할 을 한다고 알려져 있습니다 . 특히 , 아밀로이드 베타 단백질 의 비정상 적 인 축적 이 알츠하이머병 과 관련 이 있는 것 으로 알려져 있습니다 . 이 외 에도 나이 , 노화 , 고혈압 , 당뇨병 , 그리고 흡연 등 과 같은 다른 요인 들 도 알츠하이머병 발병 과 연관 성 이 있을 수 있습니다 . 더 많은 연구 와 조사 를 통해 알츠하이머병 의 원인 을 파악 하고 예방 방법 을 개발 할 필요 가 있습니다 .',\n",
       " '알츠하이머병 은 치매 를 일으키는 가장 흔한 퇴 행성 뇌 질환 으로 , 1907년 독일 의사 알 로이스 알츠하이머 에 의해 처음 으로 보고 되었습니다 . 이 질환 의 원인 에 대해 서는 현재 까지 명확한 답 은 없으나 , 치매 발생 의 위험 요소 와 관련 하여 몇 가지 위험 요인 이 알려져 있습니다 . 일반 적 으로 , 가장 잘 알려진 요인 중 하나 는 고령 입니다 . 고령 은 치매 의 발병 위험 을 증가 시키는 가장 큰 위험 요소 로 알려져 있습니다 . 또한 , 가족 력 이 있는 경우 알츠하이머병 발생 위험 이 높아집니다 . 연구 에 따르면 , 조 발성 가족 성 알츠하이머병 은 주로 65 세 이전 에 발생 하는 반면 , 노인성 알츠하이머병 은 주로 65 세 이후 에 발생 한다고 합니다 . 이 외 에도 , 여성 들 은 65 세 이후 에 더 높은 위험 에 노출 되는 경향 이 있으며 , 우울증 이나 두부 손상 과 같은 선행 요인 도 알츠하이머병 발병 위험 을 증가 시킬 수 있습니다 . 또한 , 고혈압 , 당뇨 , 고지혈증 , 비만 과 같은 심 혈관 질환 도 알츠하이머병 의 발병 위험 을 증가 시킬 수 있습니다 . 이 외 에도 , 다양한 질병 들 도 알츠하이머병 발병 위험 을 증가 시킬 수 있습니다 . 하지만 아직 까지 특정한 원인 에 대해 명확한 답변 은 없습니다 . 알츠하이머병 의 정확한 원인 은 아직 까지 연구 중이 지만 , 치매 와 관련 된 위험 요소 들 과 함께 유전 적 요소 , 환경 적 요소 들 이 복합 적 으로 작용 하여 발병 한다는 것 이 유력한 가설 로 여겨집니다 .',\n",
       " '알츠하이머병 은 현재 까지 그 발병 원인 에 대한 완벽한 해명 은 아직 이루어지지 않았습니다 . 알츠하이머병 의 발병 기전 은 아직 정확하게 밝혀지지 않았지만 , 유전 적 인 요인 과 다양한 환경 적 요소 들 이 서로 작용 하여 발생 한다는 가설 이 제시 되고 있습니다 . 대표 적 으로 아밀로이드 베타 단백질 의 쌓임과 신경세포 의 손상 이 알츠하이머병 의 발병 원인 으로 알려져 있으며 , 아밀로이드 베타 단백질 의 침착 이 발생 과 관련 이 있는 것 으로 추정 됩니다 . 또한 , 알츠하이머병 은 신경세포 사이 의 신호 전송 과 관련 된 여러 가지 경로 에서 뇌 손상 이 일어나기 때문 에 다른 뇌 질환 과도 연관 되어 있을 수 있습니다 . 그러나 이러한 환경 적 요소 들 과 유전 적 요인 들 은 아직 완전히 규명 되지는 않았으며 , 개인 의 특성 이나 환경 적 요소 에 따라 발병 가능성 이 달라질 수 있습니다 . 알츠하이머병 은 아직 까지 정확한 원인 이 밝혀지지 않았지만 , 유전 적 요인 과 다양한 환경 적 요소 들 이 복합 적 으로 작용 하여 발병 한다는 점 은 분명한 사실 입니다 . 추가 적 인 연구 가 필요하며 , 예방 및 치료 방법 을 개발 하기 위해 노력 이 필요합니다 .',\n",
       " '알츠하이머병 은 복잡한 질환 으로 , 아직도 원인 이 완전히 밝혀진 것 은 아닙니다 . 그러나 연 구 결과 에 따르면 , 알츠하이머병 은 단일 원인 으로 발생 하지 않고 여러 요인 들 이 복합 적 으로 작용 하는 것 으로 알려져 있습니다 . 알츠하이머병 은 21 번 염색체 에 위치 한 21 번 염색체 의 이상 , 14 번 염색체 의 ps 1 유전자 변 이나 19 번 염색체 의 ps 2 유전자 변 이 도 주요 원인 으로 보고 되고 있습니다 . 또한 고령 , 다운증후군 , 저 학력 , 가족 력 , 심 혈관 질환 등 다양한 위험 요인 이 있습니다 . 더불어 노화 와 더불어 콜린 계통 의 활성화 도 감소 되는 것 으로 알려져 있습니다 . 알츠하이머병 은 진행 성 치매 로 , 초기 에는 주로 기억 력 저하 와 인식력 의 감퇴 가 나타납니다 . 그러나 병 이 진행 됨에 따라 일상생활 기능 손상 과 판단력 저하 가 더욱 심해집니다 . 치매 환자 는 말 이나 행동 이 느렸을 뿐 아니라 최근 기억 력 상실 과 언어 장애 가 자주 동반 됩니다 . 수면 이상 , 성격 변화 , 우울증 , 망상 , 환각 , 정신증 등 의 정신 증상 도 나타날 수 있습니다 . 알츠하이머병 은 아직 정확한 원인 은 밝혀지지 않았지만 , 유전 적 인 요소 와 환경 적 인 요인 이 복합 적 으로 작용 하여 발병 할 것 으로 예상 됩니다 . 유전 적 인 위험 요소 가 있는 경우 병 이 발현 되기 쉬울 수 있지만 , 그렇지 않은 경우 에도 발병 할 가능성 이 높습니다 . 알츠하이머병 은 발병 과정 에서 다양한 위험 요인 들 이 함께 작용 하는 것 으로 알려져 있습니다 . 노화 , 다운증후군 , 저 학력 , 가족 력 , 심 혈관 질환 등 이 알츠하이머병 의 위험 요소 로 알려져 있으며 , 노화 와 더불어 콜린 계통 의 손상 은 진행 을 가속 화 시킬 수 있습니다 . 알츠하이머병 이 가장 일찍 인지 되는 이유 는 최근 일 에 대한 기억 력 저하 뿐 아니라 최근 의 사건 들 에 대한 기억 력 까지 저하 된다는 점 입니다 . 다른 정신 증상 으로는 망상 , 환각 , 불안 , 공격성 증가 , 우울증 등 이 동반 될 수 있습니다 . 알츠하이머병 은 아직 정확한 원인 을 찾기 어려운 질병 입니다 . 유전 적 인 요소 와 환경 적 인 요인 들 이 상호 작용 하여 발병 하는 것 으로 알려져 있으며 , 다양한 위험 요인 들 이 서로 연결 되어 있습니다 . 이 질병 은 알츠하이머병 이 가장 일찍 인지 되는 이유 는 최근 일 에 대한 기억 력 저하 뿐 아니라 최근 의 사건 들 에 대한 기억 력 까지 저하 된다는 점 입니다 . 따라서 , 알츠하이머병 의 위험 요인 을 최소 화 하고 건강한 라이프스타일 을 유지 하는 것 이 중요합니다 . 건강한 식 습관 과 꾸준한 신체 운동 , 인지 행동 요법 을 통해 삶 의 질 을 개선 하는 것 이 예방 에 도움 이 됩니다 .']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Komoran\n",
    "import numpy as np\n",
    "\n",
    "komoran = Komoran()\n",
    "text = \"오늘 날씨는 구름이 많아요.\"\n",
    "\n",
    "# 문장에서 명사만 추출\n",
    "nouns = komoran.nouns(text)\n",
    "\n",
    "# 단어 사전 구축 및 단어별 인덱스 부여\n",
    "dics = {}\n",
    "for word in nouns:\n",
    "  if word not in dics.keys(): # 이미 저장된 단어는 다시 저장하지 않음\n",
    "    dics[word] = len(dics) # key가 단어, value가 인덱스\n",
    "\n",
    "# 원-핫 벡터 차원의 크기는 단어 사전의 크기\n",
    "nb_classes = len(dics)\n",
    "\n",
    "# 단어별 인덱스값을 리스트로 변환\n",
    "targets = list(dics.values())\n",
    "\n",
    "# 원-핫 벡터 생성\n",
    "one_hot_targets = np.eye(nb_classes) # nb_classes 크기대로 단위행렬을 반환\n",
    "one_hot_targets = one_hot_targets[targets] # 단위행렬을 단어 사전의 순서에 맞게 정렬\n",
    "print(one_hot_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.2.0-cp37-cp37m-win_amd64.whl (24.0 MB)\n",
      "     ---------------------------------------- 24.0/24.0 MB 9.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\koreavc\\anaconda3\\envs\\pororo\\lib\\site-packages (from gensim) (1.21.5)\n",
      "Collecting smart-open>=1.8.1\n",
      "  Downloading smart_open-7.0.4-py3-none-any.whl (61 kB)\n",
      "     ---------------------------------------- 61.2/61.2 kB ? eta 0:00:00\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\koreavc\\anaconda3\\envs\\pororo\\lib\\site-packages (from gensim) (1.7.3)\n",
      "Collecting Cython==0.29.28\n",
      "  Downloading Cython-0.29.28-py2.py3-none-any.whl (983 kB)\n",
      "     ------------------------------------- 983.8/983.8 kB 10.4 MB/s eta 0:00:00\n",
      "Collecting wrapt\n",
      "  Downloading wrapt-1.16.0-cp37-cp37m-win_amd64.whl (37 kB)\n",
      "Installing collected packages: wrapt, Cython, smart-open, gensim\n",
      "  Attempting uninstall: Cython\n",
      "    Found existing installation: Cython 3.0.10\n",
      "    Uninstalling Cython-3.0.10:\n",
      "      Successfully uninstalled Cython-3.0.10\n",
      "Successfully installed Cython-0.29.28 gensim-4.2.0 smart-open-7.0.4 wrapt-1.16.0\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from konlpy.tag import Komoran\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) 말뭉치 데이터 읽기 시작\n",
      "1) 말뭉치 데이터 읽기 완료 :  0.0\n",
      "2) 형태소에서 명사만 추출 시작\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16960\\3700389545.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mkomoran\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKomoran\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'chatbot_data.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mdocs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mkomoran\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnouns\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mquestion\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'2) 형태소에서 명사만 추출 완료 : '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16960\\3700389545.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mkomoran\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKomoran\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'chatbot_data.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mdocs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mkomoran\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnouns\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mquestion\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'2) 형태소에서 명사만 추출 완료 : '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "\n",
    "# 학습 시간 측정 시작\n",
    "start = time.time()\n",
    "\n",
    "# 리뷰 파일 읽어오기\n",
    "print('1) 말뭉치 데이터 읽기 시작')\n",
    "print('1) 말뭉치 데이터 읽기 완료 : ', time.time() - start)\n",
    "\n",
    "# 문장 단위로 명사만 추출해 학습 입력 데이터로 만듦\n",
    "print('2) 형태소에서 명사만 추출 시작')\n",
    "komoran = Komoran()\n",
    "df=pd.read_csv('chatbot_data.csv')\n",
    "docs = [komoran.nouns(question[1]) for question in df]\n",
    "print('2) 형태소에서 명사만 추출 완료 : ', time.time() - start)\n",
    "\n",
    "# Word2Vec 모델 학습\n",
    "print('3) Word2Vec 모델 학습 시작')\n",
    "model = Word2Vec(sentences=docs, window=4, hs=1, min_count=2, sg=1)\n",
    "print('3) Word2Vec 모델 학습 완료 : ', time.time() - start)\n",
    "\n",
    "# 모델 저장\n",
    "print('4) 학습된 모델 저장 시작')\n",
    "model.save('nvmc.model')\n",
    "print('4) 학습된 모델 저장 완료 : ', time.time() - start)\n",
    "\n",
    "# 학습된 말뭉치 수, 코퍼스 내 전체 단어 수\n",
    "print(\"corpus_count : \", model.corpus_count)\n",
    "print(\"corpus_total_words : \", model.corpus_total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.11.0-cp37-cp37m-win_amd64.whl (1.9 kB)\n",
      "Collecting tensorflow-intel==2.11.0\n",
      "  Downloading tensorflow_intel-2.11.0-cp37-cp37m-win_amd64.whl (266.3 MB)\n",
      "     -------------------------------------- 266.3/266.3 MB 3.4 MB/s eta 0:00:00\n",
      "Collecting keras<2.12,>=2.11.0\n",
      "  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
      "     ---------------------------------------- 1.7/1.7 MB 7.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\koreavc\\anaconda3\\envs\\pororo\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.16.0)\n",
      "Collecting tensorboard<2.12,>=2.11\n",
      "  Downloading tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n",
      "     ---------------------------------------- 6.0/6.0 MB 6.6 MB/s eta 0:00:00\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\koreavc\\anaconda3\\envs\\pororo\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (24.0)\n",
      "Collecting protobuf<3.20,>=3.9.2\n",
      "  Downloading protobuf-3.19.6-cp37-cp37m-win_amd64.whl (896 kB)\n",
      "     -------------------------------------- 896.6/896.6 kB 5.6 MB/s eta 0:00:00\n",
      "Collecting flatbuffers>=2.0\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp37-cp37m-win_amd64.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 7.2 MB/s eta 0:00:00\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.62.2-cp37-cp37m-win_amd64.whl (4.5 MB)\n",
      "     ---------------------------------------- 4.5/4.5 MB 10.7 MB/s eta 0:00:00\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "     ---------------------------------------- 65.5/65.5 kB 3.7 MB/s eta 0:00:00\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "     ---------------------------------------- 26.4/26.4 MB 6.0 MB/s eta 0:00:00\n",
      "Collecting tensorflow-estimator<2.12,>=2.11.0\n",
      "  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
      "     -------------------------------------- 439.2/439.2 kB 2.0 MB/s eta 0:00:00\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "     -------------------------------------- 133.7/133.7 kB 4.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: setuptools in c:\\users\\koreavc\\anaconda3\\envs\\pororo\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (65.6.3)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\koreavc\\anaconda3\\envs\\pororo\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.16.0)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "     ---------------------------------------- 57.5/57.5 kB 1.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\koreavc\\anaconda3\\envs\\pororo\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.21.5)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\koreavc\\anaconda3\\envs\\pororo\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (4.7.1)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting h5py>=2.9.0\n",
      "  Downloading h5py-3.8.0-cp37-cp37m-win_amd64.whl (2.6 MB)\n",
      "     ---------------------------------------- 2.6/2.6 MB 9.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\koreavc\\anaconda3\\envs\\pororo\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.11.0->tensorflow) (0.38.4)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.32.0-py2.py3-none-any.whl (195 kB)\n",
      "     -------------------------------------- 195.5/195.5 kB 6.0 MB/s eta 0:00:00\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "     -------------------------------------- 781.3/781.3 kB 9.9 MB/s eta 0:00:00\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Downloading Werkzeug-2.2.3-py3-none-any.whl (233 kB)\n",
      "     -------------------------------------- 233.6/233.6 kB 4.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\koreavc\\anaconda3\\envs\\pororo\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.31.0)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.4.4-py3-none-any.whl (94 kB)\n",
      "     ---------------------------------------- 94.2/94.2 kB 5.6 MB/s eta 0:00:00\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "     ------------------------------------- 181.3/181.3 kB 10.7 MB/s eta 0:00:00\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.4.0-py3-none-any.whl (9.5 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\koreavc\\anaconda3\\envs\\pororo\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (6.7.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\koreavc\\anaconda3\\envs\\pororo\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2024.7.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\koreavc\\anaconda3\\envs\\pororo\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\koreavc\\anaconda3\\envs\\pororo\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.26.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\koreavc\\anaconda3\\envs\\pororo\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.3.2)\n",
      "Collecting MarkupSafe>=2.1.1\n",
      "  Downloading MarkupSafe-2.1.5-cp37-cp37m-win_amd64.whl (17 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\koreavc\\anaconda3\\envs\\pororo\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.15.0)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6\n",
      "  Downloading pyasn1-0.5.1-py2.py3-none-any.whl (84 kB)\n",
      "     ---------------------------------------- 84.9/84.9 kB 4.7 MB/s eta 0:00:00\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "     -------------------------------------- 151.7/151.7 kB 4.6 MB/s eta 0:00:00\n",
      "Installing collected packages: tensorboard-plugin-wit, libclang, flatbuffers, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, pyasn1, protobuf, opt-einsum, oauthlib, MarkupSafe, keras, h5py, grpcio, google-pasta, gast, cachetools, astunparse, absl-py, werkzeug, rsa, requests-oauthlib, pyasn1-modules, markdown, google-auth, google-auth-oauthlib, tensorboard, tensorflow-intel, tensorflow\n",
      "Successfully installed MarkupSafe-2.1.5 absl-py-2.1.0 astunparse-1.6.3 cachetools-5.4.0 flatbuffers-24.3.25 gast-0.4.0 google-auth-2.32.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.62.2 h5py-3.8.0 keras-2.11.0 libclang-18.1.1 markdown-3.4.4 oauthlib-3.2.2 opt-einsum-3.3.0 protobuf-3.19.6 pyasn1-0.5.1 pyasn1-modules-0.3.0 requests-oauthlib-2.0.0 rsa-4.9 tensorboard-2.11.2 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.11.0 tensorflow-estimator-2.11.0 tensorflow-intel-2.11.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.3.0 werkzeug-2.2.3\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Q            A  label\n",
       "0           12시 땡!   하루가 또 가네요.      0\n",
       "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
       "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "4          PPL 심하네   눈살이 찌푸려지죠.      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 필요한 모듈 임포트\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import preprocessing\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Dense, Dropout, Conv1D, GlobalMaxPool1D, concatenate\n",
    "\n",
    "# 데이터 읽어오기\n",
    "data = pd.read_csv(\"chatbot_data.csv\")\n",
    "features = data['Q'].tolist()\n",
    "labels = data['label'].tolist()\n",
    "data.head()\n",
    "#label 0,1,2 : 일상다반사/부정/긍정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, LSTM, SimpleRNN\n",
    "\n",
    "# time step만큼 시퀀스 데이터 분리\n",
    "def split_sequence(sequence, step):\n",
    "  x, y = list(), list()\n",
    "\n",
    "  for i in range(len(sequence)):\n",
    "    end_idx = i + step\n",
    "    if end_idx > len(sequence) - 1:\n",
    "      break\n",
    "\n",
    "    seq_x, seq_y = sequence[i:end_idx], sequence[end_idx]\n",
    "    x.append(seq_x)\n",
    "    y.append(seq_y)\n",
    "\n",
    "  return np.array(x), np.array(y)\n",
    "\n",
    "\n",
    "# sin 함수 학습 데이터\n",
    "x = [i for i in np.arange(start=-10, stop=10, step=0.1)]\n",
    "train_y = [np.sin(i) for i in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape x:(185, 15) / y:(185,)\n"
     ]
    }
   ],
   "source": [
    "# 하이퍼파라미터\n",
    "n_timesteps = 15\n",
    "n_features = 1\n",
    "\n",
    "# 시퀀스 나누기\n",
    "# train_x.shape => (samples, timesteps)\n",
    "# train_y.shape => (samples)\n",
    "train_x, train_y = split_sequence(train_y, step=n_timesteps)\n",
    "print(\"shape x:{} / y:{}\".format(train_x.shape, train_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x.shape = (185, 15, 1)\n",
      "train_y.shape = (185,)\n"
     ]
    }
   ],
   "source": [
    "# RNN 입력 벡터 크기를 맞추기 위해 벡터 차원 크기 변경\n",
    "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "train_x = train_x.reshape(train_x.shape[0], train_x.shape[1], n_features)\n",
    "print(\"train_x.shape = {}\".format(train_x.shape))\n",
    "print(\"train_y.shape = {}\".format(train_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KOREAVC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# RNN 모델 정의\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(units=10,\n",
    "                    return_sequences=False,\n",
    "                    input_shape=(n_timesteps, n_features)))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.2982\n",
      "Epoch 2/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1899 \n",
      "Epoch 3/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1357 \n",
      "Epoch 4/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0889 \n",
      "Epoch 5/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0644 \n",
      "Epoch 6/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0567 \n",
      "Epoch 7/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0381 \n",
      "Epoch 8/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0309 \n",
      "Epoch 9/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0228 \n",
      "Epoch 10/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0195 \n",
      "Epoch 11/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0180 \n",
      "Epoch 12/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0177 \n",
      "Epoch 13/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0145 \n",
      "Epoch 14/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0141 \n",
      "Epoch 15/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0124 \n",
      "Epoch 16/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0119 \n",
      "Epoch 17/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0101 \n",
      "Epoch 18/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0102 \n",
      "Epoch 19/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0084 \n",
      "Epoch 20/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 \n",
      "Epoch 21/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 \n",
      "Epoch 22/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0062 \n",
      "Epoch 23/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0059 \n",
      "Epoch 24/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0053 \n",
      "Epoch 25/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0043 \n",
      "Epoch 26/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0041 \n",
      "Epoch 27/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0039 \n",
      "Epoch 28/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0034 \n",
      "Epoch 29/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0034 \n",
      "Epoch 30/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0033 \n",
      "Epoch 31/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0028 \n",
      "Epoch 32/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0024 \n",
      "Epoch 33/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0022 \n",
      "Epoch 34/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0024 \n",
      "Epoch 35/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0021 \n",
      "Epoch 36/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0019 \n",
      "Epoch 37/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0019 \n",
      "Epoch 38/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0017 \n",
      "Epoch 39/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0016 \n",
      "Epoch 40/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0015 \n",
      "Epoch 41/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0014 \n",
      "Epoch 42/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0013 \n",
      "Epoch 43/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0014 \n",
      "Epoch 44/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0012 \n",
      "Epoch 45/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0012     \n",
      "Epoch 46/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0012 \n",
      "Epoch 47/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0012 \n",
      "Epoch 48/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011     \n",
      "Epoch 49/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.8413e-04 \n",
      "Epoch 50/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0010 \n",
      "Epoch 51/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0010 \n",
      "Epoch 52/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.1932e-04 \n",
      "Epoch 53/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.0651e-04 \n",
      "Epoch 54/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.5920e-04 \n",
      "Epoch 55/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.4911e-04 \n",
      "Epoch 56/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.0209e-04 \n",
      "Epoch 57/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.4602e-04 \n",
      "Epoch 58/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.3398e-04 \n",
      "Epoch 59/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.9508e-04 \n",
      "Epoch 60/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.4965e-04 \n",
      "Epoch 61/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.6515e-04 \n",
      "Epoch 62/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.2125e-04 \n",
      "Epoch 63/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.4540e-04 \n",
      "Epoch 64/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.5683e-04 \n",
      "Epoch 65/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.3188e-04 \n",
      "Epoch 66/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.4977e-04 \n",
      "Epoch 67/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.3090e-04 \n",
      "Epoch 68/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.1306e-04 \n",
      "Epoch 69/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.5246e-04 \n",
      "Epoch 70/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.3489e-04 \n",
      "Epoch 71/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.3822e-04 \n",
      "Epoch 72/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.0217e-04 \n",
      "Epoch 73/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.8082e-04 \n",
      "Epoch 74/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.5367e-04 \n",
      "Epoch 75/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.7424e-04 \n",
      "Epoch 76/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.7346e-04 \n",
      "Epoch 77/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.4677e-04 \n",
      "Epoch 78/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.1870e-04 \n",
      "Epoch 79/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.2089e-04 \n",
      "Epoch 80/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.2228e-04 \n",
      "Epoch 81/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.8907e-04 \n",
      "Epoch 82/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.7723e-04 \n",
      "Epoch 83/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.9274e-04 \n",
      "Epoch 84/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.6280e-04 \n",
      "Epoch 85/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.5521e-04 \n",
      "Epoch 86/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.4445e-04 \n",
      "Epoch 87/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.4805e-04 \n",
      "Epoch 88/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.3021e-04 \n",
      "Epoch 89/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.3010e-04 \n",
      "Epoch 90/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.3755e-04 \n",
      "Epoch 91/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.9840e-04 \n",
      "Epoch 92/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.8928e-04 \n",
      "Epoch 93/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.0625e-04 \n",
      "Epoch 94/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.7304e-04 \n",
      "Epoch 95/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.8179e-04 \n",
      "Epoch 96/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.7505e-04 \n",
      "Epoch 97/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.8032e-04 \n",
      "Epoch 98/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4469e-04 \n",
      "Epoch 99/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5358e-04 \n",
      "Epoch 100/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4194e-04 \n",
      "Epoch 101/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4627e-04 \n",
      "Epoch 102/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4527e-04 \n",
      "Epoch 103/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3966e-04 \n",
      "Epoch 104/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3126e-04 \n",
      "Epoch 105/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3670e-04 \n",
      "Epoch 106/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3809e-04 \n",
      "Epoch 107/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3122e-04 \n",
      "Epoch 108/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3870e-04 \n",
      "Epoch 109/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.2006e-04 \n",
      "Epoch 110/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1784e-04 \n",
      "Epoch 111/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1650e-04 \n",
      "Epoch 112/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1164e-04 \n",
      "Epoch 113/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0709e-04 \n",
      "Epoch 114/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0956e-04 \n",
      "Epoch 115/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1007e-04 \n",
      "Epoch 116/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.2099e-04 \n",
      "Epoch 117/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0093e-04 \n",
      "Epoch 118/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0602e-04 \n",
      "Epoch 119/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0976e-04 \n",
      "Epoch 120/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0251e-04 \n",
      "Epoch 121/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.4181e-05 \n",
      "Epoch 122/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.7893e-05 \n",
      "Epoch 123/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.8085e-05 \n",
      "Epoch 124/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0742e-04 \n",
      "Epoch 125/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0091e-04 \n",
      "Epoch 126/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0052e-04 \n",
      "Epoch 127/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0070e-04 \n",
      "Epoch 128/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0109e-04 \n",
      "Epoch 129/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.5023e-05 \n",
      "Epoch 130/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.4945e-05 \n",
      "Epoch 131/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.7715e-05 \n",
      "Epoch 132/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.0178e-05 \n",
      "Epoch 133/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.7824e-05 \n",
      "Epoch 134/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.4724e-05 \n",
      "Epoch 135/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.6444e-05 \n",
      "Epoch 136/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.5045e-05 \n",
      "Epoch 137/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.4624e-05 \n",
      "Epoch 138/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.1802e-05 \n",
      "Epoch 139/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.6982e-05 \n",
      "Epoch 140/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.7657e-05 \n",
      "Epoch 141/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.9156e-05 \n",
      "Epoch 142/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.7699e-05 \n",
      "Epoch 143/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.4792e-05 \n",
      "Epoch 144/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.9454e-05 \n",
      "Epoch 145/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.4013e-05 \n",
      "Epoch 146/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.8152e-05 \n",
      "Epoch 147/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.2529e-05 \n",
      "Epoch 148/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.1436e-05 \n",
      "Epoch 149/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.1514e-05 \n",
      "Epoch 150/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.8059e-05 \n",
      "Epoch 151/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.6040e-05 \n",
      "Epoch 152/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.1170e-05 \n",
      "Epoch 153/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.2809e-05 \n",
      "Epoch 154/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.0970e-05 \n",
      "Epoch 155/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.8421e-05 \n",
      "Epoch 156/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.5957e-05 \n",
      "Epoch 157/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.7135e-05 \n",
      "Epoch 158/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.8528e-05 \n",
      "Epoch 159/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.9707e-05 \n",
      "Epoch 160/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.3898e-05 \n",
      "Epoch 161/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.1440e-05 \n",
      "Epoch 162/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.3152e-05 \n",
      "Epoch 163/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.2250e-05 \n",
      "Epoch 164/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.7619e-05 \n"
     ]
    }
   ],
   "source": [
    "# 모델 학습\n",
    "np.random.seed(0)\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='loss',\n",
    "    patience=5,\n",
    "    mode='auto'\n",
    ")\n",
    "history = model.fit(train_x, train_y, epochs=1000, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# loss 그래프 생성\n",
    "plt.plot(history.history['loss'], label=\"loss\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15,) (1, 1) 0 15\n",
      "(16,) (1, 1) 1 16\n",
      "(17,) (1, 1) 2 17\n",
      "(18,) (1, 1) 3 18\n",
      "(19,) (1, 1) 4 19\n",
      "(20,) (1, 1) 5 20\n",
      "(21,) (1, 1) 6 21\n",
      "(22,) (1, 1) 7 22\n",
      "(23,) (1, 1) 8 23\n",
      "(24,) (1, 1) 9 24\n",
      "(25,) (1, 1) 10 25\n",
      "(26,) (1, 1) 11 26\n",
      "(27,) (1, 1) 12 27\n",
      "(28,) (1, 1) 13 28\n",
      "(29,) (1, 1) 14 29\n",
      "(30,) (1, 1) 15 30\n",
      "(31,) (1, 1) 16 31\n",
      "(32,) (1, 1) 17 32\n",
      "(33,) (1, 1) 18 33\n",
      "(34,) (1, 1) 19 34\n",
      "(35,) (1, 1) 20 35\n",
      "(36,) (1, 1) 21 36\n",
      "(37,) (1, 1) 22 37\n",
      "(38,) (1, 1) 23 38\n",
      "(39,) (1, 1) 24 39\n",
      "(40,) (1, 1) 25 40\n",
      "(41,) (1, 1) 26 41\n",
      "(42,) (1, 1) 27 42\n",
      "(43,) (1, 1) 28 43\n",
      "(44,) (1, 1) 29 44\n",
      "(45,) (1, 1) 30 45\n",
      "(46,) (1, 1) 31 46\n",
      "(47,) (1, 1) 32 47\n",
      "(48,) (1, 1) 33 48\n",
      "(49,) (1, 1) 34 49\n",
      "(50,) (1, 1) 35 50\n",
      "(51,) (1, 1) 36 51\n",
      "(52,) (1, 1) 37 52\n",
      "(53,) (1, 1) 38 53\n",
      "(54,) (1, 1) 39 54\n",
      "(55,) (1, 1) 40 55\n",
      "(56,) (1, 1) 41 56\n",
      "(57,) (1, 1) 42 57\n",
      "(58,) (1, 1) 43 58\n",
      "(59,) (1, 1) 44 59\n",
      "(60,) (1, 1) 45 60\n",
      "(61,) (1, 1) 46 61\n",
      "(62,) (1, 1) 47 62\n",
      "(63,) (1, 1) 48 63\n",
      "(64,) (1, 1) 49 64\n",
      "(65,) (1, 1) 50 65\n",
      "(66,) (1, 1) 51 66\n",
      "(67,) (1, 1) 52 67\n",
      "(68,) (1, 1) 53 68\n",
      "(69,) (1, 1) 54 69\n",
      "(70,) (1, 1) 55 70\n",
      "(71,) (1, 1) 56 71\n",
      "(72,) (1, 1) 57 72\n",
      "(73,) (1, 1) 58 73\n",
      "(74,) (1, 1) 59 74\n",
      "(75,) (1, 1) 60 75\n",
      "(76,) (1, 1) 61 76\n",
      "(77,) (1, 1) 62 77\n",
      "(78,) (1, 1) 63 78\n",
      "(79,) (1, 1) 64 79\n",
      "(80,) (1, 1) 65 80\n",
      "(81,) (1, 1) 66 81\n",
      "(82,) (1, 1) 67 82\n",
      "(83,) (1, 1) 68 83\n",
      "(84,) (1, 1) 69 84\n",
      "(85,) (1, 1) 70 85\n",
      "(86,) (1, 1) 71 86\n",
      "(87,) (1, 1) 72 87\n",
      "(88,) (1, 1) 73 88\n",
      "(89,) (1, 1) 74 89\n",
      "(90,) (1, 1) 75 90\n",
      "(91,) (1, 1) 76 91\n",
      "(92,) (1, 1) 77 92\n",
      "(93,) (1, 1) 78 93\n",
      "(94,) (1, 1) 79 94\n",
      "(95,) (1, 1) 80 95\n",
      "(96,) (1, 1) 81 96\n",
      "(97,) (1, 1) 82 97\n",
      "(98,) (1, 1) 83 98\n",
      "(99,) (1, 1) 84 99\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터셋 생성\n",
    "test_x = np.arange(10, 20, 0.1)\n",
    "calc_y = np.cos(test_x) # 테스트 정답 데이터\n",
    "\n",
    "# RNN 모델 예측 및 로그 저장\n",
    "test_y = calc_y[:n_timesteps]\n",
    "for i in range(len(test_x) - n_timesteps):\n",
    "  net_input = test_y[i : i + n_timesteps]\n",
    "  net_input = net_input.reshape((1, n_timesteps, n_features))\n",
    "  train_y = model.predict(net_input, verbose=0)\n",
    "  print(test_y.shape, train_y.shape, i, i + n_timesteps)\n",
    "  test_y = np.append(test_y, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 예측 결과 그래프 그리기\n",
    "plt.plot(test_x, calc_y, label=\"ground truth\", color=\"orange\")\n",
    "plt.plot(test_x, test_y, label=\"predictions\", color=\"blue\")\n",
    "\n",
    "plt.legend(loc='upper left')\n",
    "plt.ylim(-2, 2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape x:(185, 15) / y:(185,)\n",
      "train_x.shape = (185, 15, 1)\n",
      "train_y.shape = (185,)\n",
      "Epoch 1/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.8704\n",
      "Epoch 2/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8351 \n",
      "Epoch 3/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7616 \n",
      "Epoch 4/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6964 \n",
      "Epoch 5/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6301 \n",
      "Epoch 6/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5097 \n",
      "Epoch 7/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4749 \n",
      "Epoch 8/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4274 \n",
      "Epoch 9/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3999 \n",
      "Epoch 10/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3247 \n",
      "Epoch 11/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3063 \n",
      "Epoch 12/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2610 \n",
      "Epoch 13/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2506 \n",
      "Epoch 14/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.2318 \n",
      "Epoch 15/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2033 \n",
      "Epoch 16/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1954 \n",
      "Epoch 17/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1940 \n",
      "Epoch 18/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1819 \n",
      "Epoch 19/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1718 \n",
      "Epoch 20/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1553 \n",
      "Epoch 21/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1615 \n",
      "Epoch 22/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1480 \n",
      "Epoch 23/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1349 \n",
      "Epoch 24/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1279 \n",
      "Epoch 25/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1249 \n",
      "Epoch 26/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1201 \n",
      "Epoch 27/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1074 \n",
      "Epoch 28/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1092 \n",
      "Epoch 29/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0967 \n",
      "Epoch 30/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0932 \n",
      "Epoch 31/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0873 \n",
      "Epoch 32/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0833 \n",
      "Epoch 33/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0758 \n",
      "Epoch 34/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0720 \n",
      "Epoch 35/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0655 \n",
      "Epoch 36/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0619 \n",
      "Epoch 37/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0564 \n",
      "Epoch 38/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0496 \n",
      "Epoch 39/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0466 \n",
      "Epoch 40/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0409 \n",
      "Epoch 41/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0339 \n",
      "Epoch 42/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0304 \n",
      "Epoch 43/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0255 \n",
      "Epoch 44/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0217 \n",
      "Epoch 45/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0195 \n",
      "Epoch 46/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0153 \n",
      "Epoch 47/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0132 \n",
      "Epoch 48/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0103 \n",
      "Epoch 49/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0091 \n",
      "Epoch 50/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0077 \n",
      "Epoch 51/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0066 \n",
      "Epoch 52/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0057 \n",
      "Epoch 53/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0055 \n",
      "Epoch 54/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0052 \n",
      "Epoch 55/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0048 \n",
      "Epoch 56/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0048 \n",
      "Epoch 57/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0041 \n",
      "Epoch 58/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0041 \n",
      "Epoch 59/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0039 \n",
      "Epoch 60/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0038 \n",
      "Epoch 61/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0037 \n",
      "Epoch 62/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0034 \n",
      "Epoch 63/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0035 \n",
      "Epoch 64/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0036 \n",
      "Epoch 65/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0031 \n",
      "Epoch 66/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0031 \n",
      "Epoch 67/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0030 \n",
      "Epoch 68/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0029 \n",
      "Epoch 69/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0031 \n",
      "Epoch 70/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 \n",
      "Epoch 71/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0029 \n",
      "Epoch 72/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0026 \n",
      "Epoch 73/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0025 \n",
      "Epoch 74/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0027 \n",
      "Epoch 75/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0024 \n",
      "Epoch 76/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0023 \n",
      "Epoch 77/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0025 \n",
      "Epoch 78/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0022 \n",
      "Epoch 79/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0023 \n",
      "Epoch 80/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0022 \n",
      "Epoch 81/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0020 \n",
      "Epoch 82/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0022 \n",
      "Epoch 83/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0021 \n",
      "Epoch 84/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0020 \n",
      "Epoch 85/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0020 \n",
      "Epoch 86/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0017 \n",
      "Epoch 87/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0018 \n",
      "Epoch 88/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0016 \n",
      "Epoch 89/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0018 \n",
      "Epoch 90/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0016 \n",
      "Epoch 91/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0014 \n",
      "Epoch 92/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0014 \n",
      "Epoch 93/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0015 \n",
      "Epoch 94/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0013     \n",
      "Epoch 95/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0014 \n",
      "Epoch 96/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0013 \n",
      "Epoch 97/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0013 \n",
      "Epoch 98/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0012 \n",
      "Epoch 99/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0012 \n",
      "Epoch 100/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 \n",
      "Epoch 101/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 \n",
      "Epoch 102/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0010 \n",
      "Epoch 103/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.6631e-04 \n",
      "Epoch 104/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.8739e-04 \n",
      "Epoch 105/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.6206e-04 \n",
      "Epoch 106/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.3491e-04 \n",
      "Epoch 107/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.9602e-04 \n",
      "Epoch 108/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.0710e-04 \n",
      "Epoch 109/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.5041e-04 \n",
      "Epoch 110/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.9388e-04 \n",
      "Epoch 111/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.2008e-04 \n",
      "Epoch 112/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.7937e-04 \n",
      "Epoch 113/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.3735e-04 \n",
      "Epoch 114/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.5109e-04 \n",
      "Epoch 115/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.0075e-04 \n",
      "Epoch 116/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.3609e-04 \n",
      "Epoch 117/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.0905e-04 \n",
      "Epoch 118/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.7581e-04 \n",
      "Epoch 119/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.2999e-04 \n",
      "Epoch 120/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4355e-04 \n",
      "Epoch 121/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3754e-04 \n",
      "Epoch 122/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0814e-04 \n",
      "Epoch 123/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6628e-04 \n",
      "Epoch 124/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8307e-04 \n",
      "Epoch 125/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5627e-04 \n",
      "Epoch 126/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.0691e-04 \n",
      "Epoch 127/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.8564e-04 \n",
      "Epoch 128/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.0083e-04 \n",
      "Epoch 129/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.4368e-04 \n",
      "Epoch 130/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.7366e-04 \n",
      "Epoch 131/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.2579e-04 \n",
      "Epoch 132/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.2436e-04 \n",
      "Epoch 133/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.2973e-04 \n",
      "Epoch 134/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0687e-04 \n",
      "Epoch 135/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0652e-04 \n",
      "Epoch 136/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0268e-04 \n",
      "Epoch 137/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.6595e-04 \n",
      "Epoch 138/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.7713e-04 \n",
      "Epoch 139/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.7231e-04 \n",
      "Epoch 140/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.6314e-04 \n",
      "Epoch 141/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5896e-04 \n",
      "Epoch 142/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5358e-04 \n",
      "Epoch 143/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3924e-04 \n",
      "Epoch 144/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.4229e-04 \n",
      "Epoch 145/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2935e-04 \n",
      "Epoch 146/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3263e-04 \n",
      "Epoch 147/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2318e-04 \n",
      "Epoch 148/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1787e-04 \n",
      "Epoch 149/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2221e-04 \n",
      "Epoch 150/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2360e-04 \n",
      "Epoch 151/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1819e-04 \n",
      "Epoch 152/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.1173e-04 \n",
      "Epoch 153/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1120e-04 \n",
      "Epoch 154/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0742e-04 \n",
      "Epoch 155/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0656e-04 \n",
      "Epoch 156/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.7381e-05 \n",
      "Epoch 157/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.9930e-05 \n",
      "Epoch 158/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.9047e-05 \n",
      "Epoch 159/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.9400e-05 \n",
      "Epoch 160/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.2034e-05 \n",
      "Epoch 161/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.7195e-05 \n",
      "Epoch 162/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.9148e-05 \n",
      "Epoch 163/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.7473e-05 \n",
      "Epoch 164/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.6998e-05 \n",
      "Epoch 165/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.4189e-05 \n",
      "Epoch 166/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.1850e-05 \n",
      "Epoch 167/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.1743e-05 \n",
      "Epoch 168/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.0733e-05 \n",
      "Epoch 169/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.8143e-05 \n",
      "Epoch 170/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.7880e-05 \n",
      "Epoch 171/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.6849e-05 \n",
      "Epoch 172/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.5904e-05 \n",
      "Epoch 173/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.4647e-05 \n",
      "Epoch 174/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.3766e-05 \n",
      "Epoch 175/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.4293e-05 \n",
      "Epoch 176/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.2765e-05 \n",
      "Epoch 177/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.2016e-05 \n",
      "Epoch 178/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.6416e-05 \n",
      "Epoch 179/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.2493e-05 \n",
      "Epoch 180/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.8638e-05 \n",
      "Epoch 181/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.7489e-05 \n",
      "Epoch 182/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.7613e-05 \n",
      "Epoch 183/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.4322e-05 \n",
      "Epoch 184/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.8517e-05 \n",
      "Epoch 185/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.1316e-05 \n",
      "Epoch 186/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.6265e-05 \n",
      "Epoch 187/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.0123e-05 \n",
      "Epoch 188/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.2180e-05 \n",
      "Epoch 189/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.0299e-05 \n",
      "Epoch 190/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.6416e-05 \n",
      "Epoch 191/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.7186e-05 \n",
      "Epoch 192/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.7365e-05 \n",
      "Epoch 193/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.0473e-05 \n",
      "Epoch 194/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.5866e-05 \n",
      "Epoch 195/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.4405e-05 \n",
      "Epoch 196/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.7521e-05 \n",
      "Epoch 197/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.3474e-05 \n",
      "Epoch 198/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.8084e-05 \n",
      "Epoch 199/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.7976e-05 \n",
      "Epoch 200/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.4471e-05 \n",
      "Epoch 201/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.4995e-05 \n",
      "Epoch 202/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.7166e-05 \n",
      "Epoch 203/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.4114e-05 \n",
      "Epoch 204/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.3701e-05 \n",
      "Epoch 205/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.6618e-05 \n",
      "Epoch 206/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.6295e-05 \n",
      "Epoch 207/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.4667e-05 \n",
      "Epoch 208/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.0653e-05 \n",
      "Epoch 209/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.9853e-05 \n",
      "Epoch 210/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.1058e-05 \n",
      "Epoch 211/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.2358e-05 \n",
      "Epoch 212/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.0037e-05 \n",
      "Epoch 213/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.9713e-05 \n",
      "Epoch 214/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.8795e-05 \n",
      "Epoch 215/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.7608e-05 \n",
      "Epoch 216/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.0896e-05 \n",
      "Epoch 217/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.8546e-05 \n",
      "Epoch 218/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.7652e-05 \n",
      "Epoch 219/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.7577e-05 \n",
      "Epoch 220/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.9730e-05 \n",
      "Epoch 221/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.8581e-05 \n",
      "Epoch 222/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.9087e-05 \n",
      "Epoch 223/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.0254e-05 \n",
      "Epoch 224/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.6710e-05 \n",
      "Epoch 225/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.6158e-05 \n",
      "Epoch 226/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.5500e-05 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, LSTM, SimpleRNN\n",
    "\n",
    "# time step만큼 시퀀스 데이터 분리\n",
    "def split_sequence(sequence, step):\n",
    "  x, y = list(), list()\n",
    "\n",
    "  for i in range(len(sequence)):\n",
    "    end_idx = i + step\n",
    "    if end_idx > len(sequence) - 1:\n",
    "      break\n",
    "\n",
    "    seq_x, seq_y = sequence[i:end_idx], sequence[end_idx]\n",
    "    x.append(seq_x)\n",
    "    y.append(seq_y)\n",
    "\n",
    "  return np.array(x), np.array(y)\n",
    "\n",
    "\n",
    "# sin 함수 학습 데이터\n",
    "x = [i for i in np.arange(start=-10, stop=10, step=0.1)]\n",
    "train_y = [np.sin(i) for i in x]\n",
    "\n",
    "# 하이퍼파라미터\n",
    "n_timesteps = 15\n",
    "n_features = 1\n",
    "\n",
    "# 시퀀스 나누기\n",
    "# train_x.shape => (samples, timesteps)\n",
    "# train_y.shape => (samples)\n",
    "train_x, train_y = split_sequence(train_y, step=n_timesteps)\n",
    "print(\"shape x:{} / y:{}\".format(train_x.shape, train_y.shape))\n",
    "\n",
    "# LSTM 입력 벡터 크기를 맞추기 위해 벡터 차원 크기 변경\n",
    "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "train_x = train_x.reshape(train_x.shape[0], train_x.shape[1], n_features)\n",
    "print(\"train_x.shape = {}\".format(train_x.shape))\n",
    "print(\"train_y.shape = {}\".format(train_y.shape))\n",
    "\n",
    "# LSTM 모델 정의\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=10,\n",
    "                    return_sequences=False,\n",
    "                    input_shape=(n_timesteps, n_features)))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# 모델 학습\n",
    "np.random.seed(0)\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='loss',\n",
    "    patience=5,\n",
    "    mode='auto'\n",
    ")\n",
    "history = model.fit(train_x, train_y, epochs=1000, callbacks=[early_stopping])\n",
    "\n",
    "# 테스트 데이터셋 생성\n",
    "test_x = np.arange(10, 20, 0.1)\n",
    "calc_y = np.cos(test_x) # 테스트 정답 데이터\n",
    "\n",
    "# LSTM 모델 예측 및 로그 저장\n",
    "test_y = calc_y[:n_timesteps]\n",
    "for i in range(len(test_x) - n_timesteps):\n",
    "  net_input = test_y[i : i + n_timesteps]\n",
    "  net_input = net_input.reshape((1, n_timesteps, n_features))\n",
    "  train_y = model.predict(net_input)\n",
    "  # print(test_y.shape, train_y.shape, i, i + n_timesteps)\n",
    "  test_y = np.append(test_y, train_y)\n",
    "\n",
    "# 예측 결과 그래프 그리기\n",
    "plt.plot(test_x, calc_y, label=\"ground truth\", color=\"orange\")\n",
    "plt.plot(test_x, test_y, label=\"predictions\", color=\"blue\")\n",
    "\n",
    "plt.legend(loc='upper left')\n",
    "plt.ylim(-2, 2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "max_features = 20000  # 처음 2만개의 단어만 고려합니다\n",
    "maxlen = 200  # 각 리뷰에 첫 200개의 단어만 고려합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_7\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_7\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,560,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │     \u001b[38;5;34m2,560,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m98,816\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m98,816\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,757,761</span> (10.52 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,757,761\u001b[0m (10.52 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,757,761</span> (10.52 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,757,761\u001b[0m (10.52 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 가변 길이 정수 시퀀스를 입력합니다\n",
    "inputs = keras.Input(shape=(None,), dtype=\"int32\")\n",
    "# 128차원 벡터에 각 정수를 포함합니다 \n",
    "x = layers.Embedding(max_features, 128)(inputs)\n",
    "\n",
    "# 양항향 LSTMs을 추가합니다\n",
    "x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x)\n",
    "x = layers.Bidirectional(layers.LSTM(64))(x)\n",
    "# 분류기를 추가합니다\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000 Training sequences\n",
      "25000 Validation sequences\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_val, y_val) = keras.datasets.imdb.load_data(\n",
    "    num_words=max_features\n",
    ")\n",
    "print(len(x_train), \"Training sequences\")\n",
    "print(len(x_val), \"Validation sequences\")\n",
    "x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_val = keras.preprocessing.sequence.pad_sequences(x_val, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 131ms/step - accuracy: 0.7611 - loss: 0.4737 - val_accuracy: 0.8546 - val_loss: 0.3379\n",
      "Epoch 2/2\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 127ms/step - accuracy: 0.9167 - loss: 0.2238 - val_accuracy: 0.8646 - val_loss: 0.3349\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x22dfe393650>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\"adam\", \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=2, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "개체명 인식 Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 개수:  14041\n",
      "첫번째 샘플 : [['peter', 'B-PER'], ['blackburn', 'I-PER']]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/ukairia777/tensorflow-nlp-tutorial/main/12.%20RNN%20Sequence%20Labeling/dataset/train.txt\", filename=\"train.txt\")\n",
    "\n",
    "f = open('train.txt', 'r')\n",
    "tagged_sentences = []\n",
    "sentence = []\n",
    "\n",
    "for line in f:\n",
    "    if len(line)==0 or line.startswith('-DOCSTART') or line[0]==\"\\n\":\n",
    "        if len(sentence) > 0:\n",
    "            tagged_sentences.append(sentence)\n",
    "            sentence = []\n",
    "        continue\n",
    "    splits = line.split(' ') # 공백을 기준으로 속성을 구분한다.\n",
    "    splits[-1] = re.sub(r'\\n', '', splits[-1]) # 줄바꿈 표시 \\n을 제거한다.\n",
    "    word = splits[0].lower() # 단어들은 소문자로 바꿔서 저장한다.\n",
    "    sentence.append([word, splits[-1]]) # 단어와 개체명 태깅만 기록한다.\n",
    "\n",
    "print(\"전체 샘플 개수: \", len(tagged_sentences))\n",
    "print('첫번째 샘플 :',tagged_sentences[1])\n",
    "\n",
    "# 참고자료: https://wikidocs.net/24682"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [preprocessing.text.text_to_word_sequence(text) for text in features]\n",
    "\n",
    "tokenizer = preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "sequences = tokenizer.texts_to_sequences(corpus) #texts_to_sequences() 함수를 이용해 모든 단어를 시퀀스 번호로 변환합니다.\n",
    "word_index = tokenizer.word_index \n",
    "\n",
    "\n",
    "MAX_SEQ_LEN = 15  # 단어 시퀀스 벡터 크기를 임의로 넉넉하게 늘려서 설정합니다. \n",
    "\n",
    "padded_seqs = preprocessing.sequence.pad_sequences(sequences, maxlen=MAX_SEQ_LEN, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KOREAVC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 데이터를 랜덤하게 섞은 후 학습용, 검증용, 테스트용 데이터셋을 생성합니다.\n",
    "# 학습셋:검증셋:테스트셋 = 7:2:1\n",
    "ds = tf.data.Dataset.from_tensor_slices((padded_seqs, labels))\n",
    "ds = ds.shuffle(len(features))\n",
    "train_size = int(len(padded_seqs) * 0.7)\n",
    "val_size = int(len(padded_seqs) * 0.2)\n",
    "test_size = int(len(padded_seqs) * 0.1)\n",
    "train_ds = ds.take(train_size).batch(20)\n",
    "val_ds = ds.skip(train_size).take(val_size).batch(20)\n",
    "test_ds = ds.skip(train_size + val_size).take(test_size).batch(20)\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "dropout_prob = 0.5\n",
    "EMB_SIZE = 128\n",
    "EPOCH = 5\n",
    "VOCAB_SIZE = len(word_index) + 1  # 전체 단어 수\n",
    "\n",
    "# 케라스 함수형 모델 방식으로 CNN 모델을 정의합니다. CNN 모델은 전처리된 입력 데이터를 단어 임베딩 처리하는 영역과 합성곱 필터와 연산을 통해 문장의 특징 정보(특징맵)를 추출하고, 평탄화하는 영역, 그리고 완전 연결계층을 통해 감정별로 클래스를 분류하는 영역으로 구성되어 있습니다.\n",
    "input_layer = Input(shape=(MAX_SEQ_LEN,))\n",
    "embedding_layer = Embedding(VOCAB_SIZE, EMB_SIZE, input_length=MAX_SEQ_LEN)(input_layer)\n",
    "dropout_emb = Dropout(rate=dropout_prob)(embedding_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = Conv1D(filters=128, kernel_size=3, padding='valid', activation=tf.nn.relu)(dropout_emb)\n",
    "pool1 = GlobalMaxPool1D()(conv1)\n",
    "conv2 = Conv1D(filters=128, kernel_size=4, padding='valid', activation=tf.nn.relu)(dropout_emb)\n",
    "pool2 = GlobalMaxPool1D()(conv2)\n",
    "conv3 = Conv1D(filters=128, kernel_size=5, padding='valid', activation=tf.nn.relu)(dropout_emb)\n",
    "pool3 = GlobalMaxPool1D()(conv3)\n",
    "\n",
    "# 3, 4, 5- gram 이후 합치기\n",
    "concat = concatenate([pool1, pool2, pool3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = Dense(128, activation=tf.nn.relu)(concat)\n",
    "dropout_hidden = Dropout(rate=dropout_prob)(hidden)\n",
    "logits = Dense(3, name='logits')(dropout_hidden)\n",
    "predictions = Dense(3, activation=tf.nn.softmax)(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KerasTensor shape=(None, 128), dtype=float32, sparse=False, name=keras_tensor_10>\n"
     ]
    }
   ],
   "source": [
    "print(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.5016 - loss: 0.9798 - val_accuracy: 0.7800 - val_loss: 0.6053\n",
      "Epoch 2/5\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.7772 - loss: 0.5656 - val_accuracy: 0.9234 - val_loss: 0.2625\n",
      "Epoch 3/5\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.8992 - loss: 0.3059 - val_accuracy: 0.9569 - val_loss: 0.1609\n",
      "Epoch 4/5\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9354 - loss: 0.2049 - val_accuracy: 0.9691 - val_loss: 0.1120\n",
      "Epoch 5/5\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9566 - loss: 0.1389 - val_accuracy: 0.9831 - val_loss: 0.0588\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9823 - loss: 0.0594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.969544\n",
      "loss: 0.069299\n"
     ]
    }
   ],
   "source": [
    "# 모델 생성\n",
    "model = Model(inputs=input_layer, outputs=predictions)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(train_ds, validation_data=val_ds, epochs=EPOCH, verbose=1) \n",
    "\n",
    "# 모델 평가(테스트 데이터셋 이용)\n",
    "loss, accuracy = model.evaluate(test_ds, verbose=1)\n",
    "print('Accuracy: %f' % (accuracy * 100))\n",
    "print('loss: %f' % (loss))\n",
    "\n",
    "# 모델 저장\n",
    "model.save('cnn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras import preprocessing\n",
    "# 테스트용 데이터셋 생성\n",
    "ds = tf.data.Dataset.from_tensor_slices((padded_seqs, labels))\n",
    "ds = ds.shuffle(len(features))\n",
    "test_ds = ds.take(2000).batch(20) # 테스트 데이터셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Error when deserializing class 'Dense' using config={'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': {'module': 'builtins', 'class_name': 'function', 'config': 'softmax_v2', 'registered_name': 'function'}, 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}.\n\nException encountered: Could not interpret activation function identifier: {'module': 'builtins', 'class_name': 'function', 'config': 'softmax_v2', 'registered_name': 'function'}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\KOREAVC\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\operation.py:208\u001b[0m, in \u001b[0;36mOperation.from_config\u001b[1;34m(cls, config)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 208\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig)\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\KOREAVC\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:89\u001b[0m, in \u001b[0;36mDense.__init__\u001b[1;34m(self, units, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, lora_rank, **kwargs)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munits \u001b[38;5;241m=\u001b[39m units\n\u001b[1;32m---> 89\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation \u001b[38;5;241m=\u001b[39m activations\u001b[38;5;241m.\u001b[39mget(activation)\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_bias \u001b[38;5;241m=\u001b[39m use_bias\n",
      "File \u001b[1;32mc:\\Users\\KOREAVC\\anaconda3\\Lib\\site-packages\\keras\\src\\activations\\__init__.py:104\u001b[0m, in \u001b[0;36mget\u001b[1;34m(identifier)\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[1;32m--> 104\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not interpret activation function identifier: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midentifier\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    106\u001b[0m )\n",
      "\u001b[1;31mValueError\u001b[0m: Could not interpret activation function identifier: {'module': 'builtins', 'class_name': 'function', 'config': 'softmax_v2', 'registered_name': 'function'}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 감정 분류 CNN 모델 불러오기\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m load_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcnn_model.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n\u001b[0;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39mevaluate(test_ds, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\KOREAVC\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_api.py:183\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m saving_lib\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[0;32m    177\u001b[0m         filepath,\n\u001b[0;32m    178\u001b[0m         custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[0;32m    179\u001b[0m         \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m,\n\u001b[0;32m    180\u001b[0m         safe_mode\u001b[38;5;241m=\u001b[39msafe_mode,\n\u001b[0;32m    181\u001b[0m     )\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.hdf5\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[1;32m--> 183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m legacy_h5_format\u001b[38;5;241m.\u001b[39mload_model_from_hdf5(\n\u001b[0;32m    184\u001b[0m         filepath, custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects, \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m\n\u001b[0;32m    185\u001b[0m     )\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    188\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile not found: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    189\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure the file is an accessible `.keras` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    190\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzip file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    191\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\KOREAVC\\anaconda3\\Lib\\site-packages\\keras\\src\\legacy\\saving\\legacy_h5_format.py:133\u001b[0m, in \u001b[0;36mload_model_from_hdf5\u001b[1;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[0;32m    130\u001b[0m model_config \u001b[38;5;241m=\u001b[39m json_utils\u001b[38;5;241m.\u001b[39mdecode(model_config)\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m saving_options\u001b[38;5;241m.\u001b[39mkeras_option_scope(use_legacy_config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 133\u001b[0m     model \u001b[38;5;241m=\u001b[39m saving_utils\u001b[38;5;241m.\u001b[39mmodel_from_config(\n\u001b[0;32m    134\u001b[0m         model_config, custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects\n\u001b[0;32m    135\u001b[0m     )\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;66;03m# set weights\u001b[39;00m\n\u001b[0;32m    138\u001b[0m     load_weights_from_hdf5_group(f[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_weights\u001b[39m\u001b[38;5;124m\"\u001b[39m], model)\n",
      "File \u001b[1;32mc:\\Users\\KOREAVC\\anaconda3\\Lib\\site-packages\\keras\\src\\legacy\\saving\\saving_utils.py:85\u001b[0m, in \u001b[0;36mmodel_from_config\u001b[1;34m(config, custom_objects)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;66;03m# TODO(nkovela): Swap find and replace args during Keras 3.0 release\u001b[39;00m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;66;03m# Replace keras refs with keras\u001b[39;00m\n\u001b[0;32m     83\u001b[0m config \u001b[38;5;241m=\u001b[39m _find_replace_nested_dict(config, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 85\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m serialization\u001b[38;5;241m.\u001b[39mdeserialize_keras_object(\n\u001b[0;32m     86\u001b[0m     config,\n\u001b[0;32m     87\u001b[0m     module_objects\u001b[38;5;241m=\u001b[39mMODULE_OBJECTS\u001b[38;5;241m.\u001b[39mALL_OBJECTS,\n\u001b[0;32m     88\u001b[0m     custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[0;32m     89\u001b[0m     printable_module_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     90\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\KOREAVC\\anaconda3\\Lib\\site-packages\\keras\\src\\legacy\\saving\\serialization.py:495\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[0;32m    490\u001b[0m cls_config \u001b[38;5;241m=\u001b[39m _find_replace_nested_dict(\n\u001b[0;32m    491\u001b[0m     cls_config, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    492\u001b[0m )\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcustom_objects\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m arg_spec\u001b[38;5;241m.\u001b[39margs:\n\u001b[1;32m--> 495\u001b[0m     deserialized_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_config(\n\u001b[0;32m    496\u001b[0m         cls_config,\n\u001b[0;32m    497\u001b[0m         custom_objects\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m    498\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mobject_registration\u001b[38;5;241m.\u001b[39mGLOBAL_CUSTOM_OBJECTS,\n\u001b[0;32m    499\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcustom_objects,\n\u001b[0;32m    500\u001b[0m         },\n\u001b[0;32m    501\u001b[0m     )\n\u001b[0;32m    502\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    503\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m object_registration\u001b[38;5;241m.\u001b[39mCustomObjectScope(custom_objects):\n",
      "File \u001b[1;32mc:\\Users\\KOREAVC\\anaconda3\\Lib\\site-packages\\keras\\src\\models\\model.py:517\u001b[0m, in \u001b[0;36mModel.from_config\u001b[1;34m(cls, config, custom_objects)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_functional_config \u001b[38;5;129;01mand\u001b[39;00m revivable_as_functional:\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;66;03m# Revive Functional model\u001b[39;00m\n\u001b[0;32m    514\u001b[0m     \u001b[38;5;66;03m# (but not Functional subclasses with a custom __init__)\u001b[39;00m\n\u001b[0;32m    515\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m functional_from_config\n\u001b[1;32m--> 517\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m functional_from_config(\n\u001b[0;32m    518\u001b[0m         \u001b[38;5;28mcls\u001b[39m, config, custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects\n\u001b[0;32m    519\u001b[0m     )\n\u001b[0;32m    521\u001b[0m \u001b[38;5;66;03m# Either the model has a custom __init__, or the config\u001b[39;00m\n\u001b[0;32m    522\u001b[0m \u001b[38;5;66;03m# does not contain all the information necessary to\u001b[39;00m\n\u001b[0;32m    523\u001b[0m \u001b[38;5;66;03m# revive a Functional model. This happens when the user creates\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    526\u001b[0m \u001b[38;5;66;03m# In this case, we fall back to provide all config into the\u001b[39;00m\n\u001b[0;32m    527\u001b[0m \u001b[38;5;66;03m# constructor of the class.\u001b[39;00m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\KOREAVC\\anaconda3\\Lib\\site-packages\\keras\\src\\models\\functional.py:517\u001b[0m, in \u001b[0;36mfunctional_from_config\u001b[1;34m(cls, config, custom_objects)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;66;03m# First, we create all layers and enqueue nodes to be processed\u001b[39;00m\n\u001b[0;32m    516\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer_data \u001b[38;5;129;01min\u001b[39;00m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayers\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m--> 517\u001b[0m     process_layer(layer_data)\n\u001b[0;32m    519\u001b[0m \u001b[38;5;66;03m# Then we process nodes in order of layer depth.\u001b[39;00m\n\u001b[0;32m    520\u001b[0m \u001b[38;5;66;03m# Nodes that cannot yet be processed (if the inbound node\u001b[39;00m\n\u001b[0;32m    521\u001b[0m \u001b[38;5;66;03m# does not yet exist) are re-enqueued, and the process\u001b[39;00m\n\u001b[0;32m    522\u001b[0m \u001b[38;5;66;03m# is repeated until all nodes are processed.\u001b[39;00m\n\u001b[0;32m    523\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m unprocessed_nodes:\n",
      "File \u001b[1;32mc:\\Users\\KOREAVC\\anaconda3\\Lib\\site-packages\\keras\\src\\models\\functional.py:497\u001b[0m, in \u001b[0;36mfunctional_from_config.<locals>.process_layer\u001b[1;34m(layer_data)\u001b[0m\n\u001b[0;32m    493\u001b[0m \u001b[38;5;66;03m# Instantiate layer.\u001b[39;00m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m layer_data:\n\u001b[0;32m    495\u001b[0m     \u001b[38;5;66;03m# Legacy format deserialization (no \"module\" key)\u001b[39;00m\n\u001b[0;32m    496\u001b[0m     \u001b[38;5;66;03m# used for H5 and SavedModel formats\u001b[39;00m\n\u001b[1;32m--> 497\u001b[0m     layer \u001b[38;5;241m=\u001b[39m saving_utils\u001b[38;5;241m.\u001b[39mmodel_from_config(\n\u001b[0;32m    498\u001b[0m         layer_data, custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects\n\u001b[0;32m    499\u001b[0m     )\n\u001b[0;32m    500\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    501\u001b[0m     layer \u001b[38;5;241m=\u001b[39m serialization_lib\u001b[38;5;241m.\u001b[39mdeserialize_keras_object(\n\u001b[0;32m    502\u001b[0m         layer_data, custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects\n\u001b[0;32m    503\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\KOREAVC\\anaconda3\\Lib\\site-packages\\keras\\src\\legacy\\saving\\saving_utils.py:85\u001b[0m, in \u001b[0;36mmodel_from_config\u001b[1;34m(config, custom_objects)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;66;03m# TODO(nkovela): Swap find and replace args during Keras 3.0 release\u001b[39;00m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;66;03m# Replace keras refs with keras\u001b[39;00m\n\u001b[0;32m     83\u001b[0m config \u001b[38;5;241m=\u001b[39m _find_replace_nested_dict(config, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 85\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m serialization\u001b[38;5;241m.\u001b[39mdeserialize_keras_object(\n\u001b[0;32m     86\u001b[0m     config,\n\u001b[0;32m     87\u001b[0m     module_objects\u001b[38;5;241m=\u001b[39mMODULE_OBJECTS\u001b[38;5;241m.\u001b[39mALL_OBJECTS,\n\u001b[0;32m     88\u001b[0m     custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[0;32m     89\u001b[0m     printable_module_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     90\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\KOREAVC\\anaconda3\\Lib\\site-packages\\keras\\src\\legacy\\saving\\serialization.py:504\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[0;32m    502\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    503\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m object_registration\u001b[38;5;241m.\u001b[39mCustomObjectScope(custom_objects):\n\u001b[1;32m--> 504\u001b[0m             deserialized_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_config(cls_config)\n\u001b[0;32m    505\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     \u001b[38;5;66;03m# Then `cls` may be a function returning a class.\u001b[39;00m\n\u001b[0;32m    507\u001b[0m     \u001b[38;5;66;03m# in this case by convention `config` holds\u001b[39;00m\n\u001b[0;32m    508\u001b[0m     \u001b[38;5;66;03m# the kwargs of the function.\u001b[39;00m\n\u001b[0;32m    509\u001b[0m     custom_objects \u001b[38;5;241m=\u001b[39m custom_objects \u001b[38;5;129;01mor\u001b[39;00m {}\n",
      "File \u001b[1;32mc:\\Users\\KOREAVC\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\operation.py:210\u001b[0m, in \u001b[0;36mOperation.from_config\u001b[1;34m(cls, config)\u001b[0m\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig)\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 210\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    211\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError when deserializing class \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m using \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    212\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mException encountered: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    213\u001b[0m     )\n",
      "\u001b[1;31mTypeError\u001b[0m: Error when deserializing class 'Dense' using config={'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 3, 'activation': {'module': 'builtins', 'class_name': 'function', 'config': 'softmax_v2', 'registered_name': 'function'}, 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}.\n\nException encountered: Could not interpret activation function identifier: {'module': 'builtins', 'class_name': 'function', 'config': 'softmax_v2', 'registered_name': 'function'}"
     ]
    }
   ],
   "source": [
    "# 감정 분류 CNN 모델 불러오기\n",
    "model = load_model('cnn_model.h5')\n",
    "model.summary()\n",
    "model.evaluate(test_ds, verbose=2)\n",
    "\n",
    "# 테스트용 데이터셋의 10212번째 데이터 출력\n",
    "print(\"단어 시퀀스 : \", corpus[10212])\n",
    "print(\"단어 인덱스 시퀀스 : \", padded_seqs[10212])\n",
    "print(\"문장 분류(정답) : \", labels[10212])\n",
    "\n",
    "# 테스트용 데이터셋의 10212번째 데이터 감정 예측\n",
    "picks = [10212]\n",
    "predict = model.predict(padded_seqs[picks])\n",
    "predict_class = tf.math.argmax(predict, axis=1)\n",
    "print(\"감정 예측 점수 : \", predict)\n",
    "print(\"감정 예측 클래스 : \", predict_class.numpy())\n",
    "\n",
    "## 결과 : 실제 분류 클래스랑 예측한 감정 클래스가 동일한 결과를 보입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_TOKEN = 0\n",
    "SOS_TOKEN = 1\n",
    "EOS_TOKEN = 2\n",
    "\n",
    "\n",
    "class WordVocab():\n",
    "    def __init__(self):\n",
    "        self.word2index = {\n",
    "            '<PAD>': PAD_TOKEN,\n",
    "            '<SOS>': SOS_TOKEN, \n",
    "            '<EOS>': EOS_TOKEN,\n",
    "        }\n",
    "        self.word2count = {}\n",
    "        self.index2word = {\n",
    "            PAD_TOKEN: '<PAD>', \n",
    "            SOS_TOKEN: '<SOS>', \n",
    "            EOS_TOKEN: '<EOS>'\n",
    "        }\n",
    "        \n",
    "        self.n_words = 3  # PAD, SOS, EOS 포함\n",
    "\n",
    "    def add_sentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.add_word(word)\n",
    "\n",
    "    def add_word(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'알츠하이머병 의 진단 을 받을 수 있는 병원 을 알 고 싶습니다 .'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions[925]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원문: 알츠하이머병 과 치매 는 서로 다른 질병 인가요 ?\n",
      "==============================\n",
      "[단어사전]\n",
      "******************************\n",
      "{'<PAD>': 0, '<SOS>': 1, '<EOS>': 2, '알츠하이머병': 3, '과': 4, '치매': 5, '는': 6, '서로': 7, '다른': 8, '질병': 9, '인가요': 10, '?': 11}\n"
     ]
    }
   ],
   "source": [
    "print(f'원문: {questions[550]}')\n",
    "lang = WordVocab()\n",
    "lang.add_sentence(questions[550])\n",
    "print('==='*10)\n",
    "print('[단어사전]')\n",
    "print('***'*10)\n",
    "print(lang.word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Sentence: [72, 28, 80, 25, 17, 58]\n",
      "Output: [72, 28, 80, 25, 17, 58, 2, 0, 0, 0]\n",
      "Total Length: 10\n"
     ]
    }
   ],
   "source": [
    "max_length = 10\n",
    "sentence_length = 6\n",
    "\n",
    "sentence_tokens = np.random.randint(low=3, high=100, size=(sentence_length,))\n",
    "sentence_tokens = sentence_tokens.tolist()\n",
    "print(f'Generated Sentence: {sentence_tokens}')\n",
    "\n",
    "sentence_tokens = sentence_tokens[:(max_length-1)]\n",
    "\n",
    "token_length = len(sentence_tokens)\n",
    "\n",
    "# 문장의 맨 끝부분에 <EOS> 토큰 추가\n",
    "sentence_tokens.append(2)\n",
    "\n",
    "for i in range(token_length, max_length-1):\n",
    "    # 나머지 빈 곳에 <PAD> 토큰 추가\n",
    "    sentence_tokens.append(0)\n",
    "\n",
    "print(f'Output: {sentence_tokens}')\n",
    "print(f'Total Length: {len(sentence_tokens)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab, Okt\n",
    "import re\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, csv_path, min_length=3, max_length=32):\n",
    "        super(TextDataset, self).__init__()\n",
    "        # data_dir = 'data'\n",
    "        \n",
    "        # TOKEN 정의\n",
    "        self.PAD_TOKEN = 0 # Padding 토큰\n",
    "        self.SOS_TOKEN = 1 # SOS 토큰\n",
    "        self.EOS_TOKEN = 2 # EOS 토큰\n",
    "        \n",
    "        self.tagger = MeCab()   # 형태소 분석기\n",
    "        self.max_length = max_length # 한 문장의 최대 길이 지정\n",
    "        \n",
    "        # CSV 데이터 로드\n",
    "        # df = pd.read_csv(os.path.join(data_dir, csv_path))\n",
    "        df=pd.read_csv('Alz.csv')\n",
    "        # 한글 정규화\n",
    "        korean_pattern = r'[^ ?,.!A-Za-z0-9가-힣+]'\n",
    "        self.normalizer = re.compile(korean_pattern)\n",
    "        \n",
    "        # src: 질의, tgt: 답변\n",
    "        src_clean = []\n",
    "        tgt_clean = []\n",
    "        \n",
    "        # 단어 사전 생성\n",
    "        wordvocab = WordVocab()\n",
    "        \n",
    "        for _, row in df.iterrows():\n",
    "            src = row['question']\n",
    "            tgt = row['answer']\n",
    "            \n",
    "            # 한글 전처리\n",
    "            src = self.clean_text(src)\n",
    "            tgt = self.clean_text(tgt)\n",
    "            \n",
    "            if len(src.split()) > min_length and len(tgt.split()) > min_length:\n",
    "                # 최소 길이를 넘어가는 문장의 단어만 추가\n",
    "                wordvocab.add_sentence(src)\n",
    "                wordvocab.add_sentence(tgt)\n",
    "                src_clean.append(src)\n",
    "                tgt_clean.append(tgt)            \n",
    "        \n",
    "        self.srcs = src_clean\n",
    "        self.tgts = tgt_clean\n",
    "        self.wordvocab = wordvocab\n",
    "\n",
    "    \n",
    "    def normalize(self, sentence):\n",
    "        # 정규표현식에 따른 한글 정규화\n",
    "        return self.normalizer.sub(\"\", sentence)\n",
    "\n",
    "    def clean_text(self, sentence):\n",
    "        # 한글 정규화\n",
    "        sentence = self.normalize(sentence)\n",
    "        # 형태소 처리\n",
    "        sentence = self.tagger.morphs(sentence)\n",
    "        sentence = ' '.join(sentence)\n",
    "        sentence = sentence.lower()\n",
    "        return sentence\n",
    "    \n",
    "    def texts_to_sequences(self, sentence):\n",
    "        # 문장 -> 시퀀스로 변환\n",
    "        return [self.wordvocab.word2index[w] for w in sentence.split()]\n",
    "\n",
    "    def pad_sequence(self, sentence_tokens):\n",
    "        # 문장의 맨 끝 토큰은 제거\n",
    "        sentence_tokens = sentence_tokens[:(self.max_length-1)]\n",
    "        token_length = len(sentence_tokens)\n",
    "\n",
    "        # 문장의 맨 끝부분에 <EOS> 토큰 추가\n",
    "        sentence_tokens.append(self.EOS_TOKEN)\n",
    "\n",
    "        for i in range(token_length, (self.max_length-1)):\n",
    "            # 나머지 빈 곳에 <PAD> 토큰 추가\n",
    "            sentence_tokens.append(self.PAD_TOKEN)\n",
    "        return sentence_tokens\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        inputs = self.srcs[idx]\n",
    "        inputs_sequences = self.texts_to_sequences(inputs)\n",
    "        inputs_padded = self.pad_sequence(inputs_sequences)\n",
    "        \n",
    "        outputs = self.tgts[idx]\n",
    "        outputs_sequences = self.texts_to_sequences(outputs)\n",
    "        outputs_padded = self.pad_sequence(outputs_sequences)\n",
    "        \n",
    "        return torch.tensor(inputs_padded), torch.tensor(outputs_padded)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.srcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한 문장의 최대 단어길이를 25로 설정\n",
    "MAX_LENGTH = 25\n",
    "\n",
    "dataset = TextDataset('Alz.csv', min_length=3, max_length=MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10번째 데이터 임의 추출\n",
    "x, y = dataset[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape: torch.Size([25])\n",
      "tensor([  3,  14,  77,  11,  12, 405,  21,  12, 410, 120,  40,  14, 109,  81,\n",
      "        361, 422, 112,   2,   0,   0,   0,   0,   0,   0,   0])\n",
      "y shape: torch.Size([25])\n",
      "tensor([  3,  32, 113, 114, 115,  31,   5,  81, 346, 139, 161,  12, 108,  89,\n",
      "         29, 201, 164, 165, 138,  90,  49,  50, 120,  40,   2])\n"
     ]
    }
   ],
   "source": [
    "print(f'x shape: {x.shape}')\n",
    "print(x)\n",
    "\n",
    "print(f'y shape: {y.shape}')\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 80%의 데이터를 train에 할당합니다.\n",
    "train_size = int(len(dataset) * 0.8)\n",
    "train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 나머지 20% 데이터를 test에 할당합니다.\n",
    "test_size = len(dataset) - train_size\n",
    "test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "# 랜덤 스플릿으로 분할을 완료합니다.\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataLoader생성\n",
    "-배치 구성을 쉽게 하기 위해서 torch.utils.data.DataLoader를 활용합니다.\n",
    "-train/test 데이터셋 모두 batch_size=16 으로 설정하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "\n",
    "train_loader = DataLoader(train_dataset, \n",
    "                          batch_size=16, \n",
    "                          shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, \n",
    "                         batch_size=16, \n",
    "                         shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1개의 배치 데이터를 추출합니다.\n",
    "x, y = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 25]), torch.Size([16, 25]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape: (batch_size, sequence_length)\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델/Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, num_vocabs, hidden_size, embedding_dim, num_layers):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        # 단어 사전의 개수 지정\n",
    "        self.num_vocabs = num_vocabs\n",
    "        # 임베딩 레이어 정의 (number of vocabs, embedding dimension)\n",
    "        self.embedding = nn.Embedding(num_vocabs, embedding_dim)\n",
    "        # GRU (embedding dimension)\n",
    "        self.gru = nn.GRU(embedding_dim, \n",
    "                          hidden_size, \n",
    "                          num_layers=num_layers, \n",
    "                          bidirectional=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x).permute(1, 0, 2)\n",
    "        output, hidden = self.gru(x)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 25])\n",
      "torch.Size([16, 25, 64])\n"
     ]
    }
   ],
   "source": [
    "# Embedding Layer의 입/출력 shape에 대한 이해\n",
    "\n",
    "embedding_dim = 64 # 임베딩 차원\n",
    "embedding = nn.Embedding(dataset.wordvocab.n_words, embedding_dim)\n",
    "\n",
    "# x의 shape을 변경합니다.\n",
    "# (batch_size, sequence_length) => (sequence_length, batch_size)\n",
    "embedded = embedding(x)\n",
    "\n",
    "print(x.shape)\n",
    "print(embedded.shape)\n",
    "# input:  (sequence_length, batch_size)\n",
    "# output: (sequence_length, batch_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 16, 64])\n"
     ]
    }
   ],
   "source": [
    "embedded = embedded.permute(1, 0, 2)\n",
    "print(embedded.shape)\n",
    "# (sequence_length, batch_size, embedding_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 16, 32])\n",
      "torch.Size([1, 16, 32])\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 32   \n",
    "\n",
    "gru = nn.GRU(embedding_dim,      # embedding 차원\n",
    "             hidden_size, \n",
    "             num_layers=1, \n",
    "             bidirectional=False)\n",
    "\n",
    "# input       : (sequence_length, batch_size, embedding_dim)\n",
    "# h0          : (Bidirectional(1) x number of layers(1), batch_size, hidden_size)\n",
    "o, h = gru(embedded, None)\n",
    "\n",
    "print(o.shape)\n",
    "print(h.shape)\n",
    "# output      : (sequence_length, batch_size, hidden_size x bidirectional(1))\n",
    "# hidden_state: (bidirectional(1) x number of layers(1), batch_size, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of vocabs: 2206\n"
     ]
    }
   ],
   "source": [
    "NUM_VOCABS = dataset.wordvocab.n_words\n",
    "print(f'number of vocabs: {NUM_VOCABS}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder 정의\n",
    "encoder = Encoder(NUM_VOCABS, \n",
    "                  hidden_size=32, \n",
    "                  embedding_dim=64, \n",
    "                  num_layers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 16, 32])\n",
      "torch.Size([1, 16, 32])\n"
     ]
    }
   ],
   "source": [
    "# Encoder에 x 통과 후 output, hidden_size 의 shape 확인\n",
    "# input(x)    : (batch_size, sequence_length)\n",
    "o, h = encoder(x)\n",
    "\n",
    "print(o.shape)\n",
    "print(h.shape)\n",
    "# output      : (sequence_length, batch_size, hidden_size x bidirectional(1))\n",
    "# hidden_state: (bidirectional(1) x number of layers(1), batch_size, hidden_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, num_vocabs, hidden_size, embedding_dim, num_layers=1, dropout=0.2):\n",
    "        super(Decoder, self).__init__()\n",
    "        # 단어사전 개수\n",
    "        self.num_vocabs = num_vocabs\n",
    "        self.embedding = nn.Embedding(num_vocabs, embedding_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.gru = nn.GRU(embedding_dim, \n",
    "                          hidden_size, \n",
    "                          num_layers=num_layers, \n",
    "                          bidirectional=False)\n",
    "        \n",
    "        # 최종 출력은 단어사전의 개수\n",
    "        self.fc = nn.Linear(hidden_size, num_vocabs)\n",
    "        \n",
    "    def forward(self, x, hidden_state):\n",
    "        x = x.unsqueeze(0) # (1, batch_size) 로 변환\n",
    "        embedded = F.relu(self.embedding(x))\n",
    "        embedded = self.dropout(embedded)\n",
    "        output, hidden = self.gru(embedded, hidden_state)\n",
    "        output = self.fc(output.squeeze(0)) # (sequence_length, batch_size, hidden_size(32) x bidirectional(1))\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Embedding Layer의 입/출력 shape\n",
    "x = torch.abs(torch.randn(size=(1, 16)).long())\n",
    "print(x)\n",
    "x.shape\n",
    "# batch_size = 16 이라 가정했을 때,\n",
    "# (1, batch_size)\n",
    "# 여기서 batch_size => (1, batch_size) 로 shape 변환을 선행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 64])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dim = 64 # 임베딩 차원\n",
    "embedding = nn.Embedding(dataset.wordvocab.n_words, embedding_dim)\n",
    "\n",
    "embedded = embedding(x)\n",
    "embedded.shape\n",
    "# embedding 출력\n",
    "# (1, batch_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 32])\n",
      "torch.Size([1, 16, 32])\n"
     ]
    }
   ],
   "source": [
    " #GRU Layer의 입/출력 shape에 대한 이해\n",
    "hidden_size = 32\n",
    "\n",
    "gru = nn.GRU(embedding_dim, \n",
    "             hidden_size, \n",
    "             num_layers=1, \n",
    "             bidirectional=False, \n",
    "             batch_first=False, # batch_first=False로 지정\n",
    "            )\n",
    "\n",
    "o, h = gru(embedded)\n",
    "\n",
    "print(o.shape)\n",
    "# output shape: (sequence_length, batch_size, hidden_size(32) x bidirectional(1))\n",
    "print(h.shape)\n",
    "# hidden_state shape: (Bidirectional(1) x number of layers(1), batch_size, hidden_size(32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 32])\n",
      "torch.Size([16, 2206])\n"
     ]
    }
   ],
   "source": [
    "# 최종 출력층(FC) shape에 대한 이해\n",
    "fc = nn.Linear(32, NUM_VOCABS) # 출력은 단어사전의 개수로 가정\n",
    "\n",
    "output = fc(o[0])\n",
    "\n",
    "print(o[0].shape)\n",
    "print(output.shape)\n",
    "# input : (batch_size, output from GRU)\n",
    "# output: (batch_size, output dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#인코더 -> 디코더 입출력 shape\n",
    "decoder = Decoder(num_vocabs=dataset.wordvocab.n_words, \n",
    "                  hidden_size=32, \n",
    "                  embedding_dim=64, \n",
    "                  num_layers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 16, 32]) torch.Size([1, 16, 32])\n"
     ]
    }
   ],
   "source": [
    "x, y = next(iter(train_loader))\n",
    "\n",
    "o, h = encoder(x)\n",
    "\n",
    "print(o.shape, h.shape)\n",
    "# output      : (batch_size, sequence_length, hidden_size(32) x bidirectional(1))\n",
    "# hidden_state: (Bidirectional(1) x number of layers(1), batch_size, hidden_size(32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "인코더(Encoder)로부터 생성된 hidden_state(h)와 SOS 토큰을 디코더(Decoder)의 입력으로 넣어줍니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([16])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ***************\n",
    "x = torch.abs(torch.full(size=(16,), fill_value=SOS_TOKEN, dtype=torch.long))\n",
    "print(x)\n",
    "x.shape\n",
    "\n",
    "# batch_size = 16 이라 가정(16개의 SOS 토큰)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 64])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dim = 64 # 임베딩 차원\n",
    "embedding = nn.Embedding(dataset.wordvocab.n_words, embedding_dim)\n",
    "\n",
    "embedded = embedding(x)\n",
    "embedded.shape\n",
    "# embedding 출력\n",
    "# (1, batch_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 2206]), torch.Size([1, 16, 32]))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_output, decoder_hidden = decoder(x, h)\n",
    "decoder_output.shape, decoder_hidden.shape\n",
    "# (batch_size, num_vocabs), (1, batch_size, hidden_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        \n",
    "    def forward(self, inputs, outputs, teacher_forcing_ratio=0.5):\n",
    "        # inputs : (batch_size, sequence_length)\n",
    "        # outputs: (batch_size, sequence_length)\n",
    "        \n",
    "        batch_size, output_length = outputs.shape\n",
    "        output_num_vocabs = self.decoder.num_vocabs\n",
    "        \n",
    "        # 리턴할 예측된 outputs를 저장할 임시 변수\n",
    "        # (sequence_length, batch_size, num_vocabs)\n",
    "        predicted_outputs = torch.zeros(output_length, batch_size, output_num_vocabs).to(self.device)\n",
    "        \n",
    "        # 인코더에 입력 데이터 주입, encoder_output은 버리고 hidden_state 만 살립니다. \n",
    "        # 여기서 hidden_state가 디코더에 주입할 context vector 입니다.\n",
    "        # (Bidirectional(1) x number of layers(1), batch_size, hidden_size)\n",
    "        _, decoder_hidden = self.encoder(inputs)\n",
    "        \n",
    "        # (batch_size) shape의 SOS TOKEN으로 채워진 디코더 입력 생성********************\n",
    "        decoder_input = torch.full((batch_size,), SOS_TOKEN, dtype=torch.long, device=self.device)\n",
    "        \n",
    "        # 순회하면서 출력 단어를 생성합니다.\n",
    "        # 0번째는 SOS TOKEN이 위치하므로, 1번째 인덱스부터 순회합니다.\n",
    "        for t in range(0, output_length):\n",
    "            # decoder_input : 디코더 입력 (batch_size) 형태의 SOS TOKEN로 채워진 입력\n",
    "            # decoder_output: (batch_size, num_vocabs)\n",
    "            # decoder_hidden: (Bidirectional(1) x number of layers(1), batch_size, hidden_size), context vector와 동일 shape\n",
    "            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
    "\n",
    "            # t번째 단어에 디코더의 output 저장\n",
    "            predicted_outputs[t] = decoder_output\n",
    "            \n",
    "            # teacher forcing 적용 여부 확률로 결정\n",
    "            # teacher forcing 이란: 정답치를 다음 RNN Cell의 입력으로 넣어주는 경우. 수렴속도가 빠를 수 있으나, 불안정할 수 있음\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            \n",
    "            # top1 단어 토큰 예측\n",
    "            top1 = decoder_output.argmax(1) \n",
    "            \n",
    "            # teacher forcing 인 경우 ground truth 값을, 그렇지 않은 경우, 예측 값을 다음 input으로 지정\n",
    "            decoder_input = outputs[:, t] if teacher_force else top1\n",
    "        \n",
    "        return predicted_outputs.permute(1, 0, 2) # (batch_size, sequence_length, num_vocabs)로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seq2Seq 입출력 확인\n",
    "# Encoder 정의\n",
    "encoder = Encoder(num_vocabs=dataset.wordvocab.n_words, \n",
    "                       hidden_size=32, \n",
    "                       embedding_dim=64, \n",
    "                       num_layers=1)\n",
    "# Decoder 정의\n",
    "decoder = Decoder(num_vocabs=dataset.wordvocab.n_words, \n",
    "                       hidden_size=32, \n",
    "                       embedding_dim=64, \n",
    "                       num_layers=1)\n",
    "# Seq2Seq 정의\n",
    "seq2seq = Seq2Seq(encoder, decoder, 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 25]) torch.Size([16, 25])\n"
     ]
    }
   ],
   "source": [
    "x, y = next(iter(train_loader))\n",
    "print(x.shape, y.shape)\n",
    "# (batch_size, sequence_length), (batch_size, sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 25, 2206])\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "output = seq2seq(x, y)\n",
    "print(output.shape)\n",
    "# (batch_size, sequence_length, num_vocabs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_vocabs: 2206\n",
      "======================\n",
      "Seq2Seq(\n",
      "  (encoder): Encoder(\n",
      "    (embedding): Embedding(2206, 256)\n",
      "    (gru): GRU(256, 512)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (embedding): Embedding(2206, 256)\n",
      "    (dropout): Dropout(p=0.2, inplace=False)\n",
      "    (gru): GRU(256, 512)\n",
      "    (fc): Linear(in_features=512, out_features=2206, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "NUM_VOCABS = dataset.wordvocab.n_words\n",
    "HIDDEN_SIZE = 512\n",
    "EMBEDDIMG_DIM = 256\n",
    "\n",
    "print(f'num_vocabs: {NUM_VOCABS}\\n======================')\n",
    "\n",
    "# Encoder 정의\n",
    "encoder = Encoder(num_vocabs=NUM_VOCABS, \n",
    "                  hidden_size=HIDDEN_SIZE, \n",
    "                  embedding_dim=EMBEDDIMG_DIM, \n",
    "                  num_layers=1)\n",
    "# Decoder 정의\n",
    "decoder = Decoder(num_vocabs=NUM_VOCABS, \n",
    "                  hidden_size=HIDDEN_SIZE, \n",
    "                  embedding_dim=EMBEDDIMG_DIM, \n",
    "                  num_layers=1)\n",
    "\n",
    "# Seq2Seq 생성\n",
    "# encoder, decoder를 device 모두 지정\n",
    "model = Seq2Seq(encoder.to(device), decoder.to(device), device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HyperParameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=3, delta=0.0, mode='min', verbose=True):\n",
    "        \"\"\"\n",
    "        patience (int): loss or score가 개선된 후 기다리는 기간. default: 3\n",
    "        delta  (float): 개선시 인정되는 최소 변화 수치. default: 0.0\n",
    "        mode     (str): 개선시 최소/최대값 기준 선정('min' or 'max'). default: 'min'.\n",
    "        verbose (bool): 메시지 출력. default: True\n",
    "        \"\"\"\n",
    "        self.early_stop = False\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        \n",
    "        self.best_score = np.Inf if mode == 'min' else 0\n",
    "        self.mode = mode\n",
    "        self.delta = delta\n",
    "        \n",
    "\n",
    "    def __call__(self, score):\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.counter = 0\n",
    "        elif self.mode == 'min':\n",
    "            if score < (self.best_score - self.delta):\n",
    "                self.counter = 0\n",
    "                self.best_score = score\n",
    "                if self.verbose:\n",
    "                    print(f'[EarlyStopping] (Update) Best Score: {self.best_score:.5f}')\n",
    "            else:\n",
    "                self.counter += 1\n",
    "                if self.verbose:\n",
    "                    print(f'[EarlyStopping] (Patience) {self.counter}/{self.patience}, ' \\\n",
    "                          f'Best: {self.best_score:.5f}' \\\n",
    "                          f', Current: {score:.5f}, Delta: {np.abs(self.best_score - score):.5f}')\n",
    "                \n",
    "        elif self.mode == 'max':\n",
    "            if score > (self.best_score + self.delta):\n",
    "                self.counter = 0\n",
    "                self.best_score = score\n",
    "                if self.verbose:\n",
    "                    print(f'[EarlyStopping] (Update) Best Score: {self.best_score:.5f}')\n",
    "            else:\n",
    "                self.counter += 1\n",
    "                if self.verbose:\n",
    "                    print(f'[EarlyStopping] (Patience) {self.counter}/{self.patience}, ' \\\n",
    "                          f'Best: {self.best_score:.5f}' \\\n",
    "                          f', Current: {score:.5f}, Delta: {np.abs(self.best_score - score):.5f}')\n",
    "                \n",
    "            \n",
    "        if self.counter >= self.patience:\n",
    "            if self.verbose:\n",
    "                print(f'[EarlyStop Triggered] Best Score: {self.best_score:.5f}')\n",
    "            # Early Stop\n",
    "            self.early_stop = True\n",
    "        else:\n",
    "            # Continue\n",
    "            self.early_stop = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련에 적용할 하이퍼파라미터 설정\n",
    "\n",
    "LR = 1e-3\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "es = EarlyStopping(patience=5, \n",
    "                   delta=0.001, \n",
    "                   mode='min', \n",
    "                   verbose=True\n",
    "                  )\n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, \n",
    "                                                 mode='min', \n",
    "                                                 factor=0.5, \n",
    "                                                 patience=2,\n",
    "                                                 threshold_mode='abs',\n",
    "                                                 min_lr=1e-8, \n",
    "                                                 verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 함수 정의\n",
    "def train(model, data_loader, optimizer, loss_fn, device):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    \n",
    "    for x, y in data_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # output: (batch_size, sequence_length, num_vocabs)\n",
    "        output = model(x, y)\n",
    "        output_dim = output.size(2)\n",
    "        \n",
    "        # 1번 index 부터 슬라이싱한 이유는 0번 index가 SOS TOKEN 이기 때문\n",
    "        # (batch_size*sequence_length, num_vocabs) 로 변경\n",
    "        output = output.reshape(-1, output_dim)\n",
    "        \n",
    "        # (batch_size*sequence_length) 로 변경\n",
    "        y = y.view(-1)\n",
    "        \n",
    "        # Loss 계산\n",
    "        loss = loss_fn(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * x.size(0)\n",
    "        \n",
    "    return running_loss / len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation 함수 정의\n",
    "def evaluate(model, data_loader, loss_fn, device):\n",
    "    model.eval()\n",
    "    \n",
    "    eval_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in data_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            output = model(x, y)\n",
    "            output_dim = output.size(2)\n",
    "            output = output.reshape(-1, output_dim)\n",
    "            y = y.view(-1)\n",
    "            \n",
    "            # Loss 계산\n",
    "            loss = loss_fn(output, y)\n",
    "            \n",
    "            eval_loss += loss.item() * x.size(0)\n",
    "            \n",
    "    return eval_loss / len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤 샘플링 후 결과 추론\n",
    "def sequence_to_sentence(sequences, index2word):\n",
    "    outputs = []\n",
    "    for p in sequences:\n",
    "\n",
    "        word = index2word[p]\n",
    "        if p not in [SOS_TOKEN, EOS_TOKEN, PAD_TOKEN]:\n",
    "            outputs.append(word)\n",
    "        if word == EOS_TOKEN:\n",
    "            break\n",
    "    return ' '.join(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequence를 다시 문장으로 바꾸어 문장 형식으로 출력하기 위한 함수\n",
    "\n",
    "def random_evaluation(model, dataset, index2word, device, n=10):\n",
    "    \n",
    "    n_samples = len(dataset)\n",
    "    indices = list(range(n_samples))\n",
    "    np.random.shuffle(indices)      # Shuffle\n",
    "    sampled_indices = indices[:n]   # Sampling N indices\n",
    "    \n",
    "    # 샘플링한 데이터를 기반으로 DataLoader 생성\n",
    "    sampler = SubsetRandomSampler(sampled_indices)\n",
    "    sampled_dataloader = DataLoader(dataset, batch_size=10, sampler=sampler)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in sampled_dataloader:\n",
    "            x, y = x.to(device), y.to(device)        \n",
    "            output = model(x, y, teacher_forcing_ratio=0)\n",
    "            # output: (number of samples, sequence_length, num_vocabs)\n",
    "            \n",
    "            preds = output.detach().cpu().numpy()\n",
    "            x = x.detach().cpu().numpy()\n",
    "            y = y.detach().cpu().numpy()\n",
    "            \n",
    "            for i in range(n):\n",
    "                print(f'질문   : {sequence_to_sentence(x[i], index2word)}')\n",
    "                print(f'답변   : {sequence_to_sentence(y[i], index2word)}')\n",
    "                print(f'예측답변: {sequence_to_sentence(preds[i].argmax(1), index2word)}')\n",
    "                print('==='*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, loss: 72.4767, val_loss: 61.1671\n",
      "[EarlyStopping] (Update) Best Score: 72.47670\n",
      "[EarlyStopping] (Update) Best Score: 58.06612\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16960\\3120828990.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mval_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mbest_loss\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16960\\935022652.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(model, data_loader, loss_fn, device)\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m             \u001b[0moutput_dim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\KOREAVC\\anaconda3\\envs\\pororo\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16960\\1258445713.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, inputs, outputs, teacher_forcing_ratio)\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[1;31m# decoder_output: (batch_size, num_vocabs)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[1;31m# decoder_hidden: (Bidirectional(1) x number of layers(1), batch_size, hidden_size), context vector와 동일 shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m             \u001b[0mdecoder_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder_hidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecoder_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder_hidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m             \u001b[1;31m# t번째 단어에 디코더의 output 저장\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\KOREAVC\\anaconda3\\envs\\pororo\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16960\\927902613.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, hidden_state)\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# (1, batch_size) 로 변환\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0membedded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0membedded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\KOREAVC\\anaconda3\\envs\\pororo\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mrelu\u001b[1;34m(input, inplace)\u001b[0m\n\u001b[0;32m   1117\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1119\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1120\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#  훈련 시작\n",
    "NUM_EPOCHS = 5\n",
    "STATEDICT_PATH = 'seq2seq-chatbot-kor.pt'\n",
    "\n",
    "best_loss = np.inf\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    loss = train(model, train_loader, optimizer, loss_fn, device)\n",
    "    \n",
    "    val_loss = evaluate(model, test_loader, loss_fn, device)\n",
    "    \n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        torch.save(model.state_dict(), STATEDICT_PATH)\n",
    "    \n",
    "    if epoch % 5 == 0:\n",
    "        print(f'epoch: {epoch+1}, loss: {loss:.4f}, val_loss: {val_loss:.4f}')\n",
    "    \n",
    "    # Early Stop\n",
    "    es(loss)\n",
    "    if es.early_stop:\n",
    "        break\n",
    "    \n",
    "    # Scheduler\n",
    "    scheduler.step(val_loss)\n",
    "                   \n",
    "model.load_state_dict(torch.load(STATEDICT_PATH))\n",
    "torch.save(model.state_dict(), f'seq2seq-chatbot-kor-{best_loss:.4f}.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문   : 알츠하이머병 치료 를 위해 약물 이외 에 다른 치료법 들 이 존재 하 는지 알 고 싶 어요 .\n",
      "답변   : 알츠하이머병 은 뇌 의 인지 기능 저하 가 주요 한 증상 을 보이 는 질병 입니다 . 이러 한 치매 는 시간 이 지날수록\n",
      "예측답변: 알츠하이머병 은 치료 치료 는 치료 는 치료 는 의 치료 , , ,\n",
      "==============================\n",
      "질문   : 알츠하이머병 의 치료 에 는 어떤 종류 의 약물 이 사용 되 나요 ?\n",
      "답변   : 알츠하이머병 은 현재 까지 근본 적 인 치료 방법 이 없 으며 , 현재 까지 알려진 유일 한 치료법 은 콜린 성 신경 전달\n",
      "예측답변: 알츠하이머병 은 치료 치료 는 치료 는 치료 는 의 치료 , , ,\n",
      "==============================\n",
      "질문   : 알츠하이머병 치료 에 있 어서 어떤 치료 방법 이 가장 효과 적 일까요 ?\n",
      "답변   : 알츠하이머병 은 기억 과 인지 기능 에 영향 을 주 는 만성 뇌 질환 으로 , 치료 와 관리 의 중요 성 이 있\n",
      "예측답변: 알츠하이머병 은 치료 치료 는 치료 는 치료 는 의 치료 , , ,\n",
      "==============================\n",
      "질문   : 알츠하이머병 치료 에 있 어서 약물 이외 에 어떤 방법 이 효과 적 일까요 ?\n",
      "답변   : 알츠하이머병 은 치매 의 가장 흔한 원인 이 며 , 아직 까지 근본 적 인 치료 방법 은 없 습니다 . 현재 까지 의\n",
      "예측답변: 알츠하이머병 은 치료 치료 는 치료 는 치료 는 의 치료 , , ,\n",
      "==============================\n",
      "질문   : 알츠하이머병 치료 를 위해 어떤 약물 이 사용 될 수 있 는지 알려 주 세요 .\n",
      "답변   : 알츠하이머병 은 가장 흔한 치매 로 , 뇌 의 퇴행 성 질환 입니다 . 초기 에 는 기억력 저하 로 시작 하 여 언어\n",
      "예측답변: 알츠하이머병 은 치료 치료 는 치료 는 치료 는 의 치료 , , ,\n",
      "==============================\n",
      "질문   : 알츠하이머병 을 예방 하 기 위한 가족 들 의 주요 한 도움 방법 은 무엇 인가요 ?\n",
      "답변   : 알츠하이머병 은 현재 까지 완전 한 치료 를 위한 치료법 은 없 지만 , 약물 치료 를 통해 일부 증상 을 완화 시킬 수\n",
      "예측답변: 알츠하이머병 은 치료 치료 는 치료 는 치료 는 의 치료 , , ,\n",
      "==============================\n",
      "질문   : 알츠하이머병 치료 에 사용 되 는 약물 중 어떤 것 이 가장 효과 적 인가요 ?\n",
      "답변   : 알츠하이머병 은 치매 의 주요 원인 중 하나 로 , 그 치료 에 대한 연구 가 계속 되 고 있 습니다 . 알츠하이머병 의\n",
      "예측답변: 알츠하이머병 은 치료 치료 는 치료 는 치료 는 의 치료 , , ,\n",
      "==============================\n",
      "질문   : 알츠하이머병 치료 에 사용 되 는 전략 과 기술 은 무엇 인가요 ?\n",
      "답변   : 알츠하이머병 은 아직 근본 적 인 치료법 이 없 습니다 . 현재 까지 는 알츠하이머병 의 증상 을 완화 하 고 질병 의 진행\n",
      "예측답변: 알츠하이머병 은 치료 치료 는 치료 는 치료 는 의 치료 , , ,\n",
      "==============================\n",
      "질문   : 알츠하이머병 을 치료 하 기 위한 다른 치료 방법 들 이 있 는지 궁금 합니다 .\n",
      "답변   : 알츠하이머병 은 현재 까지 근본 적 인 치료법 은 없 지만 , 다양 한 치료법 이 있 습니다 . 알츠하이머병 의 치료 방법 중\n",
      "예측답변: 알츠하이머병 은 치료 치료 는 치료 는 치료 는 의 치료 , , ,\n",
      "==============================\n",
      "질문   : 알츠하이머병 을 치료 하 기 위해 어떤 치료 방법 들 이 사용 되 는지 알려 주 세요 .\n",
      "답변   : 알츠하이머병 은 노인 들 사이 에서 매우 흔한 질환 으로 , 주로 노화 로 인해 발생 하 는 질환 입니다 . 이 질환 은\n",
      "예측답변: 알츠하이머병 은 치료 치료 는 치료 는 치료 는 의 치료 , , ,\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(STATEDICT_PATH))\n",
    "random_evaluation(model, test_dataset, dataset.wordvocab.index2word, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pororo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
